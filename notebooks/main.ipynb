{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "opSsBIYavpHf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a8c07e4-28ae-4564-bd6e-fe2cb5220190"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.59.2)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.3.25)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.34.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.41.3)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (1.11.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "tmPLfcUaE8i1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('preprocessed_data.csv')"
      ],
      "metadata": {
        "id": "yDTiHISG3tye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming 'data' is your DataFrame with 32 input features and 'Category' is the target variable\n",
        "# Load and preprocess the data\n",
        "# ... (Assuming you've loaded and preprocessed the data as discussed earlier)\n",
        "\n",
        "# Extract features and labels\n",
        "X = data.iloc[:, :-1].values\n",
        "y = data['Category'].values\n",
        "\n",
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "results = {}\n",
        "# Models\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
        "    'Decision Tree': DecisionTreeClassifier(),\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'Naive Bayes': GaussianNB(),\n",
        "    'Gaussian Mixture Model': GaussianMixture(n_components=20),\n",
        "    'K-nearest Neighbors': KNeighborsClassifier(),\n",
        "    'Discriminant Analysis': LinearDiscriminantAnalysis(),\n",
        "    'Support Vector Machine': SVC(),\n",
        "    'Neural Network': MLPClassifier(max_iter=1000)\n",
        "}\n",
        "\n",
        "# Training and evaluation loop\n",
        "for model_name, model in models.items():\n",
        "    print(f\"Training {model_name}...\")\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Evaluate the model\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "    # class_report = classification_report(y_test, y_pred, target_names=le.classes_, zero_division=1)  # Setting zero_division parameter\n",
        "    class_report = classification_report(y_test, y_pred, target_names=list(map(str, le.classes_)))\n",
        "\n",
        "    results[model_name] = {\n",
        "        'accuracy': accuracy,\n",
        "        'confusion_matrix': conf_matrix,\n",
        "        'classification_report': class_report\n",
        "    }\n",
        "\n",
        "    # Print results\n",
        "    print(f\"\\n{model_name} Results:\")\n",
        "    print(f\"Accuracy: {accuracy}\")\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(conf_matrix)\n",
        "    print(\"Classification Report:\")\n",
        "    print(class_report)\n",
        "    print(\"=\"*50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVfpMaEJ8zsx",
        "outputId": "557793a9-eaaf-4f84-e8c9-bb260212b5e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Logistic Regression...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Logistic Regression Results:\n",
            "Accuracy: 0.2348530901722391\n",
            "Confusion Matrix:\n",
            "[[  4  18   0   0   1   0   0   2   0   2   6   1   0   0  85   0   0   0\n",
            "    3   2]\n",
            " [  4 134   8   0  27   1   0   6   0   2  56   0   0   0 229   0   0   0\n",
            "   12   1]\n",
            " [  0  25  13   1   4   0   0   1   1   1  13   0   0   0 188   0   0   0\n",
            "    0   0]\n",
            " [  0  24   2   0  21   1   0   3   1   3  63   0   0   1  94   0   0   0\n",
            "    1   0]\n",
            " [  1  28   1   0  81   3   0  11   2   9 138   1   0   2 150   0   1   0\n",
            "    0   1]\n",
            " [  1  36   0   0  24   4   1   2   2   5  97   0   0   0 133   0   0   0\n",
            "    2   0]\n",
            " [  0   8   0   0   4   0   0   0   1   2  14   0   0   0  20   0   0   0\n",
            "    0   0]\n",
            " [  0  55   4   1  12   2   0  12   1   2  68   0   0   0 181   0   0   0\n",
            "    0   0]\n",
            " [  0  24   2   2  29   1   0   4   2   6  66   0   0   2  50   0   0   0\n",
            "    1   0]\n",
            " [  0  12   0   1  15   0   0   0   0  34  39   0   0   0  56   0   0   0\n",
            "    0   0]\n",
            " [  5  45   3   2  67   5   0   4   8  11 201   0   0   0 240   0   0   0\n",
            "    1   1]\n",
            " [  0   2   0   0   2   0   0   0   0   2  15   0   0   0  15   0   0   0\n",
            "    0   0]\n",
            " [  0  19   0   2   6   1   0   0   0   2   7   0   0   1  73   0   0   0\n",
            "    1   0]\n",
            " [  0   0   0   0   3   0   0   0   3   3   6   0   0   2   2   0   0   0\n",
            "    1   0]\n",
            " [  3 127   9   1  30   2   0   6   3   5  97   0   1   2 664   0   0   0\n",
            "    8   0]\n",
            " [  0   3   0   0   0   0   0   0   1   0   3   0   0   0  12   0   0   0\n",
            "    0   0]\n",
            " [  0   4   0   1   1   0   0   0   0   0   2   0   0   0   9   0   0   0\n",
            "    0   0]\n",
            " [  0  14   2   0  12   0   0   1   0   4  23   1   0   0 102   0   0   0\n",
            "    3   0]\n",
            " [  0  37   2   0   4   1   0   2   1   2  21   0   0   1 207   0   0   0\n",
            "    8   1]\n",
            " [  0  13   1   0  12   0   0   2   0   3  13   0   0   0 152   0   0   0\n",
            "    1   0]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.22      0.03      0.06       124\n",
            "           1       0.21      0.28      0.24       480\n",
            "           2       0.28      0.05      0.09       247\n",
            "           3       0.00      0.00      0.00       214\n",
            "           4       0.23      0.19      0.21       429\n",
            "           5       0.19      0.01      0.02       307\n",
            "           6       0.00      0.00      0.00        49\n",
            "           7       0.21      0.04      0.06       338\n",
            "           8       0.08      0.01      0.02       189\n",
            "           9       0.35      0.22      0.27       157\n",
            "          10       0.21      0.34      0.26       593\n",
            "          11       0.00      0.00      0.00        36\n",
            "          12       0.00      0.00      0.00       112\n",
            "          13       0.18      0.10      0.13        20\n",
            "          14       0.25      0.69      0.37       958\n",
            "          15       0.00      0.00      0.00        19\n",
            "          16       0.00      0.00      0.00        17\n",
            "          17       0.00      0.00      0.00       162\n",
            "          18       0.19      0.03      0.05       287\n",
            "          19       0.00      0.00      0.00       197\n",
            "\n",
            "    accuracy                           0.23      4935\n",
            "   macro avg       0.13      0.10      0.09      4935\n",
            "weighted avg       0.19      0.23      0.17      4935\n",
            "\n",
            "==================================================\n",
            "Training Decision Tree...\n",
            "\n",
            "Decision Tree Results:\n",
            "Accuracy: 0.6772036474164134\n",
            "Confusion Matrix:\n",
            "[[ 86   4   0   2   2   1   0   0   2   0   5   0   3   2   9   0   0   0\n",
            "    4   4]\n",
            " [  4 392   3   8   4   1   1  17   4   3  12   2   1   0   9   0   0   6\n",
            "    9   4]\n",
            " [  4   5 199   1   2   5   1   3   2   1   5   0   0   0  10   0   1   1\n",
            "    0   7]\n",
            " [  3   7   1 137  13   9   0   4   1   5  11   0   2   0   5   0   1   1\n",
            "    6   8]\n",
            " [  2   5   0  11 261  15   1  24  18   7  36   1   2   1  23   1   0   9\n",
            "   10   2]\n",
            " [  2   5   2   4  17 204   3   2   4   7  26   1   2   1  14   2   0   4\n",
            "    4   3]\n",
            " [  1   1   2   0   5   1  20   4   2   0   3   0   1   0   3   0   0   4\n",
            "    1   1]\n",
            " [  2  17   4   3  13   7   2 231   5   1  12   1   0   0  19   1   1   8\n",
            "    6   5]\n",
            " [  4   8   1   2  11  12   4   8  78   3  22   0   6   0  15   1   1   6\n",
            "    6   1]\n",
            " [  1   1   2   8   9  10   1   5   5  91  12   0   0   1   8   0   0   1\n",
            "    2   0]\n",
            " [ 11  10   6  16  25  25   4  18  31   7 343   2  10   1  39   0   0  16\n",
            "   13  16]\n",
            " [  0   2   0   0   0   1   0   0   0   2   4  23   0   0   4   0   0   0\n",
            "    0   0]\n",
            " [  0   2   0   7   3   1   0   1   3   1   2   0  76   0   6   0   0   5\n",
            "    5   0]\n",
            " [  0   0   0   0   0   0   0   1   2   0   1   0   0  13   2   0   0   0\n",
            "    1   0]\n",
            " [  6  21   5  13  17  17   5  15  17   5  42   2   8   1 737   2   0  15\n",
            "   17  13]\n",
            " [  2   0   0   0   0   1   0   1   2   0   2   0   0   0   2   9   0   0\n",
            "    0   0]\n",
            " [  0   0   0   1   0   0   1   0   0   0   1   0   0   0   0   0  13   0\n",
            "    0   1]\n",
            " [  2   4   0   2   9   6   4   9   5   1   6   1   1   0   9   1   0  94\n",
            "    7   1]\n",
            " [  1   4   4   5   7   4   2   2   8   1  14   4   2   0  22   1   1   7\n",
            "  193   5]\n",
            " [  1   5   6   1   3   5   0   5   2   5   5   0   3   0   9   0   0   4\n",
            "    1 142]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.69      0.67       124\n",
            "           1       0.80      0.82      0.81       480\n",
            "           2       0.85      0.81      0.83       247\n",
            "           3       0.62      0.64      0.63       214\n",
            "           4       0.65      0.61      0.63       429\n",
            "           5       0.63      0.66      0.65       307\n",
            "           6       0.41      0.41      0.41        49\n",
            "           7       0.66      0.68      0.67       338\n",
            "           8       0.41      0.41      0.41       189\n",
            "           9       0.65      0.58      0.61       157\n",
            "          10       0.61      0.58      0.59       593\n",
            "          11       0.62      0.64      0.63        36\n",
            "          12       0.65      0.68      0.66       112\n",
            "          13       0.65      0.65      0.65        20\n",
            "          14       0.78      0.77      0.77       958\n",
            "          15       0.50      0.47      0.49        19\n",
            "          16       0.72      0.76      0.74        17\n",
            "          17       0.52      0.58      0.55       162\n",
            "          18       0.68      0.67      0.67       287\n",
            "          19       0.67      0.72      0.69       197\n",
            "\n",
            "    accuracy                           0.68      4935\n",
            "   macro avg       0.64      0.64      0.64      4935\n",
            "weighted avg       0.68      0.68      0.68      4935\n",
            "\n",
            "==================================================\n",
            "Training Random Forest...\n",
            "\n",
            "Random Forest Results:\n",
            "Accuracy: 0.6869300911854104\n",
            "Confusion Matrix:\n",
            "[[ 44   5   0   0   2   0   0   1   0   1  13   0   0   0  57   0   0   0\n",
            "    1   0]\n",
            " [  0 401   0   2   4   2   0   7   2   4   9   1   0   0  46   0   0   0\n",
            "    2   0]\n",
            " [  0   4 174   0   0   1   0   2   4   0   6   0   0   0  54   0   0   0\n",
            "    1   1]\n",
            " [  0   6   1 148   9   3   0   2   3   1  12   0   0   0  27   0   0   0\n",
            "    2   0]\n",
            " [  1  11   1   1 305   8   1   6   2   0  47   0   0   1  41   0   0   2\n",
            "    1   1]\n",
            " [  2  12   0   0  11 198   0   5   2   0  34   0   1   0  41   0   0   1\n",
            "    0   0]\n",
            " [  0   2   0   1   0   1  20   2   2   0   4   0   0   0  14   0   0   1\n",
            "    1   1]\n",
            " [  1  14   4   1   5   7   0 205   2   0  28   0   2   0  65   0   0   2\n",
            "    1   1]\n",
            " [  0   3   0   0  10   6   0   0 107   1  29   0   0   0  32   0   0   0\n",
            "    1   0]\n",
            " [  0   1   1   1   3   2   0   0   6  98  22   0   0   0  23   0   0   0\n",
            "    0   0]\n",
            " [  2  20   3   0  14   8   0  10   5   5 425   0   0   0  98   0   0   0\n",
            "    0   3]\n",
            " [  0   1   0   0   0   0   0   2   0   0   7  17   0   0   9   0   0   0\n",
            "    0   0]\n",
            " [  0   2   1   0   1   0   0   7   0   1   2   0  72   0  26   0   0   0\n",
            "    0   0]\n",
            " [  0   0   0   0   2   0   0   0   2   0   3   0   0  12   1   0   0   0\n",
            "    0   0]\n",
            " [  2  16  15   4  15   3   1  13   5   2  53   0   1   0 816   0   0   1\n",
            "   10   1]\n",
            " [  0   2   0   0   1   0   0   0   0   0   7   0   0   0   6   3   0   0\n",
            "    0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  17   0\n",
            "    0   0]\n",
            " [  1   4   1   0   6   3   0   4   0   0  18   0   0   0  55   0   0  69\n",
            "    1   0]\n",
            " [  1  27   1   0   2   3   0   4   2   0  15   0   0   0  81   0   0   0\n",
            "  149   2]\n",
            " [  2   6   0   0   0   2   0   3   2   2   9   0   0   0  57   0   0   0\n",
            "    4 110]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.35      0.49       124\n",
            "           1       0.75      0.84      0.79       480\n",
            "           2       0.86      0.70      0.78       247\n",
            "           3       0.94      0.69      0.80       214\n",
            "           4       0.78      0.71      0.74       429\n",
            "           5       0.80      0.64      0.71       307\n",
            "           6       0.91      0.41      0.56        49\n",
            "           7       0.75      0.61      0.67       338\n",
            "           8       0.73      0.57      0.64       189\n",
            "           9       0.85      0.62      0.72       157\n",
            "          10       0.57      0.72      0.64       593\n",
            "          11       0.94      0.47      0.63        36\n",
            "          12       0.95      0.64      0.77       112\n",
            "          13       0.92      0.60      0.73        20\n",
            "          14       0.53      0.85      0.65       958\n",
            "          15       1.00      0.16      0.27        19\n",
            "          16       1.00      1.00      1.00        17\n",
            "          17       0.91      0.43      0.58       162\n",
            "          18       0.86      0.52      0.65       287\n",
            "          19       0.92      0.56      0.69       197\n",
            "\n",
            "    accuracy                           0.69      4935\n",
            "   macro avg       0.84      0.60      0.68      4935\n",
            "weighted avg       0.74      0.69      0.69      4935\n",
            "\n",
            "==================================================\n",
            "Training Naive Bayes...\n",
            "\n",
            "Naive Bayes Results:\n",
            "Accuracy: 0.1110435663627153\n",
            "Confusion Matrix:\n",
            "[[ 30   9   2   0   4   0   0  35   0   1   0   5   0   0   7   0   2   0\n",
            "    2  27]\n",
            " [ 68  40  10   1  34   0   0 138   2   7  19   9   0   6  33   0  10   0\n",
            "   34  69]\n",
            " [ 44  21  24   2   4   0   0  44  10   2   3   0   0   2   9   0  14   0\n",
            "    1  67]\n",
            " [ 16   7   8   3  21   0   0  35  13  13  11  18   0  22   8   0   5   0\n",
            "    2  32]\n",
            " [ 34   8   6   1 109   0   2  83  25  10  16  25   1  47  12   0   0   1\n",
            "    1  48]\n",
            " [ 32  10   4   0  49   0   1  58  10  15  16  21   0  35  12   0   3   0\n",
            "    2  39]\n",
            " [  3   5   0   0   3   0   1   7   3   6   1   2   0   4   1   0   0   0\n",
            "    1  12]\n",
            " [ 47  10   7   0  32   0   1 117  11   6  15  13   0  12  11   0   4   1\n",
            "    1  50]\n",
            " [ 14   4   6   0  40   0   0  21  17   6   2  11   0  35   6   0   2   0\n",
            "    2  23]\n",
            " [ 16   4   8   0  18   0   0  22   9  14   3  11   0  29   8   0   4   0\n",
            "    0  11]\n",
            " [ 60  23   9   1  96   0   0 103  27  27  39  36   0  88  20   0   2   0\n",
            "    3  59]\n",
            " [  2   1   0   0   8   0   0   2   5   3   3   2   2   1   3   0   0   0\n",
            "    0   4]\n",
            " [ 23   7   2   1   2   0   0  27   1   3   3   5   0   6   3   0   5   0\n",
            "    0  24]\n",
            " [  0   0   0   0   4   0   0   0   1   0   0   0   0  12   0   0   0   0\n",
            "    1   2]\n",
            " [139  62  31   2  36   0   0 193  23  29  13  33   0  52  56   0  22   1\n",
            "   42 224]\n",
            " [  5   2   0   0   3   0   0   5   1   1   0   0   0   2   0   0   0   0\n",
            "    0   0]\n",
            " [  0   3   1   0   1   0   0   3   0   2   0   3   0   1   1   0   2   0\n",
            "    0   0]\n",
            " [ 20   6   2   0  16   0   0  45   4   5   4  16   0   9  10   0   1   0\n",
            "    0  24]\n",
            " [ 34  18   4   0   8   0   1  66   4   8  13  11   1  12  25   0   2   0\n",
            "   20  60]\n",
            " [ 30   7   1   0  10   0   0  39   5   7   1   4   0  11  10   0   2   0\n",
            "    8  62]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.05      0.24      0.08       124\n",
            "           1       0.16      0.08      0.11       480\n",
            "           2       0.19      0.10      0.13       247\n",
            "           3       0.27      0.01      0.03       214\n",
            "           4       0.22      0.25      0.24       429\n",
            "           5       0.00      0.00      0.00       307\n",
            "           6       0.17      0.02      0.04        49\n",
            "           7       0.11      0.35      0.17       338\n",
            "           8       0.10      0.09      0.09       189\n",
            "           9       0.08      0.09      0.09       157\n",
            "          10       0.24      0.07      0.10       593\n",
            "          11       0.01      0.06      0.02        36\n",
            "          12       0.00      0.00      0.00       112\n",
            "          13       0.03      0.60      0.06        20\n",
            "          14       0.24      0.06      0.09       958\n",
            "          15       0.00      0.00      0.00        19\n",
            "          16       0.03      0.12      0.04        17\n",
            "          17       0.00      0.00      0.00       162\n",
            "          18       0.17      0.07      0.10       287\n",
            "          19       0.07      0.31      0.12       197\n",
            "\n",
            "    accuracy                           0.11      4935\n",
            "   macro avg       0.11      0.13      0.08      4935\n",
            "weighted avg       0.16      0.11      0.10      4935\n",
            "\n",
            "==================================================\n",
            "Training Gaussian Mixture Model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Gaussian Mixture Model Results:\n",
            "Accuracy: 0.05126646403242148\n",
            "Confusion Matrix:\n",
            "[[ 31   2   1  20  25   2   1   4   2   1   2   0   2  13   2   1  12   1\n",
            "    2   0]\n",
            " [ 51   8  10 131  20   2  19  27  10   1  28   5  15  73   8   5  30   3\n",
            "   31   3]\n",
            " [ 46   0   2  31  86   2   6   4   0   2   9   5   0   9   9   2   9   2\n",
            "   22   1]\n",
            " [ 19   5   7  27  23   8   4   4   2   3  39  20   1  16   2  20   3   1\n",
            "   10   0]\n",
            " [ 36   6  47  27  23  29   5  24   4   4  60  40   7  32   7  49  13   2\n",
            "   14   0]\n",
            " [ 24   3  31  35  19  11   1  22   1   4  27  23   8  45   3  30   6   2\n",
            "   12   0]\n",
            " [  4   1   2   4   6   2   0   2   0   0   9   6   3   4   0   0   0   0\n",
            "    6   0]\n",
            " [ 40   8   6  35  27   4   5  24   1   0  41   6   9  42  10  19  32   4\n",
            "   24   1]\n",
            " [ 22   4  17  10  18  14   1   4   1   0  20  25   2  14   1  30   2   0\n",
            "    4   0]\n",
            " [ 22   3   5   6  19  10   3   1   0   0  24  19   0   8   0  25   0   1\n",
            "   10   1]\n",
            " [ 53  10  66  50  49  19   7  21   4  11  84  47  14  32   7  75  14   3\n",
            "   27   0]\n",
            " [  1   1   5   7   3   0   0   1   0   0   5   4   0   2   0   2   1   2\n",
            "    2   0]\n",
            " [ 29   2   1  10  22   2   1   4   1   0   6   4   3   7   1   5   7   2\n",
            "    5   0]\n",
            " [  0   0   1   2   0   0   0   0   0   0   1  10   0   0   0   6   0   0\n",
            "    0   0]\n",
            " [163  20  14 140 231  13   9  12   7   5  59  22  21  70  26  50  41   8\n",
            "   46   1]\n",
            " [  5   0   1   0   3   0   0   0   0   0   1   0   3   0   0   2   2   0\n",
            "    2   0]\n",
            " [  0   2   0   3   2   0   0   1   1   0   3   1   0   2   0   1   1   0\n",
            "    0   0]\n",
            " [ 36   3   5  17  19   4   2   5   0   2  16  10   0   9   6  12   7   2\n",
            "    7   0]\n",
            " [ 31  10   2  67  55   3   5  15   2   1  14  11   9  21   9  15  13   1\n",
            "    3   0]\n",
            " [ 32   0   4  21  65   1   1   7   0   0   9   4   1   9   7  10  11   2\n",
            "   12   1]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.05      0.25      0.08       124\n",
            "           1       0.09      0.02      0.03       480\n",
            "           2       0.01      0.01      0.01       247\n",
            "           3       0.04      0.13      0.06       214\n",
            "           4       0.03      0.05      0.04       429\n",
            "           5       0.09      0.04      0.05       307\n",
            "           6       0.00      0.00      0.00        49\n",
            "           7       0.13      0.07      0.09       338\n",
            "           8       0.03      0.01      0.01       189\n",
            "           9       0.00      0.00      0.00       157\n",
            "          10       0.18      0.14      0.16       593\n",
            "          11       0.02      0.11      0.03        36\n",
            "          12       0.03      0.03      0.03       112\n",
            "          13       0.00      0.00      0.00        20\n",
            "          14       0.27      0.03      0.05       958\n",
            "          15       0.01      0.11      0.01        19\n",
            "          16       0.00      0.06      0.01        17\n",
            "          17       0.06      0.01      0.02       162\n",
            "          18       0.01      0.01      0.01       287\n",
            "          19       0.12      0.01      0.01       197\n",
            "\n",
            "    accuracy                           0.05      4935\n",
            "   macro avg       0.06      0.05      0.03      4935\n",
            "weighted avg       0.11      0.05      0.05      4935\n",
            "\n",
            "==================================================\n",
            "Training K-nearest Neighbors...\n",
            "\n",
            "K-nearest Neighbors Results:\n",
            "Accuracy: 0.34812563323201623\n",
            "Confusion Matrix:\n",
            "[[ 27  14   6   0   5   7   0  10   0   1   9   1   3   0  31   0   0   2\n",
            "    2   6]\n",
            " [ 13 290  10  13  14   2   2  20   4   5  16   1   5   0  60   0   1   3\n",
            "   13   8]\n",
            " [ 10  19  98  15   7   6   0  11   3   3  14   0   4   1  49   1   0   0\n",
            "    3   3]\n",
            " [  5  10  14  73  26   5   2   8   4   5  14   1   1   1  31   1   0   5\n",
            "    4   4]\n",
            " [  9  25   7  18 179  17   1  22  12   9  57   3   1   1  46   0   0   3\n",
            "    6  13]\n",
            " [ 11  20   9  16  31 108   0   9  10   5  24   0   2   1  45   1   0   7\n",
            "    4   4]\n",
            " [  1   3   3   2   3   2   9   1   2   0   3   1   2   0  11   0   0   1\n",
            "    2   3]\n",
            " [ 19  47  11  14  25  12   2  87   2   2  43   0   5   0  56   0   0   2\n",
            "    5   6]\n",
            " [  5  12  11  12  24  13   0   2  50   5  16   0   1   1  31   0   0   4\n",
            "    1   1]\n",
            " [  8  11  11   6  14   4   0   4  15  49  15   0   0   0  17   0   0   1\n",
            "    2   0]\n",
            " [ 29  56  24  20  86  25   4  31  21  12 192   0   2   1  72   0   0   6\n",
            "    4   8]\n",
            " [  1   2   3   0   4   3   1   3   5   2   6   4   0   0   2   0   0   0\n",
            "    0   0]\n",
            " [  3   7   8   7  17   3   0   8   2   2   5   0  13   0  29   0   0   3\n",
            "    0   5]\n",
            " [  0   0   0   0   4   2   0   0   3   0   3   0   0   7   0   0   0   1\n",
            "    0   0]\n",
            " [ 40  78  69  27  51  27   4  39  19  12  81   0   9   1 453   2   0  12\n",
            "   15  19]\n",
            " [  3   0   2   0   1   1   0   3   1   0   2   0   0   0   4   1   0   0\n",
            "    0   1]\n",
            " [  0   2   1   2   0   1   0   1   0   1   0   0   0   0   5   0   1   0\n",
            "    3   0]\n",
            " [  9  16  17   4  19   5   2  12   5   1  20   0   4   1  36   0   0   8\n",
            "    2   1]\n",
            " [ 10  36  19  11  13  12   1   7   9   2  28   0   0   1  83   0   0   2\n",
            "   47   6]\n",
            " [  8  11  14   7  12  10   0   9   4   4  17   0   0   0  69   0   0   6\n",
            "    4  22]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.13      0.22      0.16       124\n",
            "           1       0.44      0.60      0.51       480\n",
            "           2       0.29      0.40      0.34       247\n",
            "           3       0.30      0.34      0.32       214\n",
            "           4       0.33      0.42      0.37       429\n",
            "           5       0.41      0.35      0.38       307\n",
            "           6       0.32      0.18      0.23        49\n",
            "           7       0.30      0.26      0.28       338\n",
            "           8       0.29      0.26      0.28       189\n",
            "           9       0.41      0.31      0.35       157\n",
            "          10       0.34      0.32      0.33       593\n",
            "          11       0.36      0.11      0.17        36\n",
            "          12       0.25      0.12      0.16       112\n",
            "          13       0.44      0.35      0.39        20\n",
            "          14       0.40      0.47      0.43       958\n",
            "          15       0.17      0.05      0.08        19\n",
            "          16       0.50      0.06      0.11        17\n",
            "          17       0.12      0.05      0.07       162\n",
            "          18       0.40      0.16      0.23       287\n",
            "          19       0.20      0.11      0.14       197\n",
            "\n",
            "    accuracy                           0.35      4935\n",
            "   macro avg       0.32      0.26      0.27      4935\n",
            "weighted avg       0.34      0.35      0.34      4935\n",
            "\n",
            "==================================================\n",
            "Training Discriminant Analysis...\n",
            "\n",
            "Discriminant Analysis Results:\n",
            "Accuracy: 0.22695035460992907\n",
            "Confusion Matrix:\n",
            "[[  4  14   0   0   1   0   1   2   0   2   5   1   0   1  90   0   0   0\n",
            "    2   1]\n",
            " [  3 113   9   0  26   1   1  10   0   7  51   0   0   1 238   0   0   0\n",
            "   19   1]\n",
            " [  0  24  14   0   2   0   1   3   1   2  10   0   0   0 188   0   2   0\n",
            "    0   0]\n",
            " [  0  20   2   0  21   1   0   3   4   8  52   0   0  10  93   0   0   0\n",
            "    0   0]\n",
            " [  4  21   3   1  63   4   2  11   5  15 132   2   0  13 151   0   1   0\n",
            "    1   0]\n",
            " [  1  32   0   1  24   1   1   4   2  11  86   0   0  10 132   0   1   0\n",
            "    1   0]\n",
            " [  0   7   0   0   2   1   0   0   2   3  10   0   0   4  19   0   0   0\n",
            "    1   0]\n",
            " [  0  48   3   1  10   2   0  14   1   3  70   0   0   0 185   0   0   0\n",
            "    0   1]\n",
            " [  0  19   2   0  31   1   2   3   6   7  54   3   0   6  53   0   1   0\n",
            "    1   0]\n",
            " [  0   4   0   1  12   0   2   0   2  35  33   1   0   4  63   0   0   0\n",
            "    0   0]\n",
            " [  3  43   5   3  64   3   3   9   8  19 183   0   0  15 233   0   1   0\n",
            "    1   0]\n",
            " [  0   1   0   0   0   0   0   0   1   4  16   0   0   0  14   0   0   0\n",
            "    0   0]\n",
            " [  0  17   0   0   6   0   1   0   0   3   8   0   0   4  73   0   0   0\n",
            "    0   0]\n",
            " [  0   0   0   0   2   0   0   0   2   3   5   0   0   4   3   0   0   0\n",
            "    1   0]\n",
            " [  3  99  10   1  24   1   2  11   3  11  96   2   1   9 672   0   0   0\n",
            "   13   0]\n",
            " [  0   2   0   0   0   0   0   0   1   0   3   0   0   0  13   0   0   0\n",
            "    0   0]\n",
            " [  0   4   0   1   0   0   0   0   0   2   1   0   0   1   8   0   0   0\n",
            "    0   0]\n",
            " [  0   8   2   0   9   0   1   2   0   6  20   3   0   5 105   0   0   0\n",
            "    1   0]\n",
            " [  0  27   1   0   2   2   0   3   2   5  18   1   0   5 208   0   1   0\n",
            "   11   1]\n",
            " [  0  12   3   0   9   2   0   2   1   3   9   0   0   3 153   0   0   0\n",
            "    0   0]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.22      0.03      0.06       124\n",
            "           1       0.22      0.24      0.23       480\n",
            "           2       0.26      0.06      0.09       247\n",
            "           3       0.00      0.00      0.00       214\n",
            "           4       0.20      0.15      0.17       429\n",
            "           5       0.05      0.00      0.01       307\n",
            "           6       0.00      0.00      0.00        49\n",
            "           7       0.18      0.04      0.07       338\n",
            "           8       0.15      0.03      0.05       189\n",
            "           9       0.23      0.22      0.23       157\n",
            "          10       0.21      0.31      0.25       593\n",
            "          11       0.00      0.00      0.00        36\n",
            "          12       0.00      0.00      0.00       112\n",
            "          13       0.04      0.20      0.07        20\n",
            "          14       0.25      0.70      0.37       958\n",
            "          15       0.00      0.00      0.00        19\n",
            "          16       0.00      0.00      0.00        17\n",
            "          17       0.00      0.00      0.00       162\n",
            "          18       0.21      0.04      0.06       287\n",
            "          19       0.00      0.00      0.00       197\n",
            "\n",
            "    accuracy                           0.23      4935\n",
            "   macro avg       0.11      0.10      0.08      4935\n",
            "weighted avg       0.17      0.23      0.16      4935\n",
            "\n",
            "==================================================\n",
            "Training Support Vector Machine...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Support Vector Machine Results:\n",
            "Accuracy: 0.30131712259371835\n",
            "Confusion Matrix:\n",
            "[[  0   6   0   0   1   0   0   2   0   0   6   0   0   0 108   0   0   0\n",
            "    1   0]\n",
            " [  0 225   4   0  17   1   0   5   0   3  39   0   0   0 185   0   0   0\n",
            "    1   0]\n",
            " [  0   9   9   0   0   0   0   3   0   1  19   0   0   0 206   0   0   0\n",
            "    0   0]\n",
            " [  0  18   0   2  22   0   0   1   3   0  67   0   0   0 100   0   0   0\n",
            "    1   0]\n",
            " [  0  29   0   1 119   0   0   3   1   1 130   0   0   1 144   0   0   0\n",
            "    0   0]\n",
            " [  0  30   0   0  22  17   0   8   0   0 113   0   0   0 117   0   0   0\n",
            "    0   0]\n",
            " [  0   7   0   0   3   0   0   3   0   0  15   0   0   0  20   0   0   0\n",
            "    1   0]\n",
            " [  0  40   1   0  19   2   0  24   0   0  71   0   0   0 180   0   0   0\n",
            "    1   0]\n",
            " [  0  18   0   0  41   1   0   2   7   2  63   0   0   1  53   0   0   0\n",
            "    1   0]\n",
            " [  0  17   0   0  21   0   0   1   1  14  43   0   0   0  60   0   0   0\n",
            "    0   0]\n",
            " [  0  40   0   0  53   2   0   9   4   1 263   0   0   0 220   0   0   0\n",
            "    1   0]\n",
            " [  0   1   0   0   5   0   0   1   0   0  16   1   0   0  12   0   0   0\n",
            "    0   0]\n",
            " [  0   7   0   1   5   0   0   1   0   1   8   0   0   0  88   0   0   1\n",
            "    0   0]\n",
            " [  0   1   0   0   1   0   0   0   0   2  12   0   0   2   0   0   0   0\n",
            "    2   0]\n",
            " [  0  46   5   0  27   3   0   7   2   2  91   0   0   1 772   0   0   0\n",
            "    2   0]\n",
            " [  0   1   0   0   1   0   0   1   0   0   3   0   0   0  13   0   0   0\n",
            "    0   0]\n",
            " [  0   2   0   0   0   0   0   1   0   0   3   0   0   0  10   0   0   1\n",
            "    0   0]\n",
            " [  0  10   1   0  14   0   0   1   0   1  31   0   0   0 103   0   0   1\n",
            "    0   0]\n",
            " [  0  38   0   0   9   0   0   1   0   1  31   0   0   0 176   0   0   0\n",
            "   31   0]\n",
            " [  0   8   0   0   5   0   0   2   1   0  25   0   0   0 155   0   0   0\n",
            "    1   0]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       124\n",
            "           1       0.41      0.47      0.44       480\n",
            "           2       0.45      0.04      0.07       247\n",
            "           3       0.50      0.01      0.02       214\n",
            "           4       0.31      0.28      0.29       429\n",
            "           5       0.65      0.06      0.10       307\n",
            "           6       0.00      0.00      0.00        49\n",
            "           7       0.32      0.07      0.12       338\n",
            "           8       0.37      0.04      0.07       189\n",
            "           9       0.48      0.09      0.15       157\n",
            "          10       0.25      0.44      0.32       593\n",
            "          11       1.00      0.03      0.05        36\n",
            "          12       0.00      0.00      0.00       112\n",
            "          13       0.40      0.10      0.16        20\n",
            "          14       0.28      0.81      0.42       958\n",
            "          15       0.00      0.00      0.00        19\n",
            "          16       0.00      0.00      0.00        17\n",
            "          17       0.33      0.01      0.01       162\n",
            "          18       0.72      0.11      0.19       287\n",
            "          19       0.00      0.00      0.00       197\n",
            "\n",
            "    accuracy                           0.30      4935\n",
            "   macro avg       0.32      0.13      0.12      4935\n",
            "weighted avg       0.35      0.30      0.23      4935\n",
            "\n",
            "==================================================\n",
            "Training Neural Network...\n",
            "\n",
            "Neural Network Results:\n",
            "Accuracy: 0.33171225937183385\n",
            "Confusion Matrix:\n",
            "[[ 19  12   2   1   0   1   0   4   1   0  10   0   0   0  69   0   0   1\n",
            "    2   2]\n",
            " [  6 242  12   9  17   7   0  11   2   7  21   1   4   1 103   0   0   2\n",
            "   28   7]\n",
            " [  0  11  73   3   5   2   0   3   2   5  14   0   2   0 115   0   0   1\n",
            "    6   5]\n",
            " [  1  23   7  39  15   7   0  11   3   9  30   1   2   2  53   0   0   2\n",
            "    7   2]\n",
            " [  4  24   5  17 122  14   2  20  16  15 108   0   3   0  68   0   0   0\n",
            "    8   3]\n",
            " [  2  18   6   9  30  58   0  11   5   7  79   1   3   2  67   0   0   0\n",
            "    5   4]\n",
            " [  0   4   1   2   4   0   3   2   2   3   5   1   1   0  15   0   0   0\n",
            "    5   1]\n",
            " [  2  45  14  11  22  18   0  41   5   4  64   0   1   0  99   0   1   0\n",
            "    6   5]\n",
            " [  1  15   2   9  24   2   0   9  27   6  41   3   2   0  42   0   0   3\n",
            "    2   1]\n",
            " [  0  12   8   8   5   0   0   1   9  62  19   1   1   0  27   0   2   0\n",
            "    2   0]\n",
            " [  8  42  17  19  65  26   2  18  16  19 209   0   4   0 135   0   0   1\n",
            "    9   3]\n",
            " [  1   4   0   4   3   1   0   1   2   2   4   5   1   0   8   0   0   0\n",
            "    0   0]\n",
            " [  1   6   4   1   4   0   0   2   0   2   8   0  11   0  68   0   0   4\n",
            "    1   0]\n",
            " [  0   1   0   0   1   3   0   0   2   0   5   0   0   6   0   0   0   0\n",
            "    2   0]\n",
            " [ 17  50  40  25  31  13   1  17   8  18  64   1   7   0 627   1   0   4\n",
            "   23  11]\n",
            " [  0   0   0   0   0   0   0   2   1   0   3   0   0   0  13   0   0   0\n",
            "    0   0]\n",
            " [  0   5   3   0   0   1   0   0   1   1   1   0   0   0   3   0   0   2\n",
            "    0   0]\n",
            " [  0  10   5   8   6   3   0   7   2   3  27   1   1   0  80   0   1   3\n",
            "    3   2]\n",
            " [  3  42   4   4   6   5   3   6   3   4  17   0   0   0 114   0   0   2\n",
            "   73   1]\n",
            " [  5   9  10   5   8   4   0   5   2   5  18   0   1   0  97   0   1   3\n",
            "    7  17]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.15      0.20       124\n",
            "           1       0.42      0.50      0.46       480\n",
            "           2       0.34      0.30      0.32       247\n",
            "           3       0.22      0.18      0.20       214\n",
            "           4       0.33      0.28      0.31       429\n",
            "           5       0.35      0.19      0.25       307\n",
            "           6       0.27      0.06      0.10        49\n",
            "           7       0.24      0.12      0.16       338\n",
            "           8       0.25      0.14      0.18       189\n",
            "           9       0.36      0.39      0.38       157\n",
            "          10       0.28      0.35      0.31       593\n",
            "          11       0.33      0.14      0.20        36\n",
            "          12       0.25      0.10      0.14       112\n",
            "          13       0.55      0.30      0.39        20\n",
            "          14       0.35      0.65      0.45       958\n",
            "          15       0.00      0.00      0.00        19\n",
            "          16       0.00      0.00      0.00        17\n",
            "          17       0.11      0.02      0.03       162\n",
            "          18       0.39      0.25      0.31       287\n",
            "          19       0.27      0.09      0.13       197\n",
            "\n",
            "    accuracy                           0.33      4935\n",
            "   macro avg       0.28      0.21      0.23      4935\n",
            "weighted avg       0.31      0.33      0.30      4935\n",
            "\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Assuming 'models' and 'results' are defined from your previous code\n",
        "\n",
        "# Extract accuracy for each model\n",
        "model_names = list(models.keys())\n",
        "accuracies = [results[model_name]['accuracy'] for model_name in model_names]\n",
        "\n",
        "# Plotting\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "bars = ax.bar(model_names, accuracies, color='blue')\n",
        "\n",
        "# Add labels and title\n",
        "ax.set_ylabel('Accuracy')\n",
        "ax.set_title('Model Performance Comparison')\n",
        "\n",
        "# Rotate the x-axis labels vertically\n",
        "plt.xticks(rotation=90)\n",
        "\n",
        "# Add data values on top of the bars\n",
        "for bar, accuracy in zip(bars, accuracies):\n",
        "    yval = round(accuracy, 2)\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 2), ha='center', va='bottom', color='black', fontsize=10)\n",
        "\n",
        "# Show the plot\n",
        "plt.ylim(0, 1)  # Set the y-axis limit between 0 and 1 for accuracy\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "id": "BnutfSm-H4bO",
        "outputId": "97a12caa-070b-4672-a16b-a0ad89f3e285"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_rHxrfEvH4uB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PXtijTy88z7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'data' is your DataFrame with 'Category' as one of the columns\n",
        "\n",
        "# Specify the categories you want to keep\n",
        "selected_categories = [14, 10, 1, 4, 7, 18, 19]\n",
        "\n",
        "# Use boolean indexing to filter the dataset\n",
        "filtered_data = data[data['Category'].isin(selected_categories)]\n",
        "\n",
        "data = filtered_data"
      ],
      "metadata": {
        "id": "kr54XXE1kj4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBD5c-Orxha_",
        "outputId": "b77a222e-e2c3-438a-85e8-f184869ac527"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "333/333 [==============================] - 3s 5ms/step - loss: 1.9694 - accuracy: 0.2953 - val_loss: 1.6733 - val_accuracy: 0.3835\n",
            "Epoch 2/100\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 1.7047 - accuracy: 0.3472 - val_loss: 1.6484 - val_accuracy: 0.3813\n",
            "Epoch 3/100\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 1.6662 - accuracy: 0.3625 - val_loss: 1.6264 - val_accuracy: 0.3805\n",
            "Epoch 4/100\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 1.6446 - accuracy: 0.3802 - val_loss: 1.5883 - val_accuracy: 0.4106\n",
            "Epoch 5/100\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 1.6241 - accuracy: 0.3806 - val_loss: 1.5800 - val_accuracy: 0.4117\n",
            "Epoch 6/100\n",
            "333/333 [==============================] - 2s 5ms/step - loss: 1.6049 - accuracy: 0.3920 - val_loss: 1.5585 - val_accuracy: 0.4256\n",
            "Epoch 7/100\n",
            "333/333 [==============================] - 2s 7ms/step - loss: 1.6001 - accuracy: 0.3956 - val_loss: 1.5611 - val_accuracy: 0.4252\n",
            "Epoch 8/100\n",
            "333/333 [==============================] - 3s 8ms/step - loss: 1.5917 - accuracy: 0.3977 - val_loss: 1.5444 - val_accuracy: 0.4298\n",
            "Epoch 9/100\n",
            "333/333 [==============================] - 2s 7ms/step - loss: 1.5775 - accuracy: 0.3992 - val_loss: 1.5286 - val_accuracy: 0.4384\n",
            "Epoch 10/100\n",
            "333/333 [==============================] - 2s 5ms/step - loss: 1.5789 - accuracy: 0.4048 - val_loss: 1.5373 - val_accuracy: 0.4226\n",
            "Epoch 11/100\n",
            "333/333 [==============================] - 2s 5ms/step - loss: 1.5637 - accuracy: 0.4092 - val_loss: 1.5484 - val_accuracy: 0.4335\n",
            "Epoch 12/100\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 1.5629 - accuracy: 0.4043 - val_loss: 1.5286 - val_accuracy: 0.4301\n",
            "Epoch 13/100\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 1.5553 - accuracy: 0.4149 - val_loss: 1.5171 - val_accuracy: 0.4421\n",
            "Epoch 14/100\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 1.5422 - accuracy: 0.4174 - val_loss: 1.5109 - val_accuracy: 0.4440\n",
            "Epoch 15/100\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 1.5392 - accuracy: 0.4196 - val_loss: 1.5124 - val_accuracy: 0.4391\n",
            "Epoch 16/100\n",
            "333/333 [==============================] - 2s 5ms/step - loss: 1.5398 - accuracy: 0.4209 - val_loss: 1.5096 - val_accuracy: 0.4410\n",
            "Epoch 17/100\n",
            "333/333 [==============================] - 4s 12ms/step - loss: 1.5304 - accuracy: 0.4223 - val_loss: 1.5172 - val_accuracy: 0.4508\n",
            "Epoch 18/100\n",
            "333/333 [==============================] - 3s 9ms/step - loss: 1.5239 - accuracy: 0.4265 - val_loss: 1.4962 - val_accuracy: 0.4523\n",
            "Epoch 19/100\n",
            "333/333 [==============================] - 2s 7ms/step - loss: 1.5266 - accuracy: 0.4255 - val_loss: 1.4962 - val_accuracy: 0.4493\n",
            "Epoch 20/100\n",
            "333/333 [==============================] - 2s 5ms/step - loss: 1.5150 - accuracy: 0.4271 - val_loss: 1.4898 - val_accuracy: 0.4504\n",
            "Epoch 21/100\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 1.5197 - accuracy: 0.4326 - val_loss: 1.4898 - val_accuracy: 0.4545\n",
            "Epoch 22/100\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 1.5092 - accuracy: 0.4337 - val_loss: 1.4972 - val_accuracy: 0.4474\n",
            "Epoch 23/100\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 1.5085 - accuracy: 0.4343 - val_loss: 1.4906 - val_accuracy: 0.4553\n",
            "Epoch 24/100\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 1.5057 - accuracy: 0.4344 - val_loss: 1.4881 - val_accuracy: 0.4613\n",
            "Epoch 25/100\n",
            "333/333 [==============================] - 2s 5ms/step - loss: 1.4946 - accuracy: 0.4373 - val_loss: 1.4794 - val_accuracy: 0.4594\n",
            "Epoch 26/100\n",
            "333/333 [==============================] - 2s 5ms/step - loss: 1.4930 - accuracy: 0.4415 - val_loss: 1.4750 - val_accuracy: 0.4553\n",
            "Epoch 27/100\n",
            "333/333 [==============================] - 5s 14ms/step - loss: 1.4886 - accuracy: 0.4415 - val_loss: 1.4787 - val_accuracy: 0.4572\n",
            "Epoch 28/100\n",
            "333/333 [==============================] - 6s 17ms/step - loss: 1.4868 - accuracy: 0.4397 - val_loss: 1.4779 - val_accuracy: 0.4666\n",
            "Epoch 29/100\n",
            "333/333 [==============================] - 3s 9ms/step - loss: 1.4852 - accuracy: 0.4433 - val_loss: 1.4686 - val_accuracy: 0.4598\n",
            "Epoch 30/100\n",
            "333/333 [==============================] - 2s 7ms/step - loss: 1.4787 - accuracy: 0.4453 - val_loss: 1.4731 - val_accuracy: 0.4699\n",
            "Epoch 31/100\n",
            "333/333 [==============================] - 2s 5ms/step - loss: 1.4746 - accuracy: 0.4437 - val_loss: 1.4761 - val_accuracy: 0.4609\n",
            "Epoch 32/100\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 1.4660 - accuracy: 0.4443 - val_loss: 1.4770 - val_accuracy: 0.4591\n",
            "Epoch 33/100\n",
            "333/333 [==============================] - 2s 5ms/step - loss: 1.4775 - accuracy: 0.4457 - val_loss: 1.4693 - val_accuracy: 0.4617\n",
            "Epoch 34/100\n",
            "333/333 [==============================] - 4s 12ms/step - loss: 1.4687 - accuracy: 0.4474 - val_loss: 1.4670 - val_accuracy: 0.4579\n",
            "Epoch 35/100\n",
            "333/333 [==============================] - 5s 14ms/step - loss: 1.4659 - accuracy: 0.4547 - val_loss: 1.4669 - val_accuracy: 0.4557\n",
            "Epoch 36/100\n",
            "333/333 [==============================] - 4s 12ms/step - loss: 1.4605 - accuracy: 0.4526 - val_loss: 1.4492 - val_accuracy: 0.4696\n",
            "Epoch 37/100\n",
            "333/333 [==============================] - 2s 7ms/step - loss: 1.4620 - accuracy: 0.4504 - val_loss: 1.4517 - val_accuracy: 0.4748\n",
            "Epoch 38/100\n",
            "333/333 [==============================] - 3s 8ms/step - loss: 1.4569 - accuracy: 0.4526 - val_loss: 1.4616 - val_accuracy: 0.4654\n",
            "Epoch 39/100\n",
            "333/333 [==============================] - 2s 5ms/step - loss: 1.4482 - accuracy: 0.4556 - val_loss: 1.4533 - val_accuracy: 0.4703\n",
            "Epoch 40/100\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 1.4521 - accuracy: 0.4533 - val_loss: 1.4433 - val_accuracy: 0.4756\n",
            "Epoch 41/100\n",
            "333/333 [==============================] - 2s 6ms/step - loss: 1.4539 - accuracy: 0.4517 - val_loss: 1.4382 - val_accuracy: 0.4816\n",
            "Epoch 42/100\n",
            "333/333 [==============================] - 2s 7ms/step - loss: 1.4434 - accuracy: 0.4558 - val_loss: 1.4591 - val_accuracy: 0.4651\n",
            "Epoch 43/100\n",
            "333/333 [==============================] - 2s 7ms/step - loss: 1.4484 - accuracy: 0.4596 - val_loss: 1.4442 - val_accuracy: 0.4688\n",
            "Epoch 44/100\n",
            "333/333 [==============================] - 2s 7ms/step - loss: 1.4341 - accuracy: 0.4639 - val_loss: 1.4456 - val_accuracy: 0.4767\n",
            "Epoch 45/100\n",
            "333/333 [==============================] - 2s 5ms/step - loss: 1.4357 - accuracy: 0.4589 - val_loss: 1.4358 - val_accuracy: 0.4745\n",
            "Epoch 46/100\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 1.4365 - accuracy: 0.4587 - val_loss: 1.4332 - val_accuracy: 0.4715\n",
            "Epoch 47/100\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 1.4370 - accuracy: 0.4627 - val_loss: 1.4305 - val_accuracy: 0.4737\n",
            "Epoch 48/100\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 1.4369 - accuracy: 0.4579 - val_loss: 1.4366 - val_accuracy: 0.4752\n",
            "Epoch 49/100\n",
            "333/333 [==============================] - 2s 5ms/step - loss: 1.4380 - accuracy: 0.4584 - val_loss: 1.4292 - val_accuracy: 0.4812\n",
            "Epoch 50/100\n",
            "333/333 [==============================] - 2s 5ms/step - loss: 1.4214 - accuracy: 0.4643 - val_loss: 1.4374 - val_accuracy: 0.4790\n",
            "Epoch 51/100\n",
            "333/333 [==============================] - 2s 6ms/step - loss: 1.4271 - accuracy: 0.4593 - val_loss: 1.4393 - val_accuracy: 0.4715\n",
            "Epoch 52/100\n",
            "333/333 [==============================] - 2s 7ms/step - loss: 1.4200 - accuracy: 0.4660 - val_loss: 1.4257 - val_accuracy: 0.4760\n",
            "Epoch 53/100\n",
            "333/333 [==============================] - 2s 7ms/step - loss: 1.4254 - accuracy: 0.4649 - val_loss: 1.4260 - val_accuracy: 0.4775\n",
            "Epoch 54/100\n",
            "333/333 [==============================] - 2s 7ms/step - loss: 1.4237 - accuracy: 0.4636 - val_loss: 1.4275 - val_accuracy: 0.4775\n",
            "Epoch 55/100\n",
            "333/333 [==============================] - 2s 5ms/step - loss: 1.4197 - accuracy: 0.4700 - val_loss: 1.4312 - val_accuracy: 0.4722\n",
            "Epoch 56/100\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 1.4134 - accuracy: 0.4646 - val_loss: 1.4184 - val_accuracy: 0.4730\n",
            "Epoch 57/100\n",
            "333/333 [==============================] - 2s 4ms/step - loss: 1.4132 - accuracy: 0.4707 - val_loss: 1.4229 - val_accuracy: 0.4782\n",
            "Epoch 58/100\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 1.4161 - accuracy: 0.4650 - val_loss: 1.4214 - val_accuracy: 0.4692\n",
            "Epoch 59/100\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 1.4078 - accuracy: 0.4727 - val_loss: 1.4278 - val_accuracy: 0.4782\n",
            "Epoch 60/100\n",
            "333/333 [==============================] - 2s 5ms/step - loss: 1.4114 - accuracy: 0.4734 - val_loss: 1.4325 - val_accuracy: 0.4741\n",
            "Epoch 61/100\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 1.4027 - accuracy: 0.4751 - val_loss: 1.4271 - val_accuracy: 0.4733\n",
            "Epoch 62/100\n",
            "333/333 [==============================] - 2s 7ms/step - loss: 1.4027 - accuracy: 0.4767 - val_loss: 1.4271 - val_accuracy: 0.4838\n",
            "Epoch 63/100\n",
            "333/333 [==============================] - 2s 7ms/step - loss: 1.4045 - accuracy: 0.4731 - val_loss: 1.4189 - val_accuracy: 0.4816\n",
            "Epoch 64/100\n",
            "333/333 [==============================] - 2s 7ms/step - loss: 1.3966 - accuracy: 0.4751 - val_loss: 1.4142 - val_accuracy: 0.4827\n",
            "Epoch 65/100\n",
            "333/333 [==============================] - 2s 7ms/step - loss: 1.4008 - accuracy: 0.4732 - val_loss: 1.4286 - val_accuracy: 0.4722\n",
            "Epoch 66/100\n",
            "333/333 [==============================] - 2s 5ms/step - loss: 1.3921 - accuracy: 0.4778 - val_loss: 1.4209 - val_accuracy: 0.4722\n",
            "Epoch 67/100\n",
            "333/333 [==============================] - 2s 5ms/step - loss: 1.3943 - accuracy: 0.4784 - val_loss: 1.4142 - val_accuracy: 0.4816\n",
            "Epoch 68/100\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 1.3897 - accuracy: 0.4781 - val_loss: 1.4118 - val_accuracy: 0.4812\n",
            "Epoch 69/100\n",
            "333/333 [==============================] - 2s 5ms/step - loss: 1.3901 - accuracy: 0.4834 - val_loss: 1.4180 - val_accuracy: 0.4790\n",
            "Epoch 70/100\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 1.3884 - accuracy: 0.4784 - val_loss: 1.4059 - val_accuracy: 0.4895\n",
            "Epoch 71/100\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 1.3823 - accuracy: 0.4832 - val_loss: 1.4040 - val_accuracy: 0.4801\n",
            "Epoch 72/100\n",
            "333/333 [==============================] - 2s 6ms/step - loss: 1.3898 - accuracy: 0.4851 - val_loss: 1.3943 - val_accuracy: 0.4880\n",
            "Epoch 73/100\n",
            "333/333 [==============================] - 2s 7ms/step - loss: 1.3817 - accuracy: 0.4793 - val_loss: 1.4018 - val_accuracy: 0.4865\n",
            "Epoch 74/100\n",
            "333/333 [==============================] - 2s 7ms/step - loss: 1.3805 - accuracy: 0.4798 - val_loss: 1.4172 - val_accuracy: 0.4797\n",
            "Epoch 75/100\n",
            "333/333 [==============================] - 2s 7ms/step - loss: 1.3805 - accuracy: 0.4846 - val_loss: 1.4063 - val_accuracy: 0.4760\n",
            "Epoch 76/100\n",
            "333/333 [==============================] - 2s 5ms/step - loss: 1.3809 - accuracy: 0.4820 - val_loss: 1.4082 - val_accuracy: 0.4820\n",
            "Epoch 77/100\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 1.3932 - accuracy: 0.4773 - val_loss: 1.4057 - val_accuracy: 0.4861\n",
            "Epoch 78/100\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 1.3803 - accuracy: 0.4846 - val_loss: 1.4050 - val_accuracy: 0.4865\n",
            "Epoch 79/100\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 1.3762 - accuracy: 0.4859 - val_loss: 1.4093 - val_accuracy: 0.4846\n",
            "Epoch 80/100\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 1.3801 - accuracy: 0.4830 - val_loss: 1.4068 - val_accuracy: 0.4857\n",
            "Epoch 81/100\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 1.3823 - accuracy: 0.4770 - val_loss: 1.4006 - val_accuracy: 0.4876\n",
            "Epoch 82/100\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 1.3599 - accuracy: 0.4909 - val_loss: 1.4062 - val_accuracy: 0.4831\n",
            "104/104 [==============================] - 0s 2ms/step - loss: 1.4163 - accuracy: 0.4674\n",
            "Test Accuracy: 0.4673880338668823\n",
            "104/104 [==============================] - 0s 2ms/step\n",
            "Confusion Matrix:\n",
            "[[269  24  17  27 128  32   1]\n",
            " [ 20 164  31 122  91   9   4]\n",
            " [ 25  21  68  78 129   2   1]\n",
            " [ 33  96  38 260 198  14   8]\n",
            " [ 56  32  29  94 669  23   9]\n",
            " [ 28  14   8  22 101 108   2]\n",
            " [  9  14   9  21 147   5  17]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.61      0.54      0.57       498\n",
            "           4       0.45      0.37      0.41       441\n",
            "           7       0.34      0.21      0.26       324\n",
            "          10       0.42      0.40      0.41       647\n",
            "          14       0.46      0.73      0.56       912\n",
            "          18       0.56      0.38      0.45       283\n",
            "          19       0.40      0.08      0.13       222\n",
            "\n",
            "    accuracy                           0.47      3327\n",
            "   macro avg       0.46      0.39      0.40      3327\n",
            "weighted avg       0.47      0.47      0.45      3327\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Assuming 'data' is your DataFrame with 32 input features and 'Category' is the target variable\n",
        "# Load and preprocess the data\n",
        "# ... (Assuming you've loaded and preprocessed the data as discussed earlier)\n",
        "\n",
        "# Extract features and labels\n",
        "X = data.iloc[:, :-1].values\n",
        "y = data['Category'].values\n",
        "\n",
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "y = to_categorical(y, num_classes=20)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a more complex deep learning model\n",
        "model = Sequential()\n",
        "model.add(Dense(256, input_dim=X_train.shape[1], activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))  # Additional hidden layer\n",
        "model.add(Dense(20, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "# Introduce early stopping to prevent overfitting\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(f'Test Accuracy: {test_acc}')\n",
        "\n",
        "# Confusion Matrix\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_true, y_pred_classes)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Convert one-hot encoded vectors back to class labels\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "class_names = [str(label) for label in le.classes_]\n",
        "\n",
        "# Classification Report\n",
        "class_report = classification_report(y_true, y_pred_classes, target_names=class_names)\n",
        "print(\"Classification Report:\")\n",
        "print(class_report)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Wpejl4DlExqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pYwQEWsoEyXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mrZuZpR6Eyur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dcY3ntmd1Txe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2QWrBKNN1TcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(f'Test Accuracy: {test_acc}')\n",
        "\n",
        "# Confusion Matrix\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_true, y_pred_classes)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Visualize the confusion matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# ... (Your code for the classification report)\n"
      ],
      "metadata": {
        "id": "sQWIliYe1STY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "id": "Z26uJgOmxuYj",
        "outputId": "cc2995e5-10ba-43ba-97f6-d8d4934ee1ee"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxQAAAK9CAYAAAC95yoDAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACU+0lEQVR4nOzde3zO9f/H8ec15sJmmw07kDM5n8Wcz0Ll1EEpVCihnItKzpNyDMl5kZIikkhOhTknZxEZ7YTFbOzabNf3D7m+u7LNrsvhs/G4f2+f2831eb+vz+t1XfT77bXX+/35mKxWq1UAAAAA4AQXoxMAAAAAkHVRUAAAAABwGgUFAAAAAKdRUAAAAABwGgUFAAAAAKdRUAAAAABwGgUFAAAAAKdRUAAAAABwGgUFAAAAAKdRUABAKk6cOKEWLVrI09NTJpNJ33333V29/l9//SWTyaSFCxfe1etmZY0aNVKjRo2MTgMA4CAKCgCZ1p9//qnXXntNxYsXV86cOeXh4aG6detq6tSpunbt2j2N3bVrVx08eFBjx47VokWLVKNGjXsa737q1q2bTCaTPDw8Uv0eT5w4IZPJJJPJpI8//tjh64eFhWnEiBHav3//XcgWAJDZZTc6AQBIzQ8//KBnnnlGZrNZXbp0UYUKFZSQkKCtW7dq8ODBOnz4sGbPnn1PYl+7dk0hISF699131adPn3sSo0iRIrp27ZpcXV3vyfVvJ3v27Lp69aq+//57Pfvss3ZjX3zxhXLmzKn4+Hinrh0WFqaRI0eqaNGiqlKlSobf99NPPzkVDwBgLAoKAJnO6dOn1alTJxUpUkQbN26Uv7+/bax37946efKkfvjhh3sW//z585IkLy+vexbDZDIpZ86c9+z6t2M2m1W3bl19+eWXtxQUS5YsUZs2bfTtt9/el1yuXr2q3LlzK0eOHPclHgDg7mLJE4BMZ8KECYqNjdW8efPsiombSpYsqbfeesv2+vr16xo9erRKlCghs9msokWLatiwYbJYLHbvK1q0qJ544glt3bpVjz32mHLmzKnixYvr888/t80ZMWKEihQpIkkaPHiwTCaTihYtKunGUqGbf05pxIgRMplMdufWr1+vevXqycvLS+7u7nr00Uc1bNgw23haeyg2btyo+vXry83NTV5eXmrbtq2OHj2aaryTJ0+qW7du8vLykqenp15++WVdvXo17S/2P1544QX9+OOPunTpku3c7t27deLECb3wwgu3zI+OjtagQYNUsWJFubu7y8PDQ61atdLvv/9um7N582bVrFlTkvTyyy/blk7d/JyNGjVShQoVtHfvXjVo0EC5c+e2fS//3UPRtWtX5cyZ85bP37JlS+XNm1dhYWEZ/qwAgHuHggJApvP999+rePHiqlOnTobmd+/eXcOHD1e1atU0efJkNWzYUEFBQerUqdMtc0+ePKmnn35azZs318SJE5U3b15169ZNhw8fliR16NBBkydPliQ9//zzWrRokaZMmeJQ/ocPH9YTTzwhi8WiUaNGaeLEiXrqqae0bdu2dN/3888/q2XLloqKitKIESM0YMAAbd++XXXr1tVff/11y/xnn31WV65cUVBQkJ599lktXLhQI0eOzHCeHTp0kMlk0vLly23nlixZojJlyqhatWq3zD916pS+++47PfHEE5o0aZIGDx6sgwcPqmHDhrYf7suWLatRo0ZJknr27KlFixZp0aJFatCgge06Fy9eVKtWrVSlShVNmTJFjRs3TjW/qVOnKn/+/OratauSkpIkSZ999pl++uknffLJJwoICMjwZwUA3ENWAMhELl++bJVkbdu2bYbm79+/3yrJ2r17d7vzgwYNskqybty40XauSJEiVknWX375xXYuKirKajabrQMHDrSdO336tFWS9aOPPrK7ZteuXa1FihS5JYcPPvjAmvL/nE6ePNkqyXr+/Pk0874ZY8GCBbZzVapUsRYoUMB68eJF27nff//d6uLiYu3Spcst8V555RW7a7Zv397q4+OTZsyUn8PNzc1qtVqtTz/9tLVp06ZWq9VqTUpKsvr5+VlHjhyZ6ncQHx9vTUpKuuVzmM1m66hRo2zndu/efctnu6lhw4ZWSdZZs2alOtawYUO7c+vWrbNKso4ZM8Z66tQpq7u7u7Vdu3a3/YwAgPuHDgWATCUmJkaSlCdPngzNX7NmjSRpwIABducHDhwoSbfstShXrpzq169ve50/f349+uijOnXqlNM5/9fNvRcrV65UcnJyht4THh6u/fv3q1u3bvL29radr1Spkpo3b277nCm9/vrrdq/r16+vixcv2r7DjHjhhRe0efNmRUREaOPGjYqIiEh1uZN0Y9+Fi8uN/7eRlJSkixcv2pZz7du3L8MxzWazXn755QzNbdGihV577TWNGjVKHTp0UM6cOfXZZ59lOBYA4N6joACQqXh4eEiSrly5kqH5Z86ckYuLi0qWLGl33s/PT15eXjpz5ozd+cKFC99yjbx58+qff/5xMuNbPffcc6pbt666d+8uX19fderUSV9//XW6xcXNPB999NFbxsqWLasLFy4oLi7O7vx/P0vevHklyaHP0rp1a+XJk0dLly7VF198oZo1a97yXd6UnJysyZMnq1SpUjKbzcqXL5/y58+vAwcO6PLlyxmOWbBgQYc2YH/88cfy9vbW/v37NW3aNBUoUCDD7wUA3HsUFAAyFQ8PDwUEBOjQoUMOve+/m6LTki1btlTPW61Wp2PcXN9/U65cufTLL7/o559/1ksvvaQDBw7oueeeU/PmzW+Zeyfu5LPcZDab1aFDBwUHB2vFihVpdickady4cRowYIAaNGigxYsXa926dVq/fr3Kly+f4U6MdOP7ccRvv/2mqKgoSdLBgwcdei8A4N6joACQ6TzxxBP6888/FRISctu5RYoUUXJysk6cOGF3PjIyUpcuXbLdseluyJs3r90dkW76bxdEklxcXNS0aVNNmjRJR44c0dixY7Vx40Zt2rQp1WvfzPP48eO3jB07dkz58uWTm5vbnX2ANLzwwgv67bffdOXKlVQ3st/0zTffqHHjxpo3b546deqkFi1aqFmzZrd8Jxkt7jIiLi5OL7/8ssqVK6eePXtqwoQJ2r179127PgDgzlFQAMh0hgwZIjc3N3Xv3l2RkZG3jP/555+aOnWqpBtLdiTdciemSZMmSZLatGlz1/IqUaKELl++rAMHDtjOhYeHa8WKFXbzoqOjb3nvzQe8/fdWtjf5+/urSpUqCg4OtvsB/dChQ/rpp59sn/NeaNy4sUaPHq3p06fLz88vzXnZsmW7pfuxbNky/f3333bnbhY+qRVfjnr77bcVGhqq4OBgTZo0SUWLFlXXrl3T/B4BAPcfD7YDkOmUKFFCS5Ys0XPPPaeyZcvaPSl7+/btWrZsmbp16yZJqly5srp27arZs2fr0qVLatiwoXbt2qXg4GC1a9cuzVuSOqNTp056++231b59e7355pu6evWqPv30U5UuXdpuU/KoUaP0yy+/qE2bNipSpIiioqI0c+ZMFSpUSPXq1Uvz+h999JFatWqlwMBAvfrqq7p27Zo++eQTeXp6asSIEXftc/yXi4uL3nvvvdvOe+KJJzRq1Ci9/PLLqlOnjg4ePKgvvvhCxYsXt5tXokQJeXl5adasWcqTJ4/c3NxUq1YtFStWzKG8Nm7cqJkzZ+qDDz6w3cZ2wYIFatSokd5//31NmDDBoesBAO4NOhQAMqWnnnpKBw4c0NNPP62VK1eqd+/eeuedd/TXX39p4sSJmjZtmm3u3LlzNXLkSO3evVv9+vXTxo0bNXToUH311Vd3NScfHx+tWLFCuXPn1pAhQxQcHKygoCA9+eSTt+ReuHBhzZ8/X71799aMGTPUoEEDbdy4UZ6enmlev1mzZlq7dq18fHw0fPhwffzxx6pdu7a2bdvm8A/j98KwYcM0cOBArVu3Tm+99Zb27dunH374QY888ojdPFdXVwUHBytbtmx6/fXX9fzzz2vLli0Oxbpy5YpeeeUVVa1aVe+++67tfP369fXWW29p4sSJ2rFjx135XACAO2OyOrJ7DwAAAABSoEMBAAAAwGkUFAAAAACcRkEBAAAAwGkUFAAAAACcRkEBAAAAwGkUFAAAAACcRkEBAAAAwGkP5JOyl/8ebmj8lmX9DI3vYjIZGt8q4x5tci76mmGxJam0b25D4wMAgDuXq2ofw2Jf+226YbGdRYcCAAAAgNMeyA4FAAAA4DQTv3N3BN8WAAAAAKdRUAAAAABwGkueAAAAgJQMvsFNVkOHAgAAAIDT6FAAAAAAKbEp2yF8WwAAAACcRocCAAAASIk9FA55KAqKzSu+0KFdv+j836FyzWFWkdLl9fiLryl/QGG7eWf+OKyfvpyrsyePysXFRf5FS+qVdz+Saw6zJGnT8kU6tm+Hwv86qWzZs+uDhT84lc+ypV9q2dIvFR72tySpeImS6vl6b9Wt38BuntVqVd9ePbV926+aOGW6Gjdt5lS8/5o35zNt+Pkn/XX6lMw5c6pylarq13+QihYrfstcq9WqPr16aNvWXzVp6gw1uQs5zJvzmTb+vN4u/lv9B9rFv3DhvKZ8/JF2hGxX3NU4FS1aTK/2fE3Nmrd0ON6h/Xu1/KvP9efxI4q+eEHDxk5SYP3GkqTr1xO1eM5M7dmxVRHh5+Tm5q7KNWqp62tvyidfAds1Th4/quDPpurEscNyccmmOg2b6tXeA5UrN0/GBgAAD7eHYsnTqSP7Fdiynd4YO1OvvvexkpKSNH/MYCXEX7PNOfPHYS0YO0SlKtdQ73GfqnfQLAW2bC9Tigr1+vXrqli7kWq1aHtH+RTw9dWb/Qbqi6XfavFX36hmrdrq/2Zv/XnyhN28LxYF28W/W/bu2aXnnu+sz5d8rVmzF+h64nX16vmqrl29esvcxYuC73qVvm/Pbj33/Av6fMlSfTp7/r/xu9vFf3/o2/rrr9OaMn2mli1fpSbNmuvtgf117OgRh+PFx19TsRKl9Xr/obeMWeLj9eeJo3quaw9Nmfulho6ZqL9Dz2jM0H62ORcvROn9Aa/Lv+Aj+njWIo34aIZCT/+pKUHDnfr8AAAAD5KHokPxyrsf2b1+uvc7Gtu9nf4+9YeKlassSfoheLrqtOqgRu062+b9t4PR/NmXJUl7N/94R/k0bNTE7nWfN/vrm6Vf6eCB31WiZClJ0vFjR7U4eIEWL/1GLRrXv6N4/zXzs3l2r0eNHa8mDQJ15MhhVa9R03b+2LGjWhQ8X0uWfqtmjerdtfgzPptr93rk2CA1bVDHLv7v+/dr2PsfqELFSpKkHq/10hefL9SRw4dVpmw5h+LVqF1PNWqnnr+bex6NnjTL7txr/d7RwNdeVFRkuAr4+mv39l+VPXt2vd5/qFxcbtTgbwx8V31fflZh50IVUKhwapcGAABZFZuyHfJQflvxV2MlSbnc80iSYi//o7MnjsrdM68+fa+3xvZor9kfvKW/jh2457kkJSVp3Y8/6Nq1q6pUuYok6dq1axr29iC98+5w5cuX/57nEBt7RZLk6elpO3ft2jUNGzJQQ+9DDqnFr1ylin5au0aXL19ScnKy1q75QZaEBNV47LF7moskXY27IpPJJPd//30kJiYoe3ZXWzEhSTnMN5bBHTm4/57nAwAAkJkZ2qG4cOGC5s+fr5CQEEVEREiS/Pz8VKdOHXXr1k3589/9H2STk5O1euF0FXm0gvwK31izHx0ZJkn6edlCtX6plwKKltS+Les0d9RA9Zu4QPn8C931PE78cVzdXnxeCQkW5cqdWxOnTFfxEiUlSRMnBKlylapq1KTpXY/7X8nJyfpo/DhVqVpNJUuVtp3/+N8cGje5O/s20ov/cSrxJ0ycorcH9VejurWVPXt25cyZU5OmfKLChYvc03wSLBYtnDVNDZo+rtxu7pKkStUe07zpk7T8y2A9+fQLssRfU/Bn0yRJ/1w8f0/zAQAABmBTtkMMKyh2796tli1bKnfu3GrWrJlKl77xw2RkZKSmTZum8ePHa926dapRo0a617FYLLJYLHbnEhMsto3U/7Vq3hRFnj2t10d9YjtntVolSbWaPakajVtJkgKKldKfh/Zpz6Y1evyFnk5/zrQULVZMX36zQrFXrmjD+nUa/t47mrtgkc6Ghmr3rp36ctnyux4zNUFjRurkyRNa+PkS27nNmzZo184dWvrNivsQf5ROnjyhBSniS9KM6VN15coVzZq7QF5eebV5488aMqi/5gcvVqnSj96TXK5fT9SHHwyR1WrVGwOH2c4XKVZC/YaN0rwZExU8+xO5uLjoyY7Py8vbRyZaogAA4CFnWEHRt29fPfPMM5o1a9YtG4+tVqtef/119e3bVyEhIeleJygoSCNHjrQ79+xrA/Rcr0G3zF05b4qO7QtRz5HT5Onz/zv45MnrI0kqUMj+t9/5CxbRpQtRDn2ujHJ1zWH7bXu58hV0+NAhLVn8ucw5c+rc2VA1rGO/tGfwgDdVtVp1zVmw6K7lEDR2lH7ZslnzgxfL18/Pdn7Xzh06dzZU9QNr2s0f1L+vqlaroXkL704O48eO0q9bNmvef+KfDQ3V0iVf6JvvvrftKXm0TBnt27dXS79covc+GJnWJZ12o5h4W1GR4Ro7ZbatO3FTo+at1Kh5K/0TfVE5c+aSyWTSyq8Xyy/g7nevAAAAshLDCorff/9dCxcuTPUuRiaTSf3791fVqlVve52hQ4dqwIABdud+PB5t99pqtWrV/Kk6smureoyYIu8C/nbjefP7ySNvPp0PO2t3/kL4WT1apVZGP9IdSbYmKzEhQa/37qv2HZ62G3u2w1MaOOQdNWjYJI13O8ZqtWr8uNHauGG95i5YpIKFHrEbf6V7T3Xo+IzduafbP6lBQ4aqYaPGdyX+h+NGa+OGnzVnwecqWMj+h/L4f+++9d/f/mdzcZHVmnzH8f/rZjERdi5U46bOloenV5pz83rfKD7X//CdXHPkUJUate96PgAAwGCsQHCIYQWFn5+fdu3apTJlyqQ6vmvXLvn6+t72OmazWWaz/fIm1xxxdq9Xzpui37f+rJeGjJU5Vy5duXRRkpQzt7tcc5hlMplU/6nn9PPXC+VftIT8i5bUvs3rdP7vUHUe8P/fhl+6EKmrsTG6dCFKycnJCvvrxm1effwKypwz488j+GTKRNWp10D+/v6Ki4vT2jWrtXf3Ls2YNVf58uVPdRO0n1/ALT94O2vcmJH6cc1qTZk2U25ubrpw4cY+AHf3PMqZM2faOfgH3FJ8OCNozCj9uGa1Jk+bkWr8osWK65HCRTRm1AcaMGiIPD29tGnjz9oRsl1TZ8y6zdVvde3qVYX//f9iMTL8b506cVzuHh7y9smn8e8P1p9/HNPwD6cqOSlZ/1y8cCMfD0+5urpKklZ/+5XKVKisXLlza//uHZr/6RR1fa2v3PPkuePvAwAAICszrKAYNGiQevbsqb1796pp06a24iEyMlIbNmzQnDlz9PHHH9+VWDt/WilJmjOin935p994W9Ub3dgzUa/NM7qemKAfgmfoauwV+RcpoVff/1g+fgVt89cvna99W9bZXn8ypIckqccHk1W8/O27KTdFR0dr+Ltv68L583LPk0elSj2qGbPmqnadus5+RIcsW/qlJKn7yy/ZnR85Jkht23W4b/F7vNzlP/HH6al2HeTq6qpPPv1M0yZP1Fu9e+nqtat65JHCGjV2vOo3aOhwvJPHj2jYWz1sr+dNnyhJavL4k3rh5de1c9sWSdKbr3Sye9+4qXNUseqNPTx/HDukJQtm6dq1qypUuKh6D3pXTVo+4XAuAAAgC2BTtkNM1ps7kg2wdOlSTZ48WXv37lVSUpIkKVu2bKpevboGDBigZ5991qnrLv89/G6m6bCWZf1uP+kecjH4PwKrDPsnpXPR124/6R4q7cuTswEAyOpyBb5jWOxrIeMNi+0sQ28b+9xzz+m5555TYmKiLly4scwkX758tmUmAAAAwH3HHgqHZIonZbu6usrf3//2EwEAAABkKpRfAAAAAJyWKToUAAAAQKbBpmyH0KEAAAAA4DQ6FAAAAEBKbMp2CN8WAAAAAKdRUAAAAABwGkueAAAAgJTYlO0QOhQAAAAAnPZAdihalzf2IXmHz8UYGr9sQB5D40fFWAyL7WZ+IP9JAwCA+4lN2Q7h2wIAAADgNH6dCwAAAKREh8IhfFsAAAAAnEZBAQAAAMBpLHkCAAAAUnLhtrGOoEMBAAAAwGl0KAAAAICU2JTtEL4tAAAAAE6joAAAAADgNAoKAAAAICWTybjDAUWLFpXJZLrl6N27tyQpPj5evXv3lo+Pj9zd3dWxY0dFRkbaXSM0NFRt2rRR7ty5VaBAAQ0ePFjXr193KI+Hcg/FvDmfacP6n3T69CmZc+ZUlSpV1W/AIBUtVtw2x2KxaOKE8Vr74xolJCSoTt16evf9D+STL5/D8Y4e3KfVyxbp9IljuhR9Qf0/+Eg16zSyjcdfu6ov503X3pAtuhJzWQX8AtSy7XNq9kRH25y5U8fp0G+79M/FC8qZK5dKl62kTq/2VcHCRR3//HM/08af1+uvfz9/5cpV9Vb/gXaf/+zZUE3+eIJ++22vEhMSVKdufb099D2nPv/B/Xu1bMlCnTh2VNEXz+uDoMmq06CJbXzr5p/1w3fLdOL4UV2JuayZC5aqROkydtdIsFg0e/pEbf55rRITE1T9sTrqO+hd5fX2cTifq3Fxmv/ZdG3dskGX/olWydJl1GfAOypTroIk6ZdNP+v75V/rxLEjiom5rNmLlqnkf/IBAAAw2u7du5WUlGR7fejQITVv3lzPPPOMJKl///764YcftGzZMnl6eqpPnz7q0KGDtm3bJklKSkpSmzZt5Ofnp+3btys8PFxdunSRq6urxo0bl+E8HsoOxZ7du/Tc85216Muv9dmcBbp+/bpe7/Gqrl69apvz0YfjtGXzJn00aYrmBy/S+fNRGvBWH6fiWeKvqUjx0nq5z5BUxxd9NlkH9oTojSGj9PGcr/V4+05aOOMj7Q3ZYptTrFQZvTZwuD6e87XeGfuJrLJq/LA+Sk7xjyij9u3Zrec6vaDPv1iqT2fP1/Xr19Xrte669u/nv3b1qt7o+apMJpNmz12oBZ8vUWJiot7q20vJyckOx4u/dk3FSz6qPgOHpj4ef03lK1XVq736pXmNWdM+0o5tW/TemI/08fT5ir5wXqOGDXA4F0n6eNwH2rsrRENHjNO8L5arRq06Gtynh85HRdryrVi5qnr06e/U9QEAQBZncjHucED+/Pnl5+dnO1avXq0SJUqoYcOGunz5subNm6dJkyapSZMmql69uhYsWKDt27drx44dkqSffvpJR44c0eLFi1WlShW1atVKo0eP1owZM5SQkJDhPB7KDsWns+fZvR41drwa1w/U0SOHVb1GTV25ckUrvv1W4yd8rFq1A2/MGTNO7Z5srQO/71elylUcilelZl1VqVk3zfETRw6ofvM2Kle5uiSpaesO2vDDCv15/IiqBza0nbspv1+Anu3aS+/0ekHnI8PlG1DIoXxmzJpr93rkmCA1bVhHR/79/Pv371NY2N/6ctkKubu7S7rxHTWs+5h27dyh2oF1HIpXM7CeagbWS3O82eNPSpIiwv9OdTwu9orWrV6hd0aMV5XqtSRJA94dpR4vtNPRQwdUtkKlDOdiiY/XL5t+1pgJ01S5ag1JUrcebyjk181atXypXn39TbVo/W8+YannAwAAcK9YLBZZLBa7c2azWWazOd33JSQkaPHixRowYIBMJpP27t2rxMRENWvWzDanTJkyKly4sEJCQlS7dm2FhISoYsWK8vX1tc1p2bKlevXqpcOHD6tq1aoZyvmh7FD8V+yVK5IkD09PSdKRw4d0/XqiaqX4wblY8RLy9w/Q7/v33/X4pcpV0r4dvyj6QpSsVqsO79+jiL9DVfHfH57/Kz7+mrb89L3y+wXIJ79vqnMcERt74/N7/vv5ExISZDKZlCNHDtscs9ksFxcX7f9t7x3Hc9SJ40d0/fp1Va3x/++jcJFiKuDrr6OHfnfoWklJSUpOSlIOcw6782ZzTh36/be7ki8AAMjiDNxDERQUJE9PT7sjKCjotil/9913unTpkrp16yZJioiIUI4cOeTl5WU3z9fXVxEREbY5KYuJm+M3xzIqU3cozp49qw8++EDz589Pc05qVZw12+2ruJuSk5M14cNxqlK1mkqVKi1JunjhglxdXeXh4WE319vHRxcunHfwU9xetzcGa+7UcerTuY2yZcsmk4uLur/1rspWrGY3b/33y7Rk7ieyxF+Tf6EiGhY0Q9ldXe8odnJysj7+9/OX/PfzV6xURbly5dLUyR+rz5v9JatVU6dMVFJSki6cv/uf/3aiL16Uq6ur3PPY/314eXsrOvqCQ9fK7eamchUra9H8z1S4aHHl9fbRxp/W6Mih3xVQqPDdTBsAAMBhQ4cO1YAB9su6M/Jz7bx589SqVSsFBATcq9TSlKk7FNHR0QoODk53TmpV3Ecf3r6Ku2ncmJH688QJTfh48p2m67R1K5fq5LGDGjhyosZOX6TOPfpp4YwJOrhvp928uk1aadzMxXr/48/kX6iwpo4dqoQESxpXzZigsaN08uQJjZ8wyXbO29tbEyZO0S+bN6lurWqqX6emYq9cUdmy5WRyydT/ZDJk6IggWa1WPftEU7WsX13Lv16iJi1aycXFsTsrAAAA3G1ms1keHh52x+0KijNnzujnn39W9+7dbef8/PyUkJCgS5cu2c2NjIyUn5+fbc5/7/p08/XNORlhaIdi1apV6Y6fOnXqttdIrYqzZstYd2LcmFH6ZctmzQ9eLN8UX5pPvnxKTExUTEyMXZci+uJF5cuXP0PXzqgES7yWLpypAcM/UtVaN/YZFC5eSmdO/aEfvlmsitX+v8wnt5u7cru5y79gYZUqU1E9OjbRnm2bVadxS6dijx87Sr9u2ax5C+0/vyQF1qmn739cr3/++UfZs2VTHg8PNWtUTy0LPeL8h3WSt4+PEhMTFXslxq5LcSk6Wt7ejt91qmChRzRl1kJdu3ZVV+Pi5JMvv0a9O0j+Du5FAQAAD6gs9qTsBQsWqECBAmrTpo3tXPXq1eXq6qoNGzaoY8cbdw49fvy4QkNDFRh4Y49wYGCgxo4dq6ioKBUoUECStH79enl4eKhcuXIZjm9oQdGuXTuZTCZZrdY055hucz/e1DapxN/m1rlWq1VBY0dr44b1mrdwkQr954fkcuUrKHt2V+3aEaJmLW78sP7X6VMKDw9T5SpV0r+4g65fv66k69dl+s9vx11cXNL9XqxWq6yyKjEx4zvwU773w3GjtXHjz5oz/3MVLJT2D9J58+aVJO3auUPR0RfVsFFjh+PdqVKPllP27Nn1255dqt/4xsais2f+UlRkuMpWqOz0dXPlyq1cuXLrSsxl7d6xXa9xVycAAJDFJCcna8GCBeratauyZ///j/aenp569dVXNWDAAHl7e8vDw0N9+/ZVYGCgateuLUlq0aKFypUrp5deekkTJkxQRESE3nvvPfXu3TvD2wckgwsKf39/zZw5U23btk11fP/+/apevfpdjztu9Ej9uGa1pnwyU2653Wz7Atzz5FHOnDmVJ08ete/YUR9PGC8PT0+5u7tr/LgxqlylqsN3eJJuPGciIuys7fX5iDD99edxuefxVL4CfipbqZqWzJmmHDlyKp+vn44e2Kdff16jF3v2kyRFhp/Tji3rVbF6bXl45lX0+Uit+jpYOXLkVJXH0r57VFqCxo7Sj2tWa/LUGXJzc7PtC3F3v/H5JWnlim9VrHgJ5fX21oH9+/XRh2PV+aWuds+qyKhrV68q7Fyo7XVE2N/6849jyuPhqQJ+/oqJuazzEeG6+G8eZ0P/kiTl9cknb598cnPPo5ZPtNfsTz5WHg8Pubm5a8bk8SpbobJDd3i6afeObbJarXqkSFH9fTZUn30ySYWLFNPjT7aTJMVcvqyoyHBdOB91I58zN/Lx/jcfAADwgHPwAXNG+vnnnxUaGqpXXnnllrHJkyfLxcVFHTt2lMViUcuWLTVz5kzbeLZs2bR69Wr16tVLgYGBcnNzU9euXTVq1CiHcjBZ0/s1+D321FNPqUqVKmkm/fvvv6tq1aoOP/vgdh2KyuUfTfX8qDFBatv+xu1Zbz7Y7sc1Pygh8d8H2733gfLlv/2Sp8PnYuxeH/l9r8YMef2WeQ2at9Hrg0boUvQFfTV/hg7u26nYKzHKV8BPTVq3V+sOL8hkMumfi+c1e/IYnT5xTHGxMfL08laZilXVoXN3BTxS9Jbrlg3Ik25+VSum/pC2kaPH6al2Nz7/1MkT9f3KFbp8+bICCgbo6Wc66cUu3W7bMZKkqBj7fR2/79utIX273zKveaunNOi90frph5WaOG74LeMvvvK6Xnq1l6T/P9hu0/oflZiYoBqP1VGfQe/e8gO+a/bbtyg3/7xWc2ZO1YWoSOXx8FT9xs30aq835e5+43tbu/o7TRj9/i3v69K9l7r1eCPdaxf0ypHuOAAAyPxytfzYsNjX1g0yLLazDC0ofv31V8XFxenxxx9PdTwuLk579uxRw4YNHbru7QqKe+2/BcX9druC4l77b0FxP2WkoLiXKCgAAMj6KCgcY+iSp/r166c77ubm5nAxAQAAANyRLLYp22h8WwAAAACclqkfbAcAAADcd1loU3ZmQIcCAAAAgNPoUAAAAAApsYfCIXxbAAAAAJxGQQEAAADAaSx5AgAAAFJiU7ZD6FAAAAAAcBodCgAAACAlNmU75IEsKKxWY+OXK+hhaPzL1xINjZ8nl3H/rC5fvW5YbAAAgIcR5RcAAAAApz2QHQoAAADAaSx5cgjfFgAAAACn0aEAAAAAUuK2sQ6hQwEAAADAaRQUAAAAAJzGkicAAAAgJTZlO4RvCwAAAIDT6FAAAAAAKbEp2yEPZUExb85n2vDzT/rr9CmZc+ZU5SpV1a//IBUtVvyWuVarVX169dC2rb9q0tQZatK0WZaPn5SUpIWzZ+qntasVffGC8uXLr8efaKcur74m07//AVmtVs3/bIZWf/eNYmOvqGKlqhrwzvsqVLjIHceXpPNRkZoxdZJ2bP9V8fHxKvRIYb07YozKlqsgSZo7a4Z+/ulHRUVEyNXVVY+WLafXer+l8hUrORzr4P69+mbJQp08flTRF8/r/XGTVadBE9v4ti0/64fvlunk8aO6EnNZ0xcsVYlSZeyuMaTPqzq4f4/dudZtn1bfwe878ekBAAAeHA9lQbF3zy4993xnla9QUUnXk/TJ1Enq1fNVLV/5g3Llzm03d/Gi4LtepRodf8nn87Ty26UaOmKsihYvqeNHD2v8qPfk5u6upzu9KEn68vP5Wr70Cw0dMVb+AQU1b9Z0Der7moK/Ximz2XxH8WNiLuu1l19UtRqPadIns+SV11tnQ88oTx4P25zCRYpo4NvvKqBgIVksFi394nP1691DX6/8UXnzejsUL/7aNRUv+ahatGmnMe8OSHW8fKWqatCkpaZ+ODLN6zz+ZEe91P0N22tzzpwO5QEAALII9lA45KEsKGZ+Ns/u9aix49WkQaCOHDms6jVq2s4fO3ZUi4Lna8nSb9WsUb0HJv7hA/tVt2FjBdZrKEnyDyioDevW6Njhg5JudCeWfblIL73SU/Ua3vhN/rCR49S+ZUNt3bJBTVu0vqP4ixfOk6+vn94bOdZ2LqBgIbs5LVo9Yff6zQFD9P133+rPP/5QjVq1HYpXM7Ceagam/f01ffxJSVJk+N/pXsecM6e8ffI5FBsAAOBBR/klKTb2iiTJ09PTdu7atWsaNmSghr47XPny5X+g4pevVEX7du/U2TN/SZJO/nFMB3/fp1p16kuSwv8+p+iLF1T9sUDbe9zd86hs+Uo6fOD3O46/dcsmlSlXXu8O6a/WTeur6/MdtXL5sjTnJyYmaOXyZXJ3z6OSpR+94/jO2rR+jZ5r01Cvv9RBC2ZNVXz8NcNyAQAAyCweyg5FSsnJyfpo/DhVqVpNJUuVtp3/eEKQKlepqsZN7nzPQmaL37lrd12NjdNLzzwpF5dsSk5OUvdeb6r5v12B6IsXJEnePj5278vr42MbuxNhf5/Tim+WqlPnrurySk8dPXxQkz8Kkqurq1o/2c42b9svmzV86CDFx8fLJ19+Tfl0jrzy5r3j+M5o1LyVfP385Z2vgE7/+YfmfzpF50L/0vvjJhuSDwAAuIfYlO0QwwuKa9euae/evfL29la5cuXsxuLj4/X111+rS5cuab7fYrHIYrHYnUt2MWd4nX/QmJE6efKEFn6+xHZu86YN2rVzh5Z+s8KBT+IcI+Jv+nmt1q9drffHfKiixUvq5B/HNH3Sh8qXv4Aef6LtPYmZUnJyssqUq6DX+/aTJD1apqxO/XlSK7752q6gqFbzMQV/+a0uXbqkVSu+0ftvD9Scz7+Ut7dP6he+h1q3fdr252IlSsnbJ5+GvtVTYX+fVUDBR+57PgAAAJmFoUue/vjjD5UtW1YNGjRQxYoV1bBhQ4WHh9vGL1++rJdffjndawQFBcnT09Pu+OjDoAzFDxo7Sr9s2ay584Pl6+dnO79r5w6dOxuq+oE1Vb1yOVWvfKPQGdS/r17t9pITnzRzxf906kR17tpdTVu0VomSpdWy9VN65vku+mLhXEmy7ROIvnjR7n3/XLx4V/YQ+OTLr2LFS9idK1qsuCIjwu3O5cqVW4UKF1GFSpU17IPRypYtm1Z/t/yO498NZcpVlCSFnws1OBMAAHC3mUwmw46syNAOxdtvv60KFSpoz549unTpkvr166e6detq8+bNKly4cIauMXToUA0YYH/nnmSX9LsTVqtV48eN1sYN6zV3wSIVLGT/G+ZXuvdUh47P2J17uv2TGjRkqBo2apyhvDJzfIslXiYX+3+wLi4uSrYmS5L8CxaSt08+7du9Q6UevXH71LjYWB09fEBtn372juNXqlJVoX+dtjt39sxf8vMPSPd9yVarEhIS7jj+3fDnieOSJG+fe7u/BgAAILMztKDYvn27fv75Z+XLl0/58uXT999/rzfeeEP169fXpk2b5ObmdttrmM23Lm+6lpj+e8aNGakf16zWlGkz5ebmpgsXzku6sfE4Z86cypcvf6obof38A2754d8ZRsevU6+RFi+YI18/fxUtXlInjh/V10s+V+un2ku6UZU/8/xL+nz+bBV6pIj8ChbU/FnT5ZOvgOo1bHrH8Z/r3EWvvfyigufNVtPmLXXk8EGtXP6N3n5vhCTp2rWrCp47W/UaNpZPvvy6fOkfffv1l7oQFakmzVs6HO/a1asK+/v/nYTI8L/154ljypPHUwX8/HUl5rKiIsN18d+/h3Ohf0mS8nrnk7dPPoX9fVab169Rzdr15eHpqdN/ntBn0z5ShSrVVaxk6dRCAgAAPDRMVqvValRwDw8P7dy5U2XLlrU736dPH61cuVJLlixRo0aNlJSU5NB1b1dQVKmQ+p2CRo4JUtt2HdJ8z916sNy9jn/5Nl/A1bg4zZv1iX7dvEH//BOtfPnyq2nL1uravZdcXV0lpXiw3YplNx5sV7ma+r/9nh4pUvS28V2z3b5dt+2Xzfp0+hSdCz0j/4BC6vRiF7XtcKMrY7FYNGLYEB0+dECXL/0jT08vlSlfQd26v6Zy5Sum/9mvXr/l3IF9u/X2m91vOd+s1VMa+O5orV+zUpPGDb9lvPPLr+vFV3vpfGSEJowepjOnTio+/pryF/BTnQZN1KlrD7m5udu9p3h+nk0BAEBW5/b0AsNix32T/nL/zMjQguKxxx5T37599dJLt+4L6NOnj7744gvFxMTc9YLiQXe7guJey0hBca+kVlDcTxQUAABkfRQUjjF0U3b79u315Zdfpjo2ffp0Pf/88zKw3gEAAMDDyGTgkQUZ2qG4V+hQ0KEwCh0KAACyPrdnDOxQLMt6HQrDn0MBAAAAZCZZ9fatRjF0yRMAAACArI2CAgAAAIDTWPIEAAAApMCSJ8fQoQAAAADgNDoUAAAAQAp0KBxDhwIAAACA0ygoAAAAADjtgVzylJiUbGj8S1eNfbCcu9nYv9Y1x8INi13Wx8Ow2JIkHmwHAECWx5Inx9ChAAAAAOC0B7JDAQAAADiNBoVD6FAAAAAAcBodCgAAACAF9lA4hg4FAAAAAKdRUAAAAABwGkueAAAAgBRY8uQYOhQAAAAAnEaHAgAAAEiBDoVj6FAAAAAAcBodCkkL583RjGmT1KnzSxo4ZJgkadyoD7RrZ4gunI9Srty5ValyVfXtN1BFixV3+PoHftujZV8s1B/Hjyr6wnmNGD9FdRs2sY1brVYFz5mpH1d9q9grV1S+UhW9OeQ9FXqkiG3OFwtna9e2X/XniePK7uqq79Zvu6PPHBUVqZlTJypk+6+Kj49XoUcK670RY1W2XAVbTnNmTdeqFct05coVVapcVUOGDdcjhYs6FGfryiU6tnurLoaFKnsOswqVKqemz/dUvoBHbHNiL0Xr5yWf6dTBvUqIvyYf/0Kq166zyj7WwO5aJ37boV+WL1JU6Clld82hwmUr6bmBo2+bw9GD+7R62SKdPnFMl6IvqP8HH6lmnUa28fhrV/XlvOnaG7JFV2Iuq4BfgFq2fU7Nnuh4I7+Yy/pm0Wwd3LdDF6Ii5eHppRp1GumZrq8rt5u7Q98HAADAg+ahLygOHzqoFd8sVanSj9qdL1OuvB5v84T8/AIUE3NJsz+doT6vd9fKNeuVLVs2h2LEx19T8VKPquUT7TVyaP9bxpcuXqDvli3RkPfHyC+goBbOnq6h/V7XvCXfKYfZLEm6npioBk1aqGzFylr7/QrnP7CkmJjLeu3lzqpe4zFN+uQz5c3rrbOhZ5Qnj4dtzuLgeVr25WK9P2qcAgIKafan09Svd08t+eZ7mf/NKSNCjx5QzeZPyb9EGSUnJWnT0nlaMn6IXp8wXzly5pIkrfx0vOLjYvXcwDHKncdDh7Zv1LdTR+vVsTPlX7SUJOnorl+0es4kNXnuVRUtX0XJSUmKOvdXhnKwxF9TkeKl1ajlU5o8asgt44s+m6wj+/fojSGjlN/XXwf27dCCTyYor08+VQ9sqH+iz+ufi+f1Qo+3VKhwcV2ICte8aeP1z8Xz6vf+hxn+LgAAQNbAkifHPNQFxdWrcRo+dLCGfTBK8+fMshvr8PSztj8HFCyoXn3e0gvPtFN42N8q9Ehhh+I8FlhfjwXWT3XMarVqxdLF6tyth+o0aCxJenv4WD3TprG2/bJRjZu3kiR17dFbkrTuh5UOxU7N4oXz5Ovrp/dGjrOdCyhYyC6npUs+V7fur6lBo6aSpOGjxqtN8/r6ZfMGNW/ZOsOxXnhnvN3rp14fokmvd1T46RMqUraSJOnsH4fV+pV+KliyjCSpfvsXtfPHbxRx+g/5Fy2l5KQkrft8hpq90FNVG/8/dv5CRTOUQ5WadVWlZt00x08cOaD6zduoXOXqkqSmrTtoww8r9OfxI6oe2FCPFC2p/sMn2Ob7BhTSs916aeaE4UpKuq5s2R7q/4wAAMBD7qHeQzFh3GjVbdBQtWrXSXfetatX9f3K5QooWEi+fn53NYeIsL8VffGCqtasbTvn5p5HZcpV1JFDv9/VWDf9umWjypSroGFD+ql103rq8nwHrVy+zDYe9vc5XbxwQTVrBdrOuefJo3IVKunQgf13FNtyNU6SlMs9j+3cI6XL68iOTboWGyNrcrIObd+o64mJKlK2iiQp/PQJXYm+IJPJRbOHvqbJbzyjJR++o6izp+8ol5tKlaukfTt+UfSFKFmtVh3ev0cRf4eqYvVaab7nWlyscuV2o5gAAOBBZDLwyIIM/2no6NGj2rFjhwIDA1WmTBkdO3ZMU6dOlcVi0YsvvqgmTZqk+36LxSKLxWJ/zup622U5P/34g44dPaLgJcvSnLNs6RJ9Mnmirl27qiJFi2nGZ/Pk6poj4x8uA6IvXpAk5fX2sTuf19tH/1y8eFdj3RT29zmt+OYrdercVV1f6amjhw9p0kfjlN3VVW2ebKeL/+bk7Z3P7n3ePj66eOGC03Gtycn6adEMPVK6ggo8Usx2vuObw/XttNH6uGd7uWTLJtccOfVM/5Hy9isoSfonKkyS9MvyYDV/sZe88vkpZM0yfT56gHpPClYud49U42VUtzcGa+7UcerTuY2yZcsmk4uLur/1rspWrJbq/JjLl7RiyTw1adX+juICAAA8CAztUKxdu1ZVqlTRoEGDVLVqVa1du1YNGjTQyZMndebMGbVo0UIbN25M9xpBQUHy9PS0OyZ9ND7d90REhGvihCCNDvoo3cKjVesntXjpt/ps/ucqXKSohg7uf0vxkhUlJyerdJly6tW3vx4tU07tOj6rtu2f1nffLL2ncX9cME1RZ/9Sh77v2Z3fvGyB4q/G6sVhH+nVMZ+qVuun9e20UYoMPSXpxhIsSarX9sZGbf/ipfXUa4NlMpl0ZOeWO85r3cqlOnnsoAaOnKix0xepc49+Wjhjgg7u23nL3Ktxsfro/X4qWLiYOr7U845jAwCAzMdkMhl2ZEWGFhSjRo3S4MGDdfHiRS1YsEAvvPCCevToofXr12vDhg0aPHiwxo9PvzgYOnSoLl++bHcMGPxOuu85duSwoqMv6qVOHVW7WgXVrlZB+/bs1tIli1W7WgUlJSVJurHMp3CRoqpWvaY+nDhFf50+rc0bf75rn1+SvH1udAH+ibbvRvwTfVF5fXxSe8sdy5cvv4oVL2F3rmixEoqICJck+fybU3S0fTci+uJF+eSz71pk1I8LpunEbzv00nsT5eGT///XjAzT7p++05OvDVaxCtXkV6SEGnbsooBij2rP+hv7RfJ4ed/Iu+D/73qV3TWHvAr46/KFKKfyuSnBEq+lC2fqxZ79Vb12AxUuXkot2z6r2g2b64dvFtvNvXY1Th+++6Zy5sqt/h98pOzZDW/wAQAAGM7QguLw4cPq1q2bJOnZZ5/VlStX9PTTT9vGO3furAMHDqR7DbPZLA8PD7vjdsudatYK1JffrNTipcttR9nyFfR46ye0eOnyVO/iZLVKVlmVkJDg+AdNh19AQXn75NNve/7/2/C4uFgdO3JQ5SpUvquxbqpYpZpC/7LffxB65i/5+QdIurFB2ydfPu3ZteP/OcXG6sihA6pQqYpDsaxWq35cME3H92zVi+9+rLwF/O3GEy3xkm69m4LJxUXW5BudCf9ipZXN1VUXw8/axpOuX9fl8xHyyufrUD7/df36dSVdvy6Ti318FxcXW2dEutGZCBrWV9ldXTVo5CTlyJHxO10BAAA8yAz/FevNHyRdXFyUM2dOeXp62sby5Mmjy5cv3/WYbm5uKlmqtN25XLlyydPLSyVLlda5c2e1ft2Pqh1YV3nz5lVkZKSC589RTrNZdes1SOOqabt29ar+Phdqex0R9rdO/nFMHh6eKuDnr/bPvaglC2er4COF5e9fUAvnzJBPvvyq2+D/+0eiIsIVE3NZURHhSk5O0sk/jkmSChYqrFy5czuUT6fOXdTz5c5aOO8zNW3+uI4cPqiVy5fpnfdGSLrxd/LcC120cO5neqRwEfkHFNKcT6cpX/4Ctrs+ZdSPC6bp0PYNem7gaJlz5VbspWhJkjm3m1xzmJUvoLC8fQtqzbzJavbC68qVx0PH92zVqUN71WnQWNvc6k2f1JZvg+XhU0Ce+XwVsvrG8qyytRreNof4a1cVEfb/YuR8RJj++vO43PN4Kl8BP5WtVE1L5kxTjhw5lc/XT0cP7NOvP6/Riz37SbpRTIwf1lcWS7x6Dxmla1djde1qrCTJwzOvXBy8jTAAAMjcsurSI6OYrCl/DXufVa5cWR9++KEef/xxSdKhQ4dUpkwZ21KSX3/9VV27dtWpU6ccum5MfLLDubz2aheVfrSMBg4ZpvNRURoz8j0dO3JEMTEx8vbxUdXqNdT9tTdUtGix217r0tVEu9e/79utQb1fvWVe89ZPacj7Y2wPtluz8hvFxl5RhUpV9ebgd1UoxUPkJox+T+vXrLrlGh/PmKfK1WranXM3375O3PrLZn06fbLOhZ6Rf0AhPf9iV7Xt8Ixt/OaD7VYu/1qxV66oUpVqGjx0uAoXKZr2Rf+15li47c+jX0i9AHnqtcGq3PDG3/vF8HPa+NVcnT1+UAmWeOX1DVBgm2dVqX5z2/yk69e1celcHfx1vRITE1SwRBm16NJbBf5z69iyPrdu0D7y+16NGfL6LecbNG+j1weN0KXoC/pq/gwd3LdTsVdilK+An5q0bq/WHV64sU8jjfdL0tTglcrvF2B7Xb3onW0QBwAAxsv/8r3dV5qe8wueMyy2swwtKGbNmqVHHnlEbdq0SXV82LBhioqK0ty5cx26rjMFxd3034LifstIQXEvpSwo7rfUCor7iYICAICsr8ArXxsWO2r+s7eflMkY+pPn66+n/lvfm8aNG5fuOAAAAABjPdQPtgMAAABwZwzflA0AAABkKuzJdggdCgAAAABOo0MBAAAApMBtYx1DhwIAAACA0+hQAAAAACnQoXAMHQoAAAAATqOgAAAAAOA0CgoAAAAgBZPJZNjhqL///lsvvviifHx8lCtXLlWsWFF79uyxjVutVg0fPlz+/v7KlSuXmjVrphMnTthdIzo6Wp07d5aHh4e8vLz06quvKjY2NsM5PJB7KJKSrYbGz5cnh6HxE64nGxq/RWlfw2IXadDfsNiSdO236YbGBwAAD49//vlHdevWVePGjfXjjz8qf/78OnHihPLmzWubM2HCBE2bNk3BwcEqVqyY3n//fbVs2VJHjhxRzpw5JUmdO3dWeHi41q9fr8TERL388svq2bOnlixZkqE8TFar1difvu+Bf64mGRrf7Gps48fogsLI+BQUAADgTgW8ttyw2GGfdcjw3HfeeUfbtm3Tr7/+muq41WpVQECABg4cqEGDBkmSLl++LF9fXy1cuFCdOnXS0aNHVa5cOe3evVs1atSQJK1du1atW7fWuXPnFBAQcNs8WPIEAAAAZBIWi0UxMTF2h8ViSXXuqlWrVKNGDT3zzDMqUKCAqlatqjlz5tjGT58+rYiICDVr1sx2ztPTU7Vq1VJISIgkKSQkRF5eXrZiQpKaNWsmFxcX7dy5M0M5U1AAAAAAmURQUJA8PT3tjqCgoFTnnjp1Sp9++qlKlSqldevWqVevXnrzzTcVHBwsSYqIiJAk+fraL0f39fW1jUVERKhAgQJ249mzZ5e3t7dtzu08kHsoAAAAAKcZ+BiKoUOHasCAAXbnzGZzqnOTk5NVo0YNjRs3TpJUtWpVHTp0SLNmzVLXrl3vea430aEAAAAAMgmz2SwPDw+7I62Cwt/fX+XKlbM7V7ZsWYWGhkqS/Pz8JEmRkZF2cyIjI21jfn5+ioqKshu/fv26oqOjbXNuh4ICAAAASCGr3Da2bt26On78uN25P/74Q0WKFJEkFStWTH5+ftqwYYNtPCYmRjt37lRgYKAkKTAwUJcuXdLevXttczZu3Kjk5GTVqlUrQ3mw5AkAAADIgvr37686depo3LhxevbZZ7Vr1y7Nnj1bs2fPlnSjMOrXr5/GjBmjUqVK2W4bGxAQoHbt2km60dF4/PHH1aNHD82aNUuJiYnq06ePOnXqlKE7PEkUFAAAAIAdZx4wZ4SaNWtqxYoVGjp0qEaNGqVixYppypQp6ty5s23OkCFDFBcXp549e+rSpUuqV6+e1q5da3sGhSR98cUX6tOnj5o2bSoXFxd17NhR06ZNy3AePIfiHuA5FDyHAgAAZF2F3vjOsNjnZrYzLLazHsoOxZxZ0zXvs5l254oULaalK37Q5cuXNOfT6dq1Y7siI8LllTevGjRqqtfeeFPuefLclfjz5nymjT+v11+nT8mcM6cqV6mqt/oPVNFixSVJYX+fU5uWzVJ974SJU9S85eN3FH/Op9M1N5XP//V3P0i6cf/jqRMnaP26NUpMSFCtOvU0ZNj78vHJd0dxb3rmyRaKCA+75Xz7Zzqp++t9Ne+zGdq9Y7siI8Pl5ZVX9Rs1UfdefeXu7vj3f+yHkSoS4HPL+VlLf1H/8V9r3Zy31KBGKbuxOd9s1Ztjv7rlPd6ebtq19B0V9M0rv/qDdTn2msP5AAAAPGgeyoJCkoqXKKlPZs2zvc6W7cZXceH8eV04f159+w9WseIlFBEepg/HjtSF8+cV9PGUuxJ7357deu75F1S+QkVdv56k6VMnq1fP7lq+crVy5c4tXz9/rd9s/8TDb5d9rc8XzFPd+vXvSg7FS5TU9M9u/fySNOXj8dr26xYFfTRZbu559PH4MXpnwFuaE/zFXYk9+/OvlJz0/y7G6T9PqH/vHmrctIUunI/SxfNR6t1vkIoWL66I8HB9HDRKF86f15gJkx2OVe/Fj5TN5f9ty3IlA7RmVl8tX/+b7dy8b7dp9Kerba+vxiemeq1ZH7yggyfCVNA3b6rjAADgwZBVljxlFg9tQZEtWzb55Mt/y/kSJUtp/MSptteFHims1/u8pRHvvq3r168re/Y7/8pmfDbX7vXIsUFq2qCOjhw5rOo1aipbtmzK95/cNm34Wc1btlLu3G53HF9K+/PHXrmiVSu+1aigj1TjsdqSpPdHjtVz7Z/QwQO/q2KlynccO29eb7vXXwTPVcFCj6hK9ZoymUwa89EU21jBQoXV8403Nfr9d5z6/i/8E2v3etDLFfRn6Hn9uveE7dy1+ARFXryS7nV6PFNPnnlya9zsH/V4vfIO5QAAAPAgy3S3jb1fWzrOhobqieYN1eGJFho+bHCqS3Buir0SKzc397tSTKR6/dgbP8x6enqmOn7k8CEdP3ZU7Tp0vGsxz4aGqk3zhmrfpoWGD/3/5z929LCuX7+ux2oF2uYWLVZcfv7+OvT7/rsW/6bExET9tGa1Wj/VPs3fBsTGXlHuu/D9u2bPpk6tayp4ZYjd+eda19DZjeO1Z9kwjer7lHLldLUbL1PcT0N7tFL39z9XcvIDt+UIAAD8l8nAIwvKdB0Ks9ms33//XWXLlr1nMcpXqKT3R41V4SLFdPHCec37bKZef+UlffHNKrm52XcALv3zjxbM+VRtOz5zT3JJTk7Wx+PHqUrVaipZqnSqc75b/q2KFS+hKlWr3ZWY5StW0vBRY1W46I3PP3fWTL32ykta8s0qXbxwQa6ursrj4WH3Hm/vfLp48cJdiZ/Sr5s3KDb2ilo/2S7V8UuX/lHw3M/0VPun7zjWU40ryStPLi3+fqft3NIf9yg0PFrh5y+rYqkAjXmrrUoXKaBOg250kXK4ZldwUDcNm/Kdzkb8o6IF784+EgAAgAeFYQXFfx8pflNSUpLGjx8vH58bG2knTZqU7nUsFossFov9uaTsaT5RUJLq1Gtg+3Op0o+qfMVKate6mTb8tFZPtf9/FyAuNlYD3nxdRYuXUI/Xet/2MzkjaMwonTx5Qgs+X5LqeHx8vH5cs1o9Xut112Le8vkrVFLbfz9/et/bvbB65XLVqlNP+fIXuGUsLjZWQ956Q0WLl9Arr71xx7G6tqujdduOKPz8Zdu5+cu32f58+GSYwi/EaO3sN1WsUD6dPndBo998SsdPR+qrNbvvOD4AAMCDyLCCYsqUKapcubK8vLzszlutVh09elRubm4Z2hATFBSkkSNH2p0bMux9vfPuBxnOJU8eDxUuXFTnzp6xnYuLi1O/3j2VO7ebPpz0ibK7uqZzBeeMHztKv27ZrHnBi+WbxqPNf/5pneKvxeuJp9rd9fg35fG48fnPnj2jWrXrKDExUVdiYuy6FNHRF+7aXZ5uiggP095dOzRmwpRbxq7GxWnQm68pt5ubxn40Vdmz39n3X9g/r5rUelSdBs1Jd97ug39Jkko8kl+nz11Qw5qlVaFkgNrvriLp/5u0zm0arw/nrdOYWWvuKC8AAJD5sCnbMYYVFOPGjdPs2bM1ceJENWnSxHbe1dVVCxcuVLly5TJ0naFDh97S7bia5NjHuno1Tn+fC9XjbZ6UdOM342+90UOuOXLo4ykz7vpv7a1Wqz4cN1obN/ysOQs+V8FChdKc+93yb9SwcWN5e3unOedO3fz8rfI9qTJlyyt79uzavWuHmjRrIUk689dpRYSHq0LlKnc17ppVK+SV11uBKTom0o3vf2Df1+Tq6qrxkz65K9//S08FKir6in789XC68yo/euPvIuLCjS7G84PmKpf5/8VM9fJFNHvki2r26hSdOnv+jvMCAADI6gwrKN555x01bdpUL774op588kkFBQXJ1YkugNlsvuUHzqTbPNhu2qQJqtegsfwCAnQhKkpzZk2Xi0s2tXi8jeJiY/XmG90VHx+vEWM/VFxcrOLibtwpyCuvt7Jly+Zwjv8VNGaUflyzWpOnzZCbm5suXLjxg6m7ex67pxaGhp7Rvr179Mmns+84ZkpTJ01Q/QaN5ecfoAvnozTn0+lyyXbj87vnyaOn2nfU1IkfysPTU25u7po4fqwqVqpyV+7wdFNycrLWfP+dWj3R1m6zdVxsrAb06an4+Gt6f/RUxcXGKS42TpLklTevU9+/yWRSl7a19cXqnUpKcbvaYoXy6blWNbRu62FdvBSniqULasLADvp17wkdOnFjk/rpc/b7Rny83CVJx05F8BwKAAAeUHQoHGPopuyaNWtq79696t27t2rUqKEvvvjivvwFRkVGavjQQbp8+ZK88nqrcpVqmvv5l8rr7a29e3bp8MEDkqSnn7J/gNzyH9YrIKDgHcdftvRLSVKPl7vYnR85ZpyeatfB9nrl8m/l6+unwDp17zhmSlGRkXp/6CBdvvTv569aTfP+/fyS1G/QOzKZXDR04FtKSEhU7Tp1NWTY+3c1hz27QhQZEa7WT7W3O//HsSM6cujG99+pXWu7sa9XrZO/E99/k1qPqrC/t4K/22F3PjHxuprUelR9Xmgst1w5dC7yH323Yb/Gz13ncAwAAICHlcl6v+7TehtfffWV+vXrp/Pnz+vgwYMZXvKUmn9u06G418yuxt6NN+F68u0nPaDxizTob1hsSbr223RD4wMAgDtX5M3vDYt9ZtqThsV2Vqa5bWynTp1Ur1497d27V0WKFDE6HQAAADykWPLkmExTUEhSoUKFVCidDcoAAAAAMpdMVVAAAAAARqND4RhjF/sDAAAAyNLoUAAAAAAp0aBwCB0KAAAAAE6joAAAAADgNJY8AQAAACmwKdsxdCgAAAAAOI0OBQAAAJACHQrH0KEAAAAA4LQHskORN3c2o1MwVG5Xoz+/cfGv/TbdsNgAAAAPoweyoAAAAACcxYonx7DkCQAAAIDT6FAAAAAAKbAp2zF0KAAAAAA4jQ4FAAAAkAINCsfQoQAAAADgNAoKAAAAAE5jyRMAAACQApuyHUOHAgAAAIDT6FAAAAAAKdCgcAwdCgAAAABOo6AAAAAA4DSWPAEAAAApuLiw5skRmaqgiIuL09dff62TJ0/K399fzz//vHx8fNJ9j8VikcVisTtnNptlNpvvZaoAAAAAZPCSp3Llyik6OlqSdPbsWVWoUEH9+/fX+vXr9cEHH6hcuXI6ffp0utcICgqSp6en3REUFHQ/0gcAAMADyGQy7siKTFar1WpUcBcXF0VERKhAgQJ68cUXdfr0aa1Zs0aenp6KjY1V+/btlT9/fi1ZsiTNa9ChAAAAwN1U/t2fDIt9eGwLw2I7K9MseQoJCdGsWbPk6ekpSXJ3d9fIkSPVqVOndN9H8QAAAIC7iQfbOcbwuzzd/AuLj4+Xv7+/3VjBggV1/vx5I9ICAAAAkAGGdyiaNm2q7NmzKyYmRsePH1eFChVsY2fOnLntpmwAAAAAxjG0oPjggw/sXru7u9u9/v7771W/fv37mRIAAAAecqx4coyhm7IBAACAzKbi++sNi31wdHPDYjvL8CVPAAAAQGbCpmzHGL4pGwAAAEDWRUEBAAAAwGkseQIAAABSYMmTY+hQAAAAAHAaHQoAAAAgBRoUjqFDAQAAAMBpdCgAAACAFNhD4Rg6FAAAAACcRkEBAAAAwGkseQIAAABSYMWTY+hQAAAAAHAaHQoAAAAgBTZlO4YOBQAAAACnUVAAAAAAcBpLngAAAIAUWPHkGDoUAAAAAJxGhwIAAABIgU3ZjqFDAQAAAMBpdCgAAACAFGhQOIYOBQAAAACnUVAAAAAAcBpLngAAAIAU2JTtGDoUAAAAAJxmaEGxb98+nT592vZ60aJFqlu3rh555BHVq1dPX3311W2vYbFYFBMTY3dYLJZ7mTYAAAAeYCaTcUdWZGhB8fLLL+vPP/+UJM2dO1evvfaaatSooXfffVc1a9ZUjx49NH/+/HSvERQUJE9PT7sjKCjofqQPAAAAPPRMVqvValTw3Llz6+jRoypSpIiqVaumXr16qUePHrbxJUuWaOzYsTp8+HCa17BYLLd0JMxms8xm8z3LGwAAAA+u2uO3GBZ7xzsNDYvtLEM3ZefOnVsXLlxQkSJF9Pfff+uxxx6zG69Vq5bdkqjUUDwAAADgbmJTtmMMXfLUqlUrffrpp5Kkhg0b6ptvvrEb//rrr1WyZEkjUgMAAACQAYYWFB9++KE2bNighg0b6pFHHtHEiRNVv3599ezZUw0bNtSIESM0fvx4I1MEAADAQyarbMoeMWKETCaT3VGmTBnbeHx8vHr37i0fHx+5u7urY8eOioyMtLtGaGio2rRpo9y5c6tAgQIaPHiwrl+/7lAehhYUAQEB+u233xQYGKi1a9fKarVq165d+umnn1SoUCFt27ZNrVu3NjJFAAAAINMqX768wsPDbcfWrVttY/3799f333+vZcuWacuWLQoLC1OHDh1s40lJSWrTpo0SEhK0fft2BQcHa+HChRo+fLhDORi6KRsAAADIbOp+9KthsbcNrp/huSNGjNB3332n/fv33zJ2+fJl5c+fX0uWLNHTTz8tSTp27JjKli2rkJAQ1a5dWz/++KOeeOIJhYWFydfXV5I0a9Ysvf322zp//rxy5MiRoTx4sB0AAACQSTj6jLUTJ04oICBAxYsXV+fOnRUaGipJ2rt3rxITE9WsWTPb3DJlyqhw4cIKCQmRJIWEhKhixYq2YkKSWrZsqZiYmHTvsvpfFBQAAABAJuHIM9Zq1aqlhQsXau3atfr00091+vRp1a9fX1euXFFERIRy5MghLy8vu/f4+voqIiJCkhQREWFXTNwcvzmWUYbeNhYAAADIbIy8a+zQoUM1YMAAu3NpPSKhVatWtj9XqlRJtWrVUpEiRfT1118rV65c9zTPlOhQAAAAAJmE2WyWh4eH3ZHRZ655eXmpdOnSOnnypPz8/JSQkKBLly7ZzYmMjJSfn58kyc/P75a7Pt18fXNORlBQAAAAACn891as9/O4E7Gxsfrzzz/l7++v6tWry9XVVRs2bLCNHz9+XKGhoQoMDJQkBQYG6uDBg4qKirLNWb9+vTw8PFSuXLkMx2XJEwAAAJAFDRo0SE8++aSKFCmisLAwffDBB8qWLZuef/55eXp66tVXX9WAAQPk7e0tDw8P9e3bV4GBgapdu7YkqUWLFipXrpxeeuklTZgwQREREXrvvffUu3fvDHdFJAoKAAAAIEs6d+6cnn/+eV28eFH58+dXvXr1tGPHDuXPn1+SNHnyZLm4uKhjx46yWCxq2bKlZs6caXt/tmzZtHr1avXq1UuBgYFyc3NT165dNWrUKIfy4DkUAAAAQAoNJm0zLPYvA+oaFttZ7KEAAAAA4DSWPAEAAAApGHnb2KyIDgUAAAAAp1FQAAAAAHAaS54AAACAFO70eRAPGzoUAAAAAJxGhwIAAABIgQaFY+hQAAAAAHAaHQoAAAAgBfZQOIYOBQAAAACnUVAAAAAAcBpLngAAAIAUWPHkGDoUAAAAAJxGhwIAAABIwYUWhUPoUAAAAABwGgUFAAAAAKcZWlD07dtXv/766x1dw2KxKCYmxu6wWCx3KUMAAAA8bEwm446syNCCYsaMGWrUqJFKly6tDz/8UBEREQ5fIygoSJ6ennZHUFDQPcgWAAAAwH+ZrFar1ajgLi4uWr9+vb7//nt98cUXunz5slq1aqUePXqodevWcnG5fb1jsVhu6UiYzWaZzeZ7lTYAAAAeYC1n7jQs9ro3ahkW21mG76GoWLGipkyZorCwMC1evFgWi0Xt2rXTI488onfffVcnT55M9/1ms1keHh52B8UEAAAAcH8YXlDc5OrqqmeffVZr167VqVOn1KNHD33xxRd69NFHjU4NAAAADxEXk3FHVpRpCoqUChcurBEjRuj06dNau3at0ekAAAAASIOhBUWRIkWULVu2NMdNJpOaN29+HzMCAAAA4AhDn5R9+vRpI8MDAAAAtzBl1fu3GiRTLnkCAAAAkDUY2qEAAAAAMhsaFI6hQwEAAADAaRQUAAAAAJzGkicAAAAgBZNY8+QIOhQAAAAAnEaHAgAAAEghqz6x2ih0KAAAAAA4jQ4FAAAAkAIPtnMMHQoAAAAATqOgAAAAAOA0ljwBAAAAKbDiyTF0KAAAAAA4jQ4FAAAAkIILLQqH0KEAAAAA4DQKCgAAAABOY8kTAAAAkAIrnhxDhwIAAACA0+hQAAAAACnwpGzH0KEAAAAA4DQ6FAAAAEAKNCgcQ4cCAAAAgNMoKAAAAAA4zfCCYvr06erSpYu++uorSdKiRYtUrlw5lSlTRsOGDdP169fTfb/FYlFMTIzdYbFY7kfqAAAAeAC5mEyGHVmRoQXFmDFjNGzYMF29elX9+/fXhx9+qP79+6tz587q2rWr5s6dq9GjR6d7jaCgIHl6etodQUFB9+kTAAAAAA83k9VqtRoVvGTJkpowYYI6dOig33//XdWrV1dwcLA6d+4sSVqxYoWGDBmiEydOpHkNi8VyS0fCbDbLbDbf09wBAADwYOoU/Jthsb/qWtWw2M4y9C5PYWFhqlGjhiSpcuXKcnFxUZUqVWzj1apVU1hYWLrXoHgAAAAAjGPokic/Pz8dOXJEknTixAklJSXZXkvS4cOHVaBAAaPSAwAAAHAbhnYoOnfurC5duqht27basGGDhgwZokGDBunixYsymUwaO3asnn76aSNTBAAAwEOGJ2U7xtCCYuTIkcqVK5dCQkLUo0cPvfPOO6pcubKGDBmiq1ev6sknn7ztpmwAAAAAxjF0UzYAAACQ2XRetN+w2F+8VMWw2M4y/DkUAAAAALIuQ5c8AQAAAJkNeygcQ4cCAAAAgNMoKAAAAAA4jSVPAAAAQAqseHIMHQoAAAAATqNDAQAAAKTApmzH0KEAAAAA4DQKCgAAAABOY8kTAAAAkIILK54cQocCAAAAgNPoUAAAAAApsCnbMXQoAAAAADiNDgUAAACQAv0Jx9ChAAAAAOA0CgoAAAAATmPJEwAAAJCCC5uyHUKHAgAAAIDTKCgAAACAFEwm4w5njR8/XiaTSf369bOdi4+PV+/eveXj4yN3d3d17NhRkZGRdu8LDQ1VmzZtlDt3bhUoUECDBw/W9evXHYpNQQEAAABkYbt379Znn32mSpUq2Z3v37+/vv/+ey1btkxbtmxRWFiYOnToYBtPSkpSmzZtlJCQoO3btys4OFgLFy7U8OHDHYrvVEHx66+/6sUXX1RgYKD+/vtvSdKiRYu0detWZy4HAAAAwAmxsbHq3Lmz5syZo7x589rOX758WfPmzdOkSZPUpEkTVa9eXQsWLND27du1Y8cOSdJPP/2kI0eOaPHixapSpYpatWql0aNHa8aMGUpISMhwDg4XFN9++61atmypXLly6bfffpPFYrElPW7cOEcvBwAAAGQqJpPJsMNisSgmJsbuuPnzdmp69+6tNm3aqFmzZnbn9+7dq8TERLvzZcqUUeHChRUSEiJJCgkJUcWKFeXr62ub07JlS8XExOjw4cMZ/r4cLijGjBmjWbNmac6cOXJ1dbWdr1u3rvbt2+fo5QAAAAD8KygoSJ6ennZHUFBQqnO/+uor7du3L9XxiIgI5ciRQ15eXnbnfX19FRERYZuTspi4OX5zLKMcvm3s8ePH1aBBg1vOe3p66tKlSw5dKzw8XJ9++qm2bt2q8PBwubi4qHjx4mrXrp26deumbNmyOZoeAAAAcEeMvGvs0KFDNWDAALtzZrP5lnlnz57VW2+9pfXr1ytnzpz3K71UOdyh8PPz08mTJ285v3XrVhUvXjzD19mzZ4/Kli2rNWvWKDExUSdOnFD16tXl5uamQYMGqUGDBrpy5cptr+NoWwgAAADIrMxmszw8POyO1AqKvXv3KioqStWqVVP27NmVPXt2bdmyRdOmTVP27Nnl6+urhISEW37hHxkZKT8/P0k3fq7/712fbr6+OScjHC4oevToobfeeks7d+6UyWRSWFiYvvjiCw0aNEi9evXK8HX69eun/v37a8+ePfr111+1cOFC/fHHH/rqq6906tQpXb16Ve+9995tr+NIWwgAAAB4EDRt2lQHDx7U/v37bUeNGjXUuXNn259dXV21YcMG23uOHz+u0NBQBQYGSpICAwN18OBBRUVF2easX79eHh4eKleuXIZzMVmtVqsjyVutVo0bN05BQUG6evWqpBuV1KBBgzR69OgMXyd37tw6dOiQrauRnJysnDlz6uzZs/L19dX69evVrVs3212k0mKxWG7pSJjN5lQrOQAAAOB2en17xLDYn3bM+A/y/9WoUSNVqVJFU6ZMkST16tVLa9as0cKFC+Xh4aG+fftKkrZv3y7pxm1jq1SpooCAAE2YMEERERF66aWX1L17d4dutuTwHgqTyaR3331XgwcP1smTJxUbG6ty5crJ3d3doesUKFBA4eHhtoIiMjJS169fl4eHhySpVKlSio6Ovu11KB4AAACAW02ePFkuLi7q2LGjLBaLWrZsqZkzZ9rGs2XLptWrV6tXr14KDAyUm5ubunbtqlGjRjkUx+EOxd3Sr18/bdiwQR999JHMZrNGjx4tq9WqTZs2SZLWrVun3r17p7pfAwAAALhX3lhuXIdiZgfnOxRGcbhD0bhxY5nS2fq+cePGDF1nzJgxCg8P15NPPqmkpCQFBgZq8eLFtnGTycReCAAAACCTc7igqFKlit3rxMRE7d+/X4cOHVLXrl0zfB13d3ctXbpU8fHxun79+i1Lplq0aOFoagAAAMAdS++X57iVwwXF5MmTUz0/YsQIxcbGOpyA0ffNBQAAAOA8h28bm5YXX3xR8+fPv1uXAwAAAJAFONyhSEtISAjdBgAAAGR5d+037g8JhwuKDh062L22Wq0KDw/Xnj179P7779+1xAAAAABkfg4XFJ6ennavXVxc9Oijj2rUqFFspAYAAECWx6ZsxzhUUCQlJenll19WxYoVlTdv3nuVEwAAAIAswqElYtmyZVOLFi106dKle5QOAAAAgKzE4T0nFSpU0KlTp+5FLgAAAIDhXEzGHVmRwwXFmDFjNGjQIK1evVrh4eGKiYmxOwAAAAA8PDK8h2LUqFEaOHCgWrduLUl66qmn7DasWK1WmUwmJSUl3f0sAQAAgPskq3YKjGKyWq3WjEzMli2bwsPDdfTo0XTnNWzY8K4kBgAAABhhwKpjhsWe9FQZw2I7K8Mdipt1BwUDAAAAHmTcNtYxDu2h4MsFAAAAkJJDz6EoXbr0bYuK6OjoO0oIAAAAQNbhUEExcuTIW56UDQAAADxI2JTtGIcKik6dOqlAgQL3KhcAAAAAWUyGCwr2TwAAAOBhwI+9jsnwpuwM3l0WAAAAwEMkwx2K5OTke5kHAAAAgCzIoT0UAAAAwIPOhTVPDnHoORQAAAAAkJLhHYqEhAR99913CgkJUUREhCTJz89PderUUdu2bZUjRw6DMwQAAMDDhN+4O8bQ7+vkyZMqW7asunbtqt9++03JyclKTk7Wb7/9pi5duqh8+fI6efKkkSkCAAAASIehHYpevXqpYsWK+u233+Th4WE3FhMToy5duqh3795at26dQRkCAADgYcMWCscYWlBs27ZNu3btuqWYkCQPDw+NHj1atWrVSvcaFotFFovF7pzZbJbZbL6ruQIAAAC4laFLnry8vPTXX3+lOf7XX3/Jy8sr3WsEBQXJ09PT7ggKCrq7iQIAAABIlaEdiu7du6tLly56//331bRpU/n6+kqSIiMjtWHDBo0ZM0Z9+/ZN9xpDhw7VgAED7M7RnQAAAICzuG2sYwwtKEaNGiU3Nzd99NFHGjhwoEz//uVZrVb5+fnp7bff1pAhQ9K9BsubAAAAAOOYrFar1egkJOn06dN2t40tVqyYwRkBAADgYTR83QnDYo9qWcqw2M7KNLfZLVasmAIDAxUYGGgrJs6ePatXXnnF4MwAAAAApCXTFBSpiY6OVnBwsNFpAAAAAEiDoXsoVq1ale74qVOn7lMmAAAAwA0u7Ml2iKEFRbt27WQymZTeNg4Tu+wBAACATMvQJU/+/v5avny5kpOTUz327dtnZHoAAAB4CLmYTIYdWZGhBUX16tW1d+/eNMdv170AAAAAYCxDlzwNHjxYcXFxaY6XLFlSmzZtuo8ZAQAA4GGXRRsFhjG0oKhfv366425ubmrYsOF9ygYAAACAozL1bWMBAAAAZG6GdigAAACAzIbbxjqGDgUAAAAAp9GhAAAAAFIwiRaFI+hQAAAAAHAaBQUAAAAAp7HkCQAAAEiBTdmOoUMBAAAAwGl0KAAAAIAU6FA4hg4FAAAAAKfRoQAAAABSMJloUTiCDgUAAAAAp1FQAAAAAHAaS54AAACAFNiU7Rg6FAAAAACclqkLisjISI0aNcroNAAAAPAQMZmMO7KiTF1QREREaOTIkUanAQAAACANhu6hOHDgQLrjx48fv0+ZAAAAAHCGoQVFlSpVZDKZZLVabxm7eZ77AAMAAOB+cuHnT4cYWlB4e3trwoQJatq0aarjhw8f1pNPPpnuNSwWiywWi905s9kss9l81/IEAAAAkDpD91BUr15dYWFhKlKkSKpHwYIFU+1epBQUFCRPT0+7Iygo6D59AgAAADxoXEzGHVmRoR2K119/XXFxcWmOFy5cWAsWLEj3GkOHDtWAAQPsztGdAAAAAO4Pk/V2LQAAAADgIfLJttOGxe5bt5hhsZ2VqW8be/bsWb3yyitGpwEAAAAgDZm6oIiOjlZwcLDRaQAAAABIg6F7KFatWpXu+KlTp+5TJgAAAMANLsqiu6MNYmhB0a5duzSfQ3ETz6EAAAAAMi9Dlzz5+/tr+fLlSk5OTvXYt2+fkekBAADgIWQyGXdkRYY/h2Lv3r1pjt+uewEAAADAWIYueRo8eHC6z6EoWbKkNm3adB8zAgAAAOAInkMBAAAApDAr5C/DYr8eWNSw2M7K1LeNBQAAAJC5GbrkCQAAAMhsXLLq7miD0KEAAAAA4DQKCgAAACAL+vTTT1WpUiV5eHjIw8NDgYGB+vHHH23j8fHx6t27t3x8fOTu7q6OHTsqMjLS7hqhoaFq06aNcufOrQIFCmjw4MG6fv26Q3lQUAAAAAApZJXnUBQqVEjjx4/X3r17tWfPHjVp0kRt27bV4cOHJUn9+/fX999/r2XLlmnLli0KCwtThw4dbO9PSkpSmzZtlJCQoO3btys4OFgLFy7U8OHDHfu+uMsTAAAA8H9zdp4xLHaPWkXu6P3e3t766KOP9PTTTyt//vxasmSJnn76aUnSsWPHVLZsWYWEhKh27dr68ccf9cQTTygsLEy+vr6SpFmzZuntt9/W+fPnlSNHjgzFpEMBAAAApOBiMhl2WCwWxcTE2B0Wi+W2OSclJemrr75SXFycAgMDtXfvXiUmJqpZs2a2OWXKlFHhwoUVEhIiSQoJCVHFihVtxYQktWzZUjExMbYuR4a+Lwe+WwAAAAD3UFBQkDw9Pe2OoKCgNOcfPHhQ7u7uMpvNev3117VixQqVK1dOERERypEjh7y8vOzm+/r6KiIiQpIUERFhV0zcHL85llHcNhYAAABIwci7xg4dOlQDBgywO2c2m9Oc/+ijj2r//v26fPmyvvnmG3Xt2lVbtmy512naoaAAAAAAMgmz2ZxuAfFfOXLkUMmSJSVJ1atX1+7duzV16lQ999xzSkhI0KVLl+y6FJGRkfLz85Mk+fn5adeuXXbXu3kXqJtzMoIlTwAAAMADIjk5WRaLRdWrV5erq6s2bNhgGzt+/LhCQ0MVGBgoSQoMDNTBgwcVFRVlm7N+/Xp5eHioXLlyGY5JhwIAAABIIav8xn3o0KFq1aqVChcurCtXrmjJkiXavHmz1q1bJ09PT7366qsaMGCAvL295eHhob59+yowMFC1a9eWJLVo0ULlypXTSy+9pAkTJigiIkLvvfeeevfu7VCXhIICAAAAyIKioqLUpUsXhYeHy9PTU5UqVdK6devUvHlzSdLkyZPl4uKijh07ymKxqGXLlpo5c6bt/dmyZdPq1avVq1cvBQYGys3NTV27dtWoUaMcyoPnUAAAAAApBO85a1jsrjUeMSy2s7JKRwcAAABAJkRBAQAAAMBpmaKgOHfunGJjY285n5iYqF9++cWAjAAAAPCwMhl4ZEWGFhTh4eF67LHHVKRIEXl5ealLly52hUV0dLQaN25sYIYAAAAA0mNoQfHOO+/IxcVFO3fu1Nq1a3XkyBE1btxY//zzj20Oe8YBAABwP7mYTIYdWZGhBcXPP/+sadOmqUaNGmrWrJm2bdsmf39/NWnSRNHR0ZIkUxb9YgEAAICHgaEFxeXLl5U3b17ba7PZrOXLl6to0aJq3Lix3VP70mKxWBQTE2N3WCyWe5k2AAAAHmDsoXCMoQVF8eLFdeDAAbtz2bNn17Jly1S8eHE98cQTt71GUFCQPD097Y6goKB7lTIAAACAFAx9sN3bb7+t/fv3a926dbeMXb9+XR07dtT333+v5OTkNK9hsVhu6UiYzWaHHhcOAAAA3PTF3nOGxe5cvZBhsZ1laEFx/fp1Xb16VR4eHmmO//333ypSpMh9zgwAAAAPqyX7jCsoXqiW9QoKQ5c8Zc+ePc1iQrpxW9mRI0fex4wAAAAAOCJTPNguLdHR0QoODjY6DQAAADxETCaTYUdWlN3I4KtWrUp3/NSpU/cpEwAAAADOMLSgaNeunUwmU7oPr8uqlRoAAADwMDB0yZO/v7+WL1+u5OTkVI99+/YZmR4AAAAeQi4GHlmRoXlXr15de/fuTXP8dt0LAAAAAMYydMnT4MGDFRcXl+Z4yZIltWnTpvuYEQAAAB52LLl3jKHPoQAAAAAym6/3hxkW+9kqAYbFdpahHQoAAAAgs6E/4ZisuvcDAAAAQCZAQQEAAADAaSx5AgAAAFJgU7Zj6FAAAAAAcBodCgAAACAFfuPuGL4vAAAAAE6joAAAAADgNJY8AQAAACmwKdsxdCgAAAAAOI0OBQAAAJAC/QnH0KEAAAAA4DQ6FAAAAEAKbKFwDB0KAAAAAE6joAAAAADgNJY8AQAAACm4sC3bIYYXFBcvXtSBAwdUuXJleXt768KFC5o3b54sFoueeeYZlS1b1ugUAQAAAKTB0IJi165datGihWJiYuTl5aX169frmWeeUfbs2ZWcnKzx48dr69atqlatmpFpAgAA4CHCpmzHGLqH4t1339Uzzzyjy5cva9iwYWrXrp2aNm2qP/74QydPnlSnTp00evRoI1MEAAAAkA6T1Wq1GhXc29tb27ZtU9myZZWYmKicOXMqJCREjz32mCRp3759euqpp3Tu3Lk0r2GxWGSxWOzOmc1mmc3me5o7AAAAHkyrD0UaFvuJCr6GxXaWoR2KhIQE5cqVS5Lk6uqq3LlzK1++fLbxfPny6eLFi+leIygoSJ6ennZHUFDQPc0bAAAADy6Tgf/LigzdQ/HII4/o1KlTKlq0qCTpq6++kr+/v208PDzcrsBIzdChQzVgwAC7c3QnAAAAgPvD0IKiU6dOioqKsr1u06aN3fiqVatsy5/SwvImAAAA3E1synaMoXsobufq1avKli0bBQMAAADumzWHo24/6R5pXb6AYbGdlamflH3x4kX16tXL6DQAAADwEHGRybAjK8rUBUV0dLSCg4ONTgMAAABAGgzdQ7Fq1ap0x0+dOnWfMgEAAADgDEMLinbt2slkMim9bRwmdsUAAADgPuLHT8cYuuTJ399fy5cvV3JycqrHvn37jEwPAAAAwG0YWlBUr15de/fuTXP8dt0LAAAA4G4zmYw7siJDlzwNHjxYcXFxaY6XLFlSmzZtuo8ZAQAAAHBEpn4OBQAAAHC//XT0vGGxW5TNb1hsZxnaoQAAAAAyG1MWfR6EUTL1cygAAAAAZG50KAAAAIAUXGhQOIQOBQAAAACn0aEAAAAAUmAPhWPoUAAAAABwGgUFAAAAAKex5AkAAABIIas+sdoodCgAAAAAOI0OBQAAAJACm7IdQ4cCAAAAgNMoKAAAAAA4jSVPAAAAQAo8KdsxdCgAAAAAOI0OBQAAAJACm7Idkyk7FMWLF9eJEyeMTgMAAADAbRjaoZg2bVqq50NDQ7VgwQL5+flJkt588837mRYAAACADDJZrVarUcFdXFxUsGBBZc9uX9ecOXNGAQEBcnV1lclk0qlTpwzKEAAAAA+brSf+MSx2vVJ5DYvtLEM7FD179tTOnTu1ZMkSlS1b1nbe1dVVP/30k8qVK2dgdgAAAABux9A9FLNmzdLw4cPVsmVLTZ8+3alrWCwWxcTE2B0Wi+UuZwoAAICHhcnAIysyfFN2+/btFRISohUrVqhVq1aKiIhw6P1BQUHy9PS0O4KCgu5RtgAAAABSMnQPRUpWq1Xjx4/XtGnTdP78eR04cCBDS54sFsstHQmz2Syz2XyvUgUAAMADLOTkJcNiB5b0Miy2szLNcyhMJpOGDh2qFi1aaOvWrfL398/Q+ygeAAAAAOMYvuTpv6pXr6633npLefPm1dmzZ/XKK68YnRIAAACQ6QQFBalmzZrKkyePChQooHbt2un48eN2c+Lj49W7d2/5+PjI3d1dHTt2VGRkpN2c0NBQtWnTRrlz51aBAgU0ePBgXb9+PcN5ZLqCIqXo6GgFBwcbnQYAAAAeIlllU/aWLVvUu3dv7dixQ+vXr1diYqJatGihuLg425z+/fvr+++/17Jly7RlyxaFhYWpQ4cOtvGkpCS1adNGCQkJ2r59u4KDg7Vw4UINHz4849+XkXsoVq1ale74qVOnNHDgQCUlJd2njAAAAPCw22HgHorad7CH4vz58ypQoIC2bNmiBg0a6PLly8qfP7+WLFmip59+WpJ07NgxlS1bViEhIapdu7Z+/PFHPfHEEwoLC5Ovr6+kG3diffvtt3X+/HnlyJHjtnEN3UPRrl07mUwmpVfTmExZ9QZaAAAAyJIM/PHzTm44dPnyZUmSt7e3JGnv3r1KTExUs2bNbHPKlCmjwoUL2wqKkJAQVaxY0VZMSFLLli3Vq1cvHT58WFWrVr1tXEOXPPn7+2v58uVKTk5O9di3b5+R6QEAAAD3lbOPREhOTla/fv1Ut25dVahQQZIUERGhHDlyyMvLy26ur6+v7VENERERdsXEzfGbYxlhaIeievXq2rt3r9q2bZvq+O26FwAAAMCDZOjQoRowYIDduYx0J3r37q1Dhw5p69at9yq1NBlaUAwePNhu08h/lSxZUps2bbqPGQEAAOBhZzJwzZMzj0To06ePVq9erV9++UWFChWynffz81NCQoIuXbpk16WIjIyUn5+fbc6uXbvsrnfzLlA359yOoUue6tevr8cffzzNcTc3NzVs2PA+ZgQAAABkDVarVX369NGKFSu0ceNGFStWzG68evXqcnV11YYNG2znjh8/rtDQUAUGBkqSAgMDdfDgQUVFRdnmrF+/Xh4eHhl6yLSUiZ6UDQAAAGQGu05dNiz2Y8U9Mzz3jTfe0JIlS7Ry5Uo9+uijtvOenp7KlSuXJKlXr15as2aNFi5cKA8PD/Xt21eStH37dkk3bhtbpUoVBQQEaMKECYqIiNBLL72k7t27a9y4cRnKg4ICAAAASCGrFBRp3Q11wYIF6tatm6QbD7YbOHCgvvzyS1ksFrVs2VIzZ860W8505swZ9erVS5s3b5abm5u6du2q8ePHK3v2jO2OoKAAAAAAUthtYEFR04GCIrPI1E/KBgAAAJC5UVAAAAAAcJqht40FAAAAMh0Dn5SdFdGhAAAAAOA0OhQAAABACkY+2C4rokMBAAAAwGkUFAAAAACcxpInAAAAIIU0nheHNNChAAAAAOA0OhQAAABACjQoHEOHAgAAAIDT6FAAAAAAKdGicAgdCgAAAABOy1QdCqvVqs2bN+vkyZPy9/dXy5Yt5erqanRaAAAAANJgaEHRunVrffnll/L09FR0dLRat26tXbt2KV++fLp48aJKly6tX375Rfnz5zcyTQAAADxEeFK2Ywxd8rR27VpZLBZJ0nvvvacrV67ozz//VFRUlM6cOSM3NzcNHz7cyBQBAAAApCPTLHnauHGjJkyYoGLFikmSChUqpA8//FA9evRI930Wi8VWlNxkNptlNpvvWa4AAAB4cPFgO8cYvinb9O/f2D///KMSJUrYjZUsWVJhYWHpvj8oKEienp52R1BQ0D3LFwAAAMD/Gd6h6Natm8xmsxITE3X69GmVL1/eNhYRESEvL6903z906FANGDDA7hzdCQAAAOD+MLSg6Nq1q+3Pbdu21dWrV+3Gv/32W1WpUiXda7C8CQAAAHcTK54cY7JarVajk0hLXFycsmXLppw5cxqdCgAAAB4Sv4deMSx25cJ5DIvtLMP3UKQnOjpab7zxhtFpAAAA4GFiMvDIgjJ9QREcHGx0GgAAAADSYOgeilWrVqU7furUqfuUCQAAAHADD7ZzjKF7KFxcXGQymZReCiaTSUlJSfcxKwAAADzMDpyNNSx2pUfcDYvtLEOXPPn7+2v58uVKTk5O9di3b5+R6QEAAAC4DUMLiurVq2vv3r1pjt+uewEAAADcbSaTcUdWZOgeisGDBysuLi7N8ZIlS2rTpk33MSMAAAAAjsjUz6EAAAAA7rdD54zbQ1GhEHsoAAAAADxEKCgAAAAAOM3QPRQAAABAppNFN0cbhQ4FAAAAAKfRoQAAAABS4EnZjqFDAQAAAMBpdCgAAACAFLLqA+aMQocCAAAAgNMoKAAAAAA4jSVPAAAAQAqseHIMHQoAAAAATqNDAQAAAKREi8IhdCgAAAAAOI2CAgAAAIDTWPIEAAAApMCTsh1jaIfi3LlzunDhgu31r7/+qs6dO6t+/fp68cUXFRISYmB2AAAAAG7H0IKiY8eO2rFjhyRp5cqVatSokWJjY1W3bl1dvXpVDRs21OrVq41MEQAAAA8Zk8m4IysyWa1Wq1HB3d3ddfDgQRUrVky1a9dW+/bt9fbbb9vGp0+frvnz52vfvn1GpQgAAICHzPGIq4bFftQvt2GxnWVohyJ79uy6cuWKJOn06dNq1aqV3XirVq10/PhxI1IDAADAQ8pk4JEVGVpQNGzYUF9++aUkqWrVqtq8ebPd+KZNm1SwYMF0r2GxWBQTE2N3WCyWe5UyAAAAgBQMvcvT+PHjVb9+fYWFhalevXp69913tXv3bpUtW1bHjx/X0qVLNWvWrHSvERQUpJEjR9qd++CDDzRixIh7mDkAAAAAyeA9FJL0559/6r333tMPP/yg2NhYSTeWQtWsWVODBw9Wu3bt0n2/xWK5pSNhNptlNpvvVcoAAAB4gP0RadweitK+WW8PheEFxU1Wq1VRUVFKTk5Wvnz55OrqanRKAAAAeAhRUDgm0zwp22QyydfXV/7+/rZi4uzZs3rllVcMzgwAAAAPE5OB/8uKMk1BkZro6GgFBwcbnQYAAACANBi6KXvVqlXpjp86deo+ZQIAAADAGYbuoXBxcZHJZFJ6KZhMJiUlJd3HrAAAAPAwOxl1zbDYJQvkMiy2swxd8uTv76/ly5crOTk51YMnZAMAAACZm6EFRfXq1bV37940x2/XvQAAAADuNp6U7RhD91AMHjxYcXFxaY6XLFlSmzZtuo8ZAQAAAHBEpnkOBQAAAJAZ/GngHooSWXAPhaEdCgAAACDTyaprjwySqZ9DAQAAACBzo0MBAAAApJBVn1htFDoUAAAAAJxGhwIAAABIwUSDwiF0KAAAAAA4jYICAAAAgNNY8gQAAACkwIonx9ChAAAAAOA0OhQAAABASrQoHEKHAgAAAIDTKCgAAAAAOI0lTwAAAEAKPCnbMXQoAAAAgCzol19+0ZNPPqmAgACZTCZ99913duNWq1XDhw+Xv7+/cuXKpWbNmunEiRN2c6Kjo9W5c2d5eHjIy8tLr776qmJjYx3Kg4ICAAAASMFkMu5wRFxcnCpXrqwZM2akOj5hwgRNmzZNs2bN0s6dO+Xm5qaWLVsqPj7eNqdz5846fPiw1q9fr9WrV+uXX35Rz549Hfu+rFar1bHUAQAAgAdXaLTFsNiFvc1Ovc9kMmnFihVq166dpBvdiYCAAA0cOFCDBg2SJF2+fFm+vr5auHChOnXqpKNHj6pcuXLavXu3atSoIUlau3atWrdurXPnzikgICBDsQ3tUEycOFFnzpwxMgUAAADAjsnAw2KxKCYmxu6wWBwvcE6fPq2IiAg1a9bMds7T01O1atVSSEiIJCkkJEReXl62YkKSmjVrJhcXF+3cuTPDsQwtKAYPHqwSJUqoefPmWrp0qRISEoxMBwAAADBUUFCQPD097Y6goCCHrxMRESFJ8vX1tTvv6+trG4uIiFCBAgXsxrNnzy5vb2/bnIwwfA/F3Llz5ebmppdeekkBAQHq16+fDh06ZHRaAAAAwH03dOhQXb582e4YOnSo0Wmly/CConXr1vruu+907tw5DRkyROvWrVPlypX12GOPac6cObpy5YrRKQIAAOAhYuSmbLPZLA8PD7vDbHZ8X4Wfn58kKTIy0u58ZGSkbczPz09RUVF249evX1d0dLRtTkYYXlDcVKBAAQ0ZMkRHjx7V5s2bVa5cOfXv31/+/v7pvu9urTMDAAAAHhTFihWTn5+fNmzYYDsXExOjnTt3KjAwUJIUGBioS5cuae/evbY5GzduVHJysmrVqpXhWIYWFKY07o1Vv359LVy4UGFhYZo8eXK617hb68wAAACAG4zclp1xsbGx2r9/v/bv3y/pxkbs/fv3KzQ0VCaTSf369dOYMWO0atUqHTx4UF26dFFAQIDtTlBly5bV448/rh49emjXrl3atm2b+vTpo06dOmX4Dk+SwbeNdXFxSXUziCMsFsstHQmz2exUawgAAAA4949xNwoqlDdHhudu3rxZjRs3vuV8165dtXDhQlmtVn3wwQeaPXu2Ll26pHr16mnmzJkqXbq0bW50dLT69Omj77//Xi4uLurYsaOmTZsmd3f3DOfBcygAAACAFLJKQZFZZJo9FKk5e/asXnnlFaPTAAAAwEMkqzwpO7PI1AVFdHS0goODjU4DAAAAQBqyGxl81apV6Y6fOnXqPmUCAAAA3JBFGwWGMXxTtslkUnopmEwmJSUl3cesAAAA8DALu2TcHooAL/ZQOMTf31/Lly9XcnJyqse+ffuMTA8AAAAPIfZQOMbQgqJ69ep2D9L4r9t1LwAAAAAYy9A9FIMHD1ZcXFya4yVLltSmTZvuY0YAAAAAHMFzKAAAAIAUIi4nGhbbz9PVsNjOytS3jQUAAACQuRm65AkAAADIdLLo5mij0KEAAAAA4DQKCgAAAABOY8kTAAAAkAIrnhxDhwIAAACA0+hQAAAAAClk1SdWG4UOBQAAAACn0aEAAAAAUjCxi8IhdCgAAAAAOI2CAgAAAIDTWPIEAAAApMSKJ4fQoQAAAADgNDoUAAAAQAo0KBxDhwIAAACA0ygoAAAAADjN8IJi9erVGj58uLZt2yZJ2rhxo1q3bq3HH39cs2fPNjg7AAAAPGxMJuOOrMjQguKzzz5T+/bttWbNGrVu3VqLFy9Wu3btVLBgQRUtWlT9+vXT1KlTjUwRAAAAQDpMVqvValTw8uXLq1+/furRo4c2bdqk1q1ba+LEiXrjjTckSQsXLtSECRN05MgRo1IEAADAQyY6Lsmw2N5u2QyL7SxDC4rcuXPr2LFjKly4sCQpR44c2rdvnypUqCBJ+uuvv1S+fHnFxcWleQ2LxSKLxWJ3zmw2y2w237vEAQAA8MCioHCMoUuefHx8dObMGUlSWFiYrl+/rtDQUNv4mTNn5O3tne41goKC5OnpaXcEBQXd07wBAADw4GIPhWMM7VD06dNHP/30k7p27apVq1apbNmy2rlzpyZPniyTyaTBgwerZs2amjdvXprXoEMBAACAu+mfq8Z1KPLmznodCkMfbPfhhx8qISFBX331lerUqaNPPvlE06ZNU9u2bZWYmKiGDRvetttA8QAAAAAYx9AORVri4+OVmJioPHnyGJ0KAAAAHjJ0KBxj+HMoUpMzZ07lyZNHZ8+e1SuvvGJ0OgAAAADSkCk7FDf9/vvvqlatmpKSjKsSAQAA8HC5dM24nz29cmW9DoWheyhWrVqV7vipU6fuUyYAAAAAnGFoh8LFxUUmk0nppWAymehQAAAA4L6hQ+EYQ/dQ+Pv7a/ny5UpOTk712Ldvn5HpAQAA4CFkMvB/WZGhBUX16tW1d+/eNMdv170AAAAAYCxD91AMHjxYcXFxaY6XLFlSmzZtuo8ZAQAA4GGXVZ9YbZRMfZcnAAAA4H6LiU82LLZHzkz5VId0GdqhAAAAADIbGhSOyXolEAAAAIBMg4ICAAAAgNNY8gQAAACkxJonh9ChAAAAAOA0OhQAAABACln1AXNGoUMBAAAAwGkUFAAAAACcxpInAAAAIAWelO0YOhQAAAAAnEaHAgAAAEiBBoVj6FAAAAAAcBoFBQAAAACnseQJAAAASIk1Tw6hQwEAAADAaYZ3KK5du6Yvv/xSW7duVXh4uFxcXFS8eHG1a9dOTZs2NTo9AAAAPGR4UrZjTFar1WpU8JMnT6pZs2a6du2azGazzp07p9atW+vChQvas2ePOnTooCVLlih7dsPrHgAAADwkriUaFzuXq3GxnWXokqc333xTjz/+uCIiIhQaGqqgoCAlJydrx44dOnr0qHbv3q0xY8YYmSIAAAAeMiaTcUdWZGiHws3NTfv371epUqUkSQkJCXJ3d1d4eLh8fHz0v/buPSrKMoHj+G8EZpgAQRCEUWcAUfACJKCsl5U1CfF4ECTTXDRYtHM0SNAidVtWy1WkVvOSB7wgYqZpJkhYErKCuquoIIUtISp5RfGuYALOPPuHwYo3FJl3Kn6fc+aceGeY7/MSPvrM+84727dvR2xsLCoqKgw1RCIiIiJqY+7cNVzb9Dd4Yo5Bh2xlZYVbt241fn379m3cvXsXcrkcAODh4YHKysonPkdtbS1qa2ubbFMoFFAoFK0/YCIiIiIiasKgpzy9/PLLmDFjBn788UdUVFRgypQpePHFF2FhYQEAOH36NOzs7J74HAkJCbC0tGxyS0hIaPGYamtrMXfu3IcWKVJh33D9trzv7PN3j/222W/L+97W+21535+GqbHhbr9FBj3lqaqqCsHBwSgoKIBMJkPXrl2Rnp6Ovn37AgC2bt2KyspKvPXWW499jtY+QnHz5k1YWlrixo0baN++fYue43mwb7h+W9539vm7x37b7LflfW/r/ba879T6DLoOsrOzw/79+1FeXo7a2lq4ubk1uaLTmDFjmn0Ont5ERERERGQ4v4oPtuvevTv69Onz0OVhz5w5g8jISAONioiIiIiImvOrWFA8ztWrV5GWlmboYRARERER0WMY9JSnzMzMJ95/8uRJiUbyfwqFAnPmzDHYaVTsG67flvedff7usd82+21539t6vy3vO7U+g74pu127dpDJZHjSEGQyGbRarYSjIiIiIiKip2XQU54cHBywbds26HS6R96KiooMOTwiIiIiImqGQRcU3t7eKCwsfOz9zR29ICIiIiIiwzLoeyji4uJQU1Pz2PtdXFywe/duCUdERERERETPwqDvoSAiIiIiot+2X/VlYw1hxYoVcHR0hKmpKXx9fXHw4EFJunv27EFQUBBUKhVkMhkyMjIk6QJAQkIC+vXrBwsLC9jZ2SEkJARlZWWS9ZOSkuDh4YH27dujffv2GDBgAL755hvJ+g9auHAhZDIZYmNjJenNnTsXMpmsyc3NzU2SdoNz585hwoQJsLGxgVKphLu7Ow4fPqz3rqOj40P7LpPJEBUVpfc2AGi1WsTHx8PJyQlKpRLdunXDvHnzJD3V8tatW4iNjYVGo4FSqcTAgQNx6NAhvbSam2eEEPj73/8OBwcHKJVK+Pv7o7y8XLL+tm3bEBAQABsbG8hkMhQXF0vSrq+vx8yZM+Hu7g4zMzOoVCq8/vrrOH/+vCR94N484ObmBjMzM3To0AH+/v4oKCiQrH+/KVOmQCaTYcmSJZL1IyIiHpoHAgMDJesDQGlpKUaNGgVLS0uYmZmhX79+OH36tN7bj5oDZTIZPvroo+duP02/uroa0dHR6NKlC5RKJXr16oXk5ORWaT9N/+LFi4iIiIBKpcILL7yAwMDAVp13SBpcUNxn8+bNmDFjBubMmYOioiJ4enpi+PDhqKqq0nu7pqYGnp6eWLFihd5bD8rPz0dUVBQOHDiAnJwc1NfXIyAg4Imno7WmLl26YOHChSgsLMThw4fx0ksvITg4GD/88IMk/fsdOnQIK1euhIeHh6Td3r17o7KysvG2b98+ydrXrl3DoEGDYGJigm+++Qb//e9/sWjRInTo0EHv7UOHDjXZ75ycHADAq6++qvc2ACQmJiIpKQmffPIJSktLkZiYiA8//BDLly+XpA8AkydPRk5ODj799FOUlJQgICAA/v7+OHfuXKu3mptnPvzwQyxbtgzJyckoKCiAmZkZhg8fjjt37kjSr6mpweDBg5GYmNgqvadt3759G0VFRYiPj0dRURG2bduGsrIyjBo1SpI+APTo0QOffPIJSkpKsG/fPjg6OiIgIACXLl2SpN8gPT0dBw4cgEqlapXus/QDAwObzAebNm2SrH/ixAkMHjwYbm5uyMvLw/fff4/4+HiYmprqvX3/PldWVmLt2rWQyWR45ZVXnrv9NP0ZM2Zg586d2LBhA0pLSxEbG4vo6OhmL+3fGn0hBEJCQnDy5Els374dR44cgUajgb+/v2T/BqFWIqhR//79RVRUVOPXWq1WqFQqkZCQIOk4AIj09HRJm/erqqoSAER+fr7BxtChQwexZs0aSZu3bt0S3bt3Fzk5OcLPz0/ExMRI0p0zZ47w9PSUpPUoM2fOFIMHDzZY/34xMTGiW7duQqfTSdIbOXKkiIyMbLItNDRUhIWFSdK/ffu2MDIyEllZWU22e3l5iffee0+v7QfnGZ1OJ+zt7cVHH33UuO369etCoVCITZs26b1/v4qKCgFAHDlypNW7zbUbHDx4UAAQp06dMkj/xo0bAoDYtWuXZP2zZ8+Kzp07i6NHjwqNRiM+/vjjVm8/rh8eHi6Cg4P10nua/rhx48SECRMM0n5QcHCweOmllyTr9+7dW3zwwQdNtulrDnqwX1ZWJgCIo0ePNm7TarXC1tZWrF69utX7pD88QvGLuro6FBYWwt/fv3Fbu3bt4O/vj/379xtwZNK7ceMGAMDa2lrytlarxeeff46amhoMGDBA0nZUVBRGjhzZ5HdAKuXl5VCpVHB2dkZYWFirHGZ/WpmZmfDx8cGrr74KOzs79O3bF6tXr5as36Curg4bNmxAZGQkZDKZJM2BAwciNzcXx44dAwB899132LdvH0aMGCFJ/+7du9BqtQ+9CqpUKiU9SgUAFRUVuHDhQpPff0tLS/j6+ra5ORC4Nw/KZDJYWVlJ3q6rq8OqVatgaWkJT09PSZo6nQ4TJ05EXFwcevfuLUnzQXl5ebCzs4OrqyumTp2KK1euSNLV6XTYsWMHevTogeHDh8POzg6+vr6Snnrc4OLFi9ixYwcmTZokWXPgwIHIzMzEuXPnIITA7t27cezYMQQEBOi9XVtbCwBN5sB27dpBoVBIPgfS8+GC4heXL1+GVqtFp06dmmzv1KkTLly4YKBRSU+n0yE2NhaDBg1Cnz59JOuWlJTA3NwcCoUCU6ZMQXp6Onr16iVZ//PPP0dRURESEhIkazbw9fXFunXrsHPnTiQlJaGiogJ//OMfcevWLUn6J0+eRFJSErp3747s7GxMnToV06ZNQ1pamiT9BhkZGbh+/ToiIiIka86aNQuvvfYa3NzcYGJigr59+yI2NhZhYWGS9C0sLDBgwADMmzcP58+fh1arxYYNG7B//35UVlZKMoYGDfNcW58DAeDOnTuYOXMmxo8fj/bt20vWzcrKgrm5OUxNTfHxxx8jJycHHTt2lKSdmJgIY2NjTJs2TZLegwIDA7F+/Xrk5uYiMTER+fn5GDFihCQfbFtVVYXq6mosXLgQgYGB+PbbbzF69GiEhoYiPz9f7/37paWlwcLCAqGhoZI1ly9fjl69eqFLly6Qy+UIDAzEihUrMGTIEL233dzcoFarMXv2bFy7dg11dXVITEzE2bNnJZ8D6fkY9LKx9OsTFRWFo0ePSv7KgKurK4qLi3Hjxg1s3boV4eHhyM/Pl2RRcebMGcTExCAnJ6dVzpd9Vve/Gu7h4QFfX19oNBps2bJFklepdDodfHx8sGDBAgBA3759cfToUSQnJyM8PFzv/QYpKSkYMWJEq5+7/SRbtmzBZ599ho0bN6J3794oLi5GbGwsVCqVZPv+6aefIjIyEp07d4aRkRG8vLwwfvz4J35GD+lPfX09xo4dCyEEkpKSJG0PHToUxcXFuHz5MlavXo2xY8eioKAAdnZ2eu0WFhZi6dKlKCoqkuzo4INee+21xv92d3eHh4cHunXrhry8PAwbNkyvbZ1OBwAIDg7G9OnTAQAvvvgi/vOf/yA5ORl+fn567d9v7dq1CAsLk/TvouXLl+PAgQPIzMyERqPBnj17EBUVBZVKpfcj9iYmJti2bRsmTZoEa2trGBkZwd/fHyNGjODnkP3G8AjFLzp27AgjIyNcvHixyfaLFy/C3t7eQKOSVnR0NLKysrB792506dJF0rZcLoeLiwu8vb2RkJAAT09PLF26VJJ2YWEhqqqq4OXlBWNjYxgbGyM/Px/Lli2DsbGxJK+Q3c/Kygo9evTA8ePHJek5ODg8tHDr2bOnpKddnTp1Crt27cLkyZMlawL3Pgun4SiFu7s7Jk6ciOnTp0t6pKpbt27Iz89HdXU1zpw5g4MHD6K+vh7Ozs6SjQFA4zzXlufAhsXEqVOnkJOTI+nRCQAwMzODi4sL/vCHPyAlJQXGxsZISUnRe3fv3r2oqqqCWq1unANPnTqFt99+G46OjnrvP4qzszM6duwoyTzYsWNHGBsbG3we3Lt3L8rKyiSdB3/++Wf89a9/xeLFixEUFAQPDw9ER0dj3Lhx+Oc//ynJGLy9vVFcXIzr16+jsrISO3fuxJUrVySfA+n5cEHxC7lcDm9vb+Tm5jZu0+l0yM3NlfxcfqkJIRAdHY309HT861//gpOTk6GHBJ1O13hupb4NGzYMJSUlKC4ubrz5+PggLCwMxcXFMDIykmQcDaqrq3HixAk4ODhI0hs0aNBDlwk+duwYNBqNJH0ASE1NhZ2dHUaOHClZE7h3dZ927ZpOg0ZGRo2vWErJzMwMDg4OuHbtGrKzsxEcHCxp38nJCfb29k3mwJs3b6KgoOB3PwcC/19MlJeXY9euXbCxsTH0kCSbBydOnIjvv/++yRyoUqkQFxeH7Oxsvfcf5ezZs7hy5Yok86BcLke/fv0MPg+mpKTA29tbsvfNAPd+7+vr638V86ClpSVsbW1RXl6Ow4cPSz4H0vPhKU/3mTFjBsLDw+Hj44P+/ftjyZIlqKmpwV/+8he9t6urq5u8ElNRUYHi4mJYW1tDrVbrtR0VFYWNGzdi+/btsLCwaDxf2tLSEkqlUq9tAJg9ezZGjBgBtVqNW7duYePGjcjLy5PsLzILC4uH3i9iZmYGGxsbSd5H8s477yAoKAgajQbnz5/HnDlzYGRkhPHjx+u9DQDTp0/HwIEDsWDBAowdOxYHDx7EqlWrsGrVKkn6Op0OqampCA8Ph7GxtFNSUFAQ5s+fD7Vajd69e+PIkSNYvHgxIiMjJRtDdnY2hBBwdXXF8ePHERcXBzc3N73MO83NM7GxsfjHP/6B7t27w8nJCfHx8VCpVAgJCZGkf/XqVZw+fbrx8x8a/oFnb2//3EdJntR2cHDAmDFjUFRUhKysLGi12sZ50NraGnK5/LnazfVtbGwwf/58jBo1Cg4ODrh8+TJWrFiBc+fOtdollJv72T+4gDIxMYG9vT1cXV313re2tsb777+PV155Bfb29jhx4gTeffdduLi4YPjw4Xrvq9VqxMXFYdy4cRgyZAiGDh2KnTt34quvvkJeXp7e28C9xfsXX3yBRYsWPXfvWft+fn6Ii4uDUqmERqNBfn4+1q9fj8WLF0vS/+KLL2Brawu1Wo2SkhLExMQgJCREkjeFUysy6DWmfoWWL18u1Gq1kMvlon///uLAgQOSdHfv3i0APHQLDw/Xe/tRXQAiNTVV720hhIiMjBQajUbI5XJha2srhg0bJr799ltJ2o8j5WVjx40bJxwcHIRcLhedO3cW48aNE8ePH5ek3eCrr74Sffr0EQqFQri5uYlVq1ZJ1s7OzhYARFlZmWTNBjdv3hQxMTFCrVYLU1NT4ezsLN577z1RW1sr2Rg2b94snJ2dhVwuF/b29iIqKkpcv35dL63m5hmdTifi4+NFp06dhEKhEMOGDWvV/y/N9VNTUx95/5w5c/TabrhM7aNuu3fvfu52c/2ff/5ZjB49WqhUKiGXy4WDg4MYNWqUOHjwYKu0m+s/SmtfNvZJ/du3b4uAgABha2srTExMhEajEW+88Ya4cOGCJP0GKSkpwsXFRZiamgpPT0+RkZEhWXvlypVCqVTq5c9+c/3KykoREREhVCqVMDU1Fa6urmLRokWtdvnu5vpLly4VXbp0ESYmJkKtVou//e1vks7B1DpkQvBdL0RERERE1DJ8DwUREREREbUYFxRERERERNRiXFAQEREREVGLcUFBREREREQtxgUFERERERG1GBcURERERETUYlxQEBERERFRi3FBQURERERELcYFBRHRr0xERARCQkIav/7Tn/6E2NhYyceRl5cHmUyG69evS94mIqLfDi4oiIieUkREBGQyGWQyGeRyOVxcXPDBBx/g7t27eu1u27YN8+bNe6rHchFARERSMzb0AIiIfksCAwORmpqK2tpafP3114iKioKJiQlmz57d5HF1dXWQy+Wt0rS2tm6V5yEiItIHHqEgInoGCoUC9vb20Gg0mDp1Kvz9/ZGZmdl4mtL8+fOhUqng6uoKADhz5gzGjh0LKysrWFtbIzg4GD/99FPj82m1WsyYMQNWVlawsbHBu+++CyFEk+aDpzzV1tZi5syZ6Nq1KxQKBVxcXJCSkoKffvoJQ4cOBQB06NABMpkMERERAACdToeEhAQ4OTlBqVTC09MTW7dubdL5+uuv0aNHDyiVSgwdOrTJOImIiB6HCwoiouegVCpRV1cHAMjNzUVZWRlycnKQlZWF+vp6DB8+HBYWFti7dy/+/e9/w9zcHIGBgY3fs2jRIqxbtw5r167Fvn37cPXqVaSnpz+x+frrr2PTpk1YtmwZSktLsXLlSpibm6Nr16748ssvAQBlZWWorKzE0qVLAQAJCQlYv349kpOT8cMPP2D69OmYMGEC8vPzAdxb+ISGhiIoKAjFxcWYPHkyZs2apa8fGxER/Y7wlCciohYQQiA3NxfZ2dl46623cOnSJZiZmWHNmjWNpzpt2LABOp0Oa9asgUwmAwCkpqbCysoKeXl5CAgIwJIlSzB79myEhoYCAJKTk5Gdnf3Y7rFjx7Blyxbk5OTA398fAODs7Nx4f8PpUXZ2drCysgJw74jGggULsGvXLgwYMKDxe/bt24eVK1fCz88PSUlJ6NatGxYtWgQAcHV1RUlJCRITE1vxp0ZERL9HXFAQET2DrKwsmJubo76+HjqdDn/+858xd+5cREVFwd3dvcn7Jr777jscP34cFhYWTZ7jzp07OHHiBG7cuIHKykr4+vo23mdsbAwfH5+HTntqUFxcDCMjI/j5+T31mI8fP47bt2/j5ZdfbrK9rq4Offv2BQCUlpY2GQeAxsUHERHRk3BBQUT0DIYOHYqkpCTI5XKoVCoYG/9/GjUzM2vy2Orqanh7e+Ozzz576HlsbW1b1Fcqlc/8PdXV1QCAHTt2oHPnzk3uUygULRoHERFRAy4oiIiegZmZGVxcXJ7qsV5eXti8eTPs7OzQvn37Rz7GwcEBBQUFGDJkCADg7t27KCwshJeX1yMf7+7uDp1Oh/z8/MZTnu7XcIREq9U2buvVqxcUCgVOnz792CMbPXv2RGZmZpNtBw4caH4niYiozeObsomI9CQsLAwdO3ZEcHAw9u7di4qKCuTl5WHatGk4e/YsACAmJgYLFy5ERkYGfvzxR7z55ptP/AwJR0dHhIeHIzIyEhkZGY3PuWXLFgCARqOBTCZDVlYWLl26hOrqalhYWOCdd97B9OnTkZaWhhMnTqCoqAjLly9HWloaAGDKlCkoLy9HXFwcysrKsHHjRqxbt07fPyIiIvod4IKCiEhPXnjhBezZswdqtRqhoaHo2bMnJk2ahDt37jQesXj77bcxceJEhIeHY8CAAbCwsMDo0aOf+LxJSUkYM2YM3nzzTbi5ueGNN95ATU0NAKBz5854//33MWvWLHTq1AnR0dEAgHnz5iE+Ph4JCQno2bMnAgMDsWPHDjg5OQEA1Go1vvzyS2RkZMDT0xPJyclYsGCBHn86RET0eyETj3vnHxERERERUTN4hIKIiIiIiFqMCwoiIiIiImoxLiiIiIiIiKjFuKAgIiIiIqIW44KCiIiIiIhajAsKIiIiIiJqMS4oiIiIiIioxbigICIiIiKiFuOCgoiIiIiIWowLCiIiIiIiajEuKIiIiIiIqMX+B+XJurfvaz8UAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "\n",
        "labels = label_encoder.classes_\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "973U9X8u1NEB",
        "outputId": "72cafbc2-6c53-49c7-e338-5f73a28242e4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([[0.77364291, 0.33883058, 0.09364821, ..., 0.41482112, 0.50884086,\n",
              "         0.45432099],\n",
              "        [0.12086401, 0.67516242, 0.95276873, ..., 0.60562181, 0.74165029,\n",
              "         0.58106996],\n",
              "        [0.39398107, 0.12343828, 0.34364821, ..., 0.06218058, 0.03683694,\n",
              "         0.0691358 ],\n",
              "        ...,\n",
              "        [0.03478683, 0.42778611, 0.58631922, ..., 0.5153322 , 0.39931238,\n",
              "         0.51440329],\n",
              "        [0.63991586, 0.44777611, 0.43241042, ..., 0.10477002, 0.40422397,\n",
              "         0.32016461],\n",
              "        [0.95861985, 0.39030485, 0.49429967, ..., 0.36201022, 0.37180747,\n",
              "         0.39259259]]),\n",
              " array([ 0, 17,  1, ..., 14, 14,  1]))"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train, y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "diA7c3WtQof3"
      },
      "outputs": [],
      "source": [
        "vgg16_model = VGG16(pooling='avg', weights='imagenet', include_top=False, input_shape=(150,150,3))\n",
        "for layers in vgg16_model.layers:\n",
        "            layers.trainable=False\n",
        "last_output = vgg16_model.layers[-1].output\n",
        "vgg_x = Flatten()(last_output)\n",
        "vgg_x = Dense(128, activation = 'relu')(vgg_x)\n",
        "vgg_x = Dense(6, activation = 'softmax')(vgg_x)\n",
        "vgg16_final_model = Model(vgg16_model.input, vgg_x)\n",
        "vgg16_final_model.compile(loss = 'categorical_crossentropy', optimizer= 'adam', metrics=['acc'])\n",
        "\n",
        "# VGG16\n",
        "number_of_epochs = vgg_epoch\n",
        "vgg16_filepath = 'vgg_16_'+'-saved-model-{epoch:02d}-acc-{val_acc:.2f}.hdf5'\n",
        "vgg_checkpoint = tf.keras.callbacks.ModelCheckpoint(vgg16_filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "vgg_early_stopping = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
        "vgg16_history = vgg16_final_model.fit(train_generator, epochs = number_of_epochs ,validation_data = validation_generator,callbacks=[vgg_checkpoint,vgg_early_stopping],verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b85zXLNeSBmD",
        "outputId": "32e68807-c249-4a80-cf5e-7d977363107a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/250\n",
            "494/494 [==============================] - 7s 6ms/step - loss: 2.5264 - accuracy: 0.2263 - val_loss: 2.4310 - val_accuracy: 0.2452\n",
            "Epoch 2/250\n",
            "494/494 [==============================] - 2s 5ms/step - loss: 2.4140 - accuracy: 0.2495 - val_loss: 2.3912 - val_accuracy: 0.2535\n",
            "Epoch 3/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 2.3710 - accuracy: 0.2590 - val_loss: 2.3435 - val_accuracy: 0.2670\n",
            "Epoch 4/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 2.3485 - accuracy: 0.2666 - val_loss: 2.3252 - val_accuracy: 0.2647\n",
            "Epoch 5/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 2.3219 - accuracy: 0.2732 - val_loss: 2.3129 - val_accuracy: 0.2748\n",
            "Epoch 6/250\n",
            "494/494 [==============================] - 2s 4ms/step - loss: 2.3054 - accuracy: 0.2785 - val_loss: 2.2908 - val_accuracy: 0.2786\n",
            "Epoch 7/250\n",
            "494/494 [==============================] - 2s 4ms/step - loss: 2.2915 - accuracy: 0.2815 - val_loss: 2.2865 - val_accuracy: 0.2761\n",
            "Epoch 8/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 2.2748 - accuracy: 0.2857 - val_loss: 2.2659 - val_accuracy: 0.2827\n",
            "Epoch 9/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 2.2612 - accuracy: 0.2919 - val_loss: 2.2649 - val_accuracy: 0.2799\n",
            "Epoch 10/250\n",
            "494/494 [==============================] - 3s 5ms/step - loss: 2.2460 - accuracy: 0.2946 - val_loss: 2.2654 - val_accuracy: 0.2832\n",
            "Epoch 11/250\n",
            "494/494 [==============================] - 2s 4ms/step - loss: 2.2342 - accuracy: 0.2996 - val_loss: 2.2483 - val_accuracy: 0.2936\n",
            "Epoch 12/250\n",
            "494/494 [==============================] - 2s 4ms/step - loss: 2.2280 - accuracy: 0.2968 - val_loss: 2.2450 - val_accuracy: 0.2913\n",
            "Epoch 13/250\n",
            "494/494 [==============================] - 3s 5ms/step - loss: 2.2164 - accuracy: 0.2975 - val_loss: 2.2296 - val_accuracy: 0.2984\n",
            "Epoch 14/250\n",
            "494/494 [==============================] - 4s 7ms/step - loss: 2.2084 - accuracy: 0.3006 - val_loss: 2.2202 - val_accuracy: 0.2971\n",
            "Epoch 15/250\n",
            "494/494 [==============================] - 2s 5ms/step - loss: 2.1944 - accuracy: 0.3080 - val_loss: 2.2166 - val_accuracy: 0.3032\n",
            "Epoch 16/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 2.1878 - accuracy: 0.3083 - val_loss: 2.2123 - val_accuracy: 0.3060\n",
            "Epoch 17/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 2.1777 - accuracy: 0.3116 - val_loss: 2.2070 - val_accuracy: 0.3065\n",
            "Epoch 18/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 2.1666 - accuracy: 0.3135 - val_loss: 2.1978 - val_accuracy: 0.3057\n",
            "Epoch 19/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 2.1649 - accuracy: 0.3140 - val_loss: 2.1924 - val_accuracy: 0.3080\n",
            "Epoch 20/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 2.1565 - accuracy: 0.3149 - val_loss: 2.1976 - val_accuracy: 0.3029\n",
            "Epoch 21/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 2.1489 - accuracy: 0.3191 - val_loss: 2.1882 - val_accuracy: 0.3121\n",
            "Epoch 22/250\n",
            "494/494 [==============================] - 2s 4ms/step - loss: 2.1434 - accuracy: 0.3196 - val_loss: 2.1896 - val_accuracy: 0.3095\n",
            "Epoch 23/250\n",
            "494/494 [==============================] - 2s 4ms/step - loss: 2.1330 - accuracy: 0.3226 - val_loss: 2.1829 - val_accuracy: 0.3113\n",
            "Epoch 24/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 2.1257 - accuracy: 0.3231 - val_loss: 2.1796 - val_accuracy: 0.3113\n",
            "Epoch 25/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 2.1184 - accuracy: 0.3285 - val_loss: 2.1709 - val_accuracy: 0.3161\n",
            "Epoch 26/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 2.1191 - accuracy: 0.3260 - val_loss: 2.1792 - val_accuracy: 0.3148\n",
            "Epoch 27/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 2.1137 - accuracy: 0.3270 - val_loss: 2.1598 - val_accuracy: 0.3138\n",
            "Epoch 28/250\n",
            "494/494 [==============================] - 2s 5ms/step - loss: 2.1060 - accuracy: 0.3325 - val_loss: 2.1559 - val_accuracy: 0.3247\n",
            "Epoch 29/250\n",
            "494/494 [==============================] - 2s 4ms/step - loss: 2.1030 - accuracy: 0.3305 - val_loss: 2.1566 - val_accuracy: 0.3237\n",
            "Epoch 30/250\n",
            "494/494 [==============================] - 2s 4ms/step - loss: 2.0961 - accuracy: 0.3323 - val_loss: 2.1537 - val_accuracy: 0.3255\n",
            "Epoch 31/250\n",
            "494/494 [==============================] - 2s 4ms/step - loss: 2.0886 - accuracy: 0.3340 - val_loss: 2.1490 - val_accuracy: 0.3242\n",
            "Epoch 32/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 2.0897 - accuracy: 0.3325 - val_loss: 2.1483 - val_accuracy: 0.3255\n",
            "Epoch 33/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 2.0787 - accuracy: 0.3358 - val_loss: 2.1442 - val_accuracy: 0.3290\n",
            "Epoch 34/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 2.0763 - accuracy: 0.3384 - val_loss: 2.1550 - val_accuracy: 0.3217\n",
            "Epoch 35/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 2.0742 - accuracy: 0.3399 - val_loss: 2.1449 - val_accuracy: 0.3288\n",
            "Epoch 36/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 2.0691 - accuracy: 0.3372 - val_loss: 2.1466 - val_accuracy: 0.3224\n",
            "Epoch 37/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 2.0640 - accuracy: 0.3412 - val_loss: 2.1466 - val_accuracy: 0.3295\n",
            "Epoch 38/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 2.0545 - accuracy: 0.3425 - val_loss: 2.1365 - val_accuracy: 0.3240\n",
            "Epoch 39/250\n",
            "494/494 [==============================] - 2s 4ms/step - loss: 2.0570 - accuracy: 0.3438 - val_loss: 2.1404 - val_accuracy: 0.3267\n",
            "Epoch 40/250\n",
            "494/494 [==============================] - 2s 5ms/step - loss: 2.0478 - accuracy: 0.3476 - val_loss: 2.1346 - val_accuracy: 0.3321\n",
            "Epoch 41/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 2.0477 - accuracy: 0.3424 - val_loss: 2.1408 - val_accuracy: 0.3328\n",
            "Epoch 42/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 2.0444 - accuracy: 0.3478 - val_loss: 2.1502 - val_accuracy: 0.3247\n",
            "Epoch 43/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 2.0378 - accuracy: 0.3473 - val_loss: 2.1364 - val_accuracy: 0.3341\n",
            "Epoch 44/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 2.0290 - accuracy: 0.3497 - val_loss: 2.1264 - val_accuracy: 0.3316\n",
            "Epoch 45/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 2.0336 - accuracy: 0.3510 - val_loss: 2.1313 - val_accuracy: 0.3295\n",
            "Epoch 46/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 2.0299 - accuracy: 0.3503 - val_loss: 2.1282 - val_accuracy: 0.3343\n",
            "Epoch 47/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 2.0248 - accuracy: 0.3532 - val_loss: 2.1350 - val_accuracy: 0.3308\n",
            "Epoch 48/250\n",
            "494/494 [==============================] - 2s 4ms/step - loss: 2.0206 - accuracy: 0.3524 - val_loss: 2.1316 - val_accuracy: 0.3295\n",
            "Epoch 49/250\n",
            "494/494 [==============================] - 2s 4ms/step - loss: 2.0130 - accuracy: 0.3554 - val_loss: 2.1234 - val_accuracy: 0.3338\n",
            "Epoch 50/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 2.0194 - accuracy: 0.3533 - val_loss: 2.1188 - val_accuracy: 0.3369\n",
            "Epoch 51/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 2.0062 - accuracy: 0.3561 - val_loss: 2.1273 - val_accuracy: 0.3267\n",
            "Epoch 52/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 2.0058 - accuracy: 0.3593 - val_loss: 2.1229 - val_accuracy: 0.3333\n",
            "Epoch 53/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 2.0027 - accuracy: 0.3578 - val_loss: 2.1183 - val_accuracy: 0.3387\n",
            "Epoch 54/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 2.0058 - accuracy: 0.3571 - val_loss: 2.1137 - val_accuracy: 0.3366\n",
            "Epoch 55/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 2.0034 - accuracy: 0.3593 - val_loss: 2.1259 - val_accuracy: 0.3356\n",
            "Epoch 56/250\n",
            "494/494 [==============================] - 2s 4ms/step - loss: 1.9938 - accuracy: 0.3624 - val_loss: 2.1125 - val_accuracy: 0.3351\n",
            "Epoch 57/250\n",
            "494/494 [==============================] - 2s 4ms/step - loss: 1.9929 - accuracy: 0.3639 - val_loss: 2.1209 - val_accuracy: 0.3311\n",
            "Epoch 58/250\n",
            "494/494 [==============================] - 2s 4ms/step - loss: 1.9888 - accuracy: 0.3592 - val_loss: 2.1110 - val_accuracy: 0.3359\n",
            "Epoch 59/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.9939 - accuracy: 0.3640 - val_loss: 2.1066 - val_accuracy: 0.3351\n",
            "Epoch 60/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.9909 - accuracy: 0.3572 - val_loss: 2.1069 - val_accuracy: 0.3356\n",
            "Epoch 61/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.9832 - accuracy: 0.3601 - val_loss: 2.1101 - val_accuracy: 0.3402\n",
            "Epoch 62/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.9865 - accuracy: 0.3590 - val_loss: 2.1153 - val_accuracy: 0.3409\n",
            "Epoch 63/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.9829 - accuracy: 0.3617 - val_loss: 2.1095 - val_accuracy: 0.3419\n",
            "Epoch 64/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.9760 - accuracy: 0.3672 - val_loss: 2.1080 - val_accuracy: 0.3432\n",
            "Epoch 65/250\n",
            "494/494 [==============================] - 2s 4ms/step - loss: 1.9688 - accuracy: 0.3690 - val_loss: 2.1148 - val_accuracy: 0.3480\n",
            "Epoch 66/250\n",
            "494/494 [==============================] - 2s 4ms/step - loss: 1.9733 - accuracy: 0.3670 - val_loss: 2.1053 - val_accuracy: 0.3379\n",
            "Epoch 67/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.9753 - accuracy: 0.3702 - val_loss: 2.1062 - val_accuracy: 0.3422\n",
            "Epoch 68/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.9688 - accuracy: 0.3704 - val_loss: 2.1018 - val_accuracy: 0.3470\n",
            "Epoch 69/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 1.9639 - accuracy: 0.3706 - val_loss: 2.1035 - val_accuracy: 0.3427\n",
            "Epoch 70/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.9597 - accuracy: 0.3706 - val_loss: 2.1035 - val_accuracy: 0.3475\n",
            "Epoch 71/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.9589 - accuracy: 0.3712 - val_loss: 2.1048 - val_accuracy: 0.3503\n",
            "Epoch 72/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.9589 - accuracy: 0.3720 - val_loss: 2.1071 - val_accuracy: 0.3432\n",
            "Epoch 73/250\n",
            "494/494 [==============================] - 2s 4ms/step - loss: 1.9503 - accuracy: 0.3739 - val_loss: 2.1003 - val_accuracy: 0.3422\n",
            "Epoch 74/250\n",
            "494/494 [==============================] - 2s 5ms/step - loss: 1.9525 - accuracy: 0.3757 - val_loss: 2.1093 - val_accuracy: 0.3409\n",
            "Epoch 75/250\n",
            "494/494 [==============================] - 2s 4ms/step - loss: 1.9476 - accuracy: 0.3754 - val_loss: 2.1013 - val_accuracy: 0.3409\n",
            "Epoch 76/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.9450 - accuracy: 0.3765 - val_loss: 2.1007 - val_accuracy: 0.3541\n",
            "Epoch 77/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.9525 - accuracy: 0.3706 - val_loss: 2.1030 - val_accuracy: 0.3468\n",
            "Epoch 78/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.9509 - accuracy: 0.3695 - val_loss: 2.1010 - val_accuracy: 0.3425\n",
            "Epoch 79/250\n",
            "494/494 [==============================] - 2s 4ms/step - loss: 1.9407 - accuracy: 0.3781 - val_loss: 2.1066 - val_accuracy: 0.3371\n",
            "Epoch 80/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.9432 - accuracy: 0.3773 - val_loss: 2.0900 - val_accuracy: 0.3437\n",
            "Epoch 81/250\n",
            "494/494 [==============================] - 2s 4ms/step - loss: 1.9396 - accuracy: 0.3778 - val_loss: 2.1011 - val_accuracy: 0.3445\n",
            "Epoch 82/250\n",
            "494/494 [==============================] - 2s 4ms/step - loss: 1.9420 - accuracy: 0.3773 - val_loss: 2.1037 - val_accuracy: 0.3435\n",
            "Epoch 83/250\n",
            "494/494 [==============================] - 2s 4ms/step - loss: 1.9319 - accuracy: 0.3782 - val_loss: 2.0957 - val_accuracy: 0.3442\n",
            "Epoch 84/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 1.9352 - accuracy: 0.3795 - val_loss: 2.0888 - val_accuracy: 0.3488\n",
            "Epoch 85/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.9416 - accuracy: 0.3739 - val_loss: 2.0982 - val_accuracy: 0.3427\n",
            "Epoch 86/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.9364 - accuracy: 0.3745 - val_loss: 2.1058 - val_accuracy: 0.3427\n",
            "Epoch 87/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 1.9226 - accuracy: 0.3828 - val_loss: 2.1029 - val_accuracy: 0.3473\n",
            "Epoch 88/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 1.9315 - accuracy: 0.3807 - val_loss: 2.1011 - val_accuracy: 0.3485\n",
            "Epoch 89/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 1.9284 - accuracy: 0.3820 - val_loss: 2.0994 - val_accuracy: 0.3452\n",
            "Epoch 90/250\n",
            "494/494 [==============================] - 2s 4ms/step - loss: 1.9198 - accuracy: 0.3858 - val_loss: 2.0973 - val_accuracy: 0.3463\n",
            "Epoch 91/250\n",
            "494/494 [==============================] - 2s 4ms/step - loss: 1.9227 - accuracy: 0.3817 - val_loss: 2.1087 - val_accuracy: 0.3392\n",
            "Epoch 92/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.9210 - accuracy: 0.3810 - val_loss: 2.0978 - val_accuracy: 0.3480\n",
            "Epoch 93/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 1.9234 - accuracy: 0.3813 - val_loss: 2.0960 - val_accuracy: 0.3445\n",
            "Epoch 94/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 1.9265 - accuracy: 0.3778 - val_loss: 2.1040 - val_accuracy: 0.3533\n",
            "Epoch 95/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 1.9184 - accuracy: 0.3816 - val_loss: 2.0998 - val_accuracy: 0.3582\n",
            "Epoch 96/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 1.9189 - accuracy: 0.3869 - val_loss: 2.0993 - val_accuracy: 0.3478\n",
            "Epoch 97/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.9182 - accuracy: 0.3832 - val_loss: 2.1077 - val_accuracy: 0.3427\n",
            "Epoch 98/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.9101 - accuracy: 0.3852 - val_loss: 2.1010 - val_accuracy: 0.3442\n",
            "Epoch 99/250\n",
            "494/494 [==============================] - 3s 5ms/step - loss: 1.9091 - accuracy: 0.3842 - val_loss: 2.0941 - val_accuracy: 0.3536\n",
            "Epoch 100/250\n",
            "494/494 [==============================] - 2s 4ms/step - loss: 1.9123 - accuracy: 0.3881 - val_loss: 2.0948 - val_accuracy: 0.3544\n",
            "Epoch 101/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.9103 - accuracy: 0.3814 - val_loss: 2.0864 - val_accuracy: 0.3508\n",
            "Epoch 102/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 1.9068 - accuracy: 0.3890 - val_loss: 2.0952 - val_accuracy: 0.3503\n",
            "Epoch 103/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.9085 - accuracy: 0.3825 - val_loss: 2.1101 - val_accuracy: 0.3445\n",
            "Epoch 104/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.9142 - accuracy: 0.3851 - val_loss: 2.0893 - val_accuracy: 0.3498\n",
            "Epoch 105/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 1.9001 - accuracy: 0.3917 - val_loss: 2.0916 - val_accuracy: 0.3513\n",
            "Epoch 106/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.9069 - accuracy: 0.3839 - val_loss: 2.0973 - val_accuracy: 0.3468\n",
            "Epoch 107/250\n",
            "494/494 [==============================] - 2s 4ms/step - loss: 1.9104 - accuracy: 0.3841 - val_loss: 2.0971 - val_accuracy: 0.3485\n",
            "Epoch 108/250\n",
            "494/494 [==============================] - 2s 4ms/step - loss: 1.9010 - accuracy: 0.3885 - val_loss: 2.0967 - val_accuracy: 0.3536\n",
            "Epoch 109/250\n",
            "494/494 [==============================] - 2s 4ms/step - loss: 1.9067 - accuracy: 0.3879 - val_loss: 2.1006 - val_accuracy: 0.3556\n",
            "Epoch 110/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.9003 - accuracy: 0.3901 - val_loss: 2.1000 - val_accuracy: 0.3539\n",
            "Epoch 111/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 1.8942 - accuracy: 0.3909 - val_loss: 2.1035 - val_accuracy: 0.3513\n",
            "Epoch 112/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.8938 - accuracy: 0.3956 - val_loss: 2.0983 - val_accuracy: 0.3468\n",
            "Epoch 113/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.8858 - accuracy: 0.3954 - val_loss: 2.1006 - val_accuracy: 0.3511\n",
            "Epoch 114/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 1.8935 - accuracy: 0.3864 - val_loss: 2.0907 - val_accuracy: 0.3539\n",
            "Epoch 115/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 1.8864 - accuracy: 0.3886 - val_loss: 2.0991 - val_accuracy: 0.3478\n",
            "Epoch 116/250\n",
            "494/494 [==============================] - 2s 4ms/step - loss: 1.8860 - accuracy: 0.3911 - val_loss: 2.0899 - val_accuracy: 0.3541\n",
            "Epoch 117/250\n",
            "494/494 [==============================] - 2s 4ms/step - loss: 1.8865 - accuracy: 0.3921 - val_loss: 2.0923 - val_accuracy: 0.3589\n",
            "Epoch 118/250\n",
            "494/494 [==============================] - 2s 4ms/step - loss: 1.8978 - accuracy: 0.3905 - val_loss: 2.0860 - val_accuracy: 0.3582\n",
            "Epoch 119/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.8789 - accuracy: 0.3927 - val_loss: 2.0963 - val_accuracy: 0.3541\n",
            "Epoch 120/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.8834 - accuracy: 0.3944 - val_loss: 2.0896 - val_accuracy: 0.3523\n",
            "Epoch 121/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 1.8765 - accuracy: 0.3935 - val_loss: 2.0954 - val_accuracy: 0.3582\n",
            "Epoch 122/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 1.8808 - accuracy: 0.3965 - val_loss: 2.0966 - val_accuracy: 0.3556\n",
            "Epoch 123/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.8812 - accuracy: 0.3935 - val_loss: 2.0928 - val_accuracy: 0.3566\n",
            "Epoch 124/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.8835 - accuracy: 0.3968 - val_loss: 2.0908 - val_accuracy: 0.3528\n",
            "Epoch 125/250\n",
            "494/494 [==============================] - 2s 5ms/step - loss: 1.8724 - accuracy: 0.3990 - val_loss: 2.0927 - val_accuracy: 0.3609\n",
            "Epoch 126/250\n",
            "494/494 [==============================] - 2s 5ms/step - loss: 1.8812 - accuracy: 0.3980 - val_loss: 2.0864 - val_accuracy: 0.3549\n",
            "Epoch 127/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.8760 - accuracy: 0.3911 - val_loss: 2.0928 - val_accuracy: 0.3566\n",
            "Epoch 128/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.8740 - accuracy: 0.3951 - val_loss: 2.0886 - val_accuracy: 0.3554\n",
            "Epoch 129/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 1.8734 - accuracy: 0.3964 - val_loss: 2.0904 - val_accuracy: 0.3617\n",
            "Epoch 130/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.8686 - accuracy: 0.3935 - val_loss: 2.0854 - val_accuracy: 0.3584\n",
            "Epoch 131/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 1.8780 - accuracy: 0.3965 - val_loss: 2.0930 - val_accuracy: 0.3592\n",
            "Epoch 132/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.8681 - accuracy: 0.3951 - val_loss: 2.0775 - val_accuracy: 0.3660\n",
            "Epoch 133/250\n",
            "494/494 [==============================] - 2s 4ms/step - loss: 1.8764 - accuracy: 0.3958 - val_loss: 2.0917 - val_accuracy: 0.3549\n",
            "Epoch 134/250\n",
            "494/494 [==============================] - 2s 5ms/step - loss: 1.8687 - accuracy: 0.3961 - val_loss: 2.0891 - val_accuracy: 0.3566\n",
            "Epoch 135/250\n",
            "494/494 [==============================] - 2s 4ms/step - loss: 1.8730 - accuracy: 0.3975 - val_loss: 2.0892 - val_accuracy: 0.3599\n",
            "Epoch 136/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 1.8681 - accuracy: 0.3953 - val_loss: 2.0925 - val_accuracy: 0.3592\n",
            "Epoch 137/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.8659 - accuracy: 0.3997 - val_loss: 2.0917 - val_accuracy: 0.3559\n",
            "Epoch 138/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.8531 - accuracy: 0.3966 - val_loss: 2.0888 - val_accuracy: 0.3592\n",
            "Epoch 139/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 1.8626 - accuracy: 0.3945 - val_loss: 2.0875 - val_accuracy: 0.3561\n",
            "Epoch 140/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.8739 - accuracy: 0.3954 - val_loss: 2.0981 - val_accuracy: 0.3544\n",
            "Epoch 141/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.8593 - accuracy: 0.3993 - val_loss: 2.0860 - val_accuracy: 0.3501\n",
            "Epoch 142/250\n",
            "494/494 [==============================] - 3s 6ms/step - loss: 1.8629 - accuracy: 0.4027 - val_loss: 2.0849 - val_accuracy: 0.3556\n",
            "Epoch 143/250\n",
            "494/494 [==============================] - 2s 4ms/step - loss: 1.8623 - accuracy: 0.3977 - val_loss: 2.0997 - val_accuracy: 0.3587\n",
            "Epoch 144/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 1.8587 - accuracy: 0.3970 - val_loss: 2.0850 - val_accuracy: 0.3612\n",
            "Epoch 145/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 1.8648 - accuracy: 0.4028 - val_loss: 2.0851 - val_accuracy: 0.3587\n",
            "Epoch 146/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 1.8526 - accuracy: 0.4030 - val_loss: 2.0917 - val_accuracy: 0.3513\n",
            "Epoch 147/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 1.8560 - accuracy: 0.4018 - val_loss: 2.0931 - val_accuracy: 0.3503\n",
            "Epoch 148/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 1.8603 - accuracy: 0.3996 - val_loss: 2.0966 - val_accuracy: 0.3495\n",
            "Epoch 149/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 1.8526 - accuracy: 0.3986 - val_loss: 2.0828 - val_accuracy: 0.3612\n",
            "Epoch 150/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 1.8571 - accuracy: 0.3993 - val_loss: 2.0865 - val_accuracy: 0.3495\n",
            "Epoch 151/250\n",
            "494/494 [==============================] - 2s 4ms/step - loss: 1.8530 - accuracy: 0.4042 - val_loss: 2.0889 - val_accuracy: 0.3551\n",
            "Epoch 152/250\n",
            "494/494 [==============================] - 2s 4ms/step - loss: 1.8551 - accuracy: 0.4023 - val_loss: 2.0878 - val_accuracy: 0.3561\n",
            "Epoch 153/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.8534 - accuracy: 0.3970 - val_loss: 2.0754 - val_accuracy: 0.3544\n",
            "Epoch 154/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.8484 - accuracy: 0.4023 - val_loss: 2.0872 - val_accuracy: 0.3604\n",
            "Epoch 155/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 1.8520 - accuracy: 0.3995 - val_loss: 2.0882 - val_accuracy: 0.3607\n",
            "Epoch 156/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 1.8598 - accuracy: 0.4017 - val_loss: 2.0852 - val_accuracy: 0.3592\n",
            "Epoch 157/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 1.8535 - accuracy: 0.4036 - val_loss: 2.0866 - val_accuracy: 0.3516\n",
            "Epoch 158/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.8458 - accuracy: 0.4008 - val_loss: 2.0870 - val_accuracy: 0.3574\n",
            "Epoch 159/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.8405 - accuracy: 0.4050 - val_loss: 2.0864 - val_accuracy: 0.3551\n",
            "Epoch 160/250\n",
            "494/494 [==============================] - 2s 4ms/step - loss: 1.8441 - accuracy: 0.4044 - val_loss: 2.0885 - val_accuracy: 0.3584\n",
            "Epoch 161/250\n",
            "494/494 [==============================] - 2s 4ms/step - loss: 1.8476 - accuracy: 0.4042 - val_loss: 2.0859 - val_accuracy: 0.3658\n",
            "Epoch 162/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.8464 - accuracy: 0.4024 - val_loss: 2.0823 - val_accuracy: 0.3696\n",
            "Epoch 163/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 1.8346 - accuracy: 0.4103 - val_loss: 2.0943 - val_accuracy: 0.3625\n",
            "Epoch 164/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.8407 - accuracy: 0.4075 - val_loss: 2.0855 - val_accuracy: 0.3554\n",
            "Epoch 165/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 1.8362 - accuracy: 0.4077 - val_loss: 2.0875 - val_accuracy: 0.3604\n",
            "Epoch 166/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.8434 - accuracy: 0.4041 - val_loss: 2.0961 - val_accuracy: 0.3609\n",
            "Epoch 167/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 1.8448 - accuracy: 0.4085 - val_loss: 2.0930 - val_accuracy: 0.3622\n",
            "Epoch 168/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 1.8341 - accuracy: 0.4106 - val_loss: 2.0832 - val_accuracy: 0.3607\n",
            "Epoch 169/250\n",
            "494/494 [==============================] - 2s 4ms/step - loss: 1.8324 - accuracy: 0.4084 - val_loss: 2.0814 - val_accuracy: 0.3620\n",
            "Epoch 170/250\n",
            "494/494 [==============================] - 2s 4ms/step - loss: 1.8322 - accuracy: 0.4076 - val_loss: 2.0894 - val_accuracy: 0.3589\n",
            "Epoch 171/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.8321 - accuracy: 0.4097 - val_loss: 2.0784 - val_accuracy: 0.3612\n",
            "Epoch 172/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.8309 - accuracy: 0.4099 - val_loss: 2.0817 - val_accuracy: 0.3607\n",
            "Epoch 173/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.8386 - accuracy: 0.4078 - val_loss: 2.0835 - val_accuracy: 0.3589\n",
            "Epoch 174/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 1.8400 - accuracy: 0.4051 - val_loss: 2.0858 - val_accuracy: 0.3589\n",
            "Epoch 175/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.8365 - accuracy: 0.4058 - val_loss: 2.0764 - val_accuracy: 0.3652\n",
            "Epoch 176/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 1.8351 - accuracy: 0.4096 - val_loss: 2.0789 - val_accuracy: 0.3627\n",
            "Epoch 177/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 1.8249 - accuracy: 0.4077 - val_loss: 2.0886 - val_accuracy: 0.3660\n",
            "Epoch 178/250\n",
            "494/494 [==============================] - 2s 4ms/step - loss: 1.8218 - accuracy: 0.4125 - val_loss: 2.0838 - val_accuracy: 0.3650\n",
            "Epoch 179/250\n",
            "494/494 [==============================] - 2s 4ms/step - loss: 1.8272 - accuracy: 0.4133 - val_loss: 2.0851 - val_accuracy: 0.3675\n",
            "Epoch 180/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.8259 - accuracy: 0.4115 - val_loss: 2.0713 - val_accuracy: 0.3625\n",
            "Epoch 181/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 1.8278 - accuracy: 0.4095 - val_loss: 2.0791 - val_accuracy: 0.3592\n",
            "Epoch 182/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 1.8343 - accuracy: 0.4006 - val_loss: 2.0806 - val_accuracy: 0.3574\n",
            "Epoch 183/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 1.8253 - accuracy: 0.4085 - val_loss: 2.0703 - val_accuracy: 0.3625\n",
            "Epoch 184/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 1.8238 - accuracy: 0.4114 - val_loss: 2.0827 - val_accuracy: 0.3625\n",
            "Epoch 185/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 1.8196 - accuracy: 0.4080 - val_loss: 2.0850 - val_accuracy: 0.3625\n",
            "Epoch 186/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.8282 - accuracy: 0.4107 - val_loss: 2.0806 - val_accuracy: 0.3604\n",
            "Epoch 187/250\n",
            "494/494 [==============================] - 2s 5ms/step - loss: 1.8249 - accuracy: 0.4089 - val_loss: 2.0839 - val_accuracy: 0.3622\n",
            "Epoch 188/250\n",
            "494/494 [==============================] - 2s 4ms/step - loss: 1.8252 - accuracy: 0.4067 - val_loss: 2.0908 - val_accuracy: 0.3544\n",
            "Epoch 189/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.8272 - accuracy: 0.4149 - val_loss: 2.0712 - val_accuracy: 0.3665\n",
            "Epoch 190/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 1.8187 - accuracy: 0.4099 - val_loss: 2.0845 - val_accuracy: 0.3597\n",
            "Epoch 191/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.8242 - accuracy: 0.4104 - val_loss: 2.0734 - val_accuracy: 0.3571\n",
            "Epoch 192/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 1.8289 - accuracy: 0.4063 - val_loss: 2.0819 - val_accuracy: 0.3604\n",
            "Epoch 193/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 1.8165 - accuracy: 0.4134 - val_loss: 2.0788 - val_accuracy: 0.3612\n",
            "Epoch 194/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 1.8177 - accuracy: 0.4120 - val_loss: 2.0784 - val_accuracy: 0.3592\n",
            "Epoch 195/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.8236 - accuracy: 0.4105 - val_loss: 2.0838 - val_accuracy: 0.3592\n",
            "Epoch 196/250\n",
            "494/494 [==============================] - 2s 4ms/step - loss: 1.8141 - accuracy: 0.4130 - val_loss: 2.0885 - val_accuracy: 0.3602\n",
            "Epoch 197/250\n",
            "494/494 [==============================] - 2s 4ms/step - loss: 1.8174 - accuracy: 0.4097 - val_loss: 2.0716 - val_accuracy: 0.3635\n",
            "Epoch 198/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.8230 - accuracy: 0.4085 - val_loss: 2.0714 - val_accuracy: 0.3632\n",
            "Epoch 199/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 1.8205 - accuracy: 0.4149 - val_loss: 2.0801 - val_accuracy: 0.3559\n",
            "Epoch 200/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 1.8131 - accuracy: 0.4118 - val_loss: 2.0857 - val_accuracy: 0.3574\n",
            "Epoch 201/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 1.8102 - accuracy: 0.4145 - val_loss: 2.0777 - val_accuracy: 0.3609\n",
            "Epoch 202/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.8201 - accuracy: 0.4118 - val_loss: 2.0846 - val_accuracy: 0.3620\n",
            "Epoch 203/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.8126 - accuracy: 0.4117 - val_loss: 2.0819 - val_accuracy: 0.3642\n",
            "Epoch 204/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 1.8160 - accuracy: 0.4113 - val_loss: 2.0762 - val_accuracy: 0.3658\n",
            "Epoch 205/250\n",
            "494/494 [==============================] - 2s 4ms/step - loss: 1.8190 - accuracy: 0.4109 - val_loss: 2.0819 - val_accuracy: 0.3609\n",
            "Epoch 206/250\n",
            "494/494 [==============================] - 2s 5ms/step - loss: 1.8223 - accuracy: 0.4096 - val_loss: 2.0849 - val_accuracy: 0.3602\n",
            "Epoch 207/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.8121 - accuracy: 0.4077 - val_loss: 2.0871 - val_accuracy: 0.3561\n",
            "Epoch 208/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.8192 - accuracy: 0.4105 - val_loss: 2.0820 - val_accuracy: 0.3612\n",
            "Epoch 209/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.8139 - accuracy: 0.4156 - val_loss: 2.0808 - val_accuracy: 0.3645\n",
            "Epoch 210/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.8070 - accuracy: 0.4186 - val_loss: 2.0960 - val_accuracy: 0.3574\n",
            "Epoch 211/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.8168 - accuracy: 0.4099 - val_loss: 2.0799 - val_accuracy: 0.3655\n",
            "Epoch 212/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 1.8173 - accuracy: 0.4111 - val_loss: 2.0907 - val_accuracy: 0.3594\n",
            "Epoch 213/250\n",
            "494/494 [==============================] - 2s 4ms/step - loss: 1.8165 - accuracy: 0.4154 - val_loss: 2.0913 - val_accuracy: 0.3571\n",
            "Epoch 214/250\n",
            "494/494 [==============================] - 2s 5ms/step - loss: 1.8097 - accuracy: 0.4107 - val_loss: 2.0858 - val_accuracy: 0.3701\n",
            "Epoch 215/250\n",
            "494/494 [==============================] - 2s 4ms/step - loss: 1.8060 - accuracy: 0.4152 - val_loss: 2.0730 - val_accuracy: 0.3696\n",
            "Epoch 216/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 1.8194 - accuracy: 0.4104 - val_loss: 2.0789 - val_accuracy: 0.3693\n",
            "Epoch 217/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.8081 - accuracy: 0.4104 - val_loss: 2.0811 - val_accuracy: 0.3604\n",
            "Epoch 218/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.7989 - accuracy: 0.4147 - val_loss: 2.0874 - val_accuracy: 0.3675\n",
            "Epoch 219/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 1.8064 - accuracy: 0.4136 - val_loss: 2.0758 - val_accuracy: 0.3673\n",
            "Epoch 220/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 1.8009 - accuracy: 0.4149 - val_loss: 2.0873 - val_accuracy: 0.3614\n",
            "Epoch 221/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.8114 - accuracy: 0.4138 - val_loss: 2.0913 - val_accuracy: 0.3635\n",
            "Epoch 222/250\n",
            "494/494 [==============================] - 2s 4ms/step - loss: 1.8089 - accuracy: 0.4137 - val_loss: 2.0793 - val_accuracy: 0.3630\n",
            "Epoch 223/250\n",
            "494/494 [==============================] - 2s 4ms/step - loss: 1.7951 - accuracy: 0.4197 - val_loss: 2.0836 - val_accuracy: 0.3673\n",
            "Epoch 224/250\n",
            "494/494 [==============================] - 2s 4ms/step - loss: 1.7985 - accuracy: 0.4217 - val_loss: 2.0900 - val_accuracy: 0.3660\n",
            "Epoch 225/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.8023 - accuracy: 0.4141 - val_loss: 2.0827 - val_accuracy: 0.3632\n",
            "Epoch 226/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.8095 - accuracy: 0.4184 - val_loss: 2.0912 - val_accuracy: 0.3731\n",
            "Epoch 227/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 1.7985 - accuracy: 0.4167 - val_loss: 2.0904 - val_accuracy: 0.3622\n",
            "Epoch 228/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 1.8014 - accuracy: 0.4187 - val_loss: 2.0808 - val_accuracy: 0.3660\n",
            "Epoch 229/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.8075 - accuracy: 0.4144 - val_loss: 2.0910 - val_accuracy: 0.3566\n",
            "Epoch 230/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 1.8039 - accuracy: 0.4152 - val_loss: 2.0880 - val_accuracy: 0.3640\n",
            "Epoch 231/250\n",
            "494/494 [==============================] - 2s 4ms/step - loss: 1.8070 - accuracy: 0.4108 - val_loss: 2.0878 - val_accuracy: 0.3655\n",
            "Epoch 232/250\n",
            "494/494 [==============================] - 2s 4ms/step - loss: 1.8011 - accuracy: 0.4200 - val_loss: 2.0846 - val_accuracy: 0.3690\n",
            "Epoch 233/250\n",
            "494/494 [==============================] - 2s 4ms/step - loss: 1.7964 - accuracy: 0.4142 - val_loss: 2.0966 - val_accuracy: 0.3597\n",
            "Epoch 234/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 1.7949 - accuracy: 0.4190 - val_loss: 2.0820 - val_accuracy: 0.3665\n",
            "Epoch 235/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.7858 - accuracy: 0.4219 - val_loss: 2.0967 - val_accuracy: 0.3594\n",
            "Epoch 236/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 1.7884 - accuracy: 0.4204 - val_loss: 2.0801 - val_accuracy: 0.3708\n",
            "Epoch 237/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 1.8027 - accuracy: 0.4206 - val_loss: 2.0913 - val_accuracy: 0.3609\n",
            "Epoch 238/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 1.8041 - accuracy: 0.4153 - val_loss: 2.0925 - val_accuracy: 0.3683\n",
            "Epoch 239/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 1.8045 - accuracy: 0.4154 - val_loss: 2.0886 - val_accuracy: 0.3655\n",
            "Epoch 240/250\n",
            "494/494 [==============================] - 2s 4ms/step - loss: 1.7988 - accuracy: 0.4174 - val_loss: 2.0727 - val_accuracy: 0.3668\n",
            "Epoch 241/250\n",
            "494/494 [==============================] - 2s 4ms/step - loss: 1.7851 - accuracy: 0.4229 - val_loss: 2.0897 - val_accuracy: 0.3597\n",
            "Epoch 242/250\n",
            "494/494 [==============================] - 2s 4ms/step - loss: 1.7923 - accuracy: 0.4251 - val_loss: 2.0834 - val_accuracy: 0.3668\n",
            "Epoch 243/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.7872 - accuracy: 0.4201 - val_loss: 2.0839 - val_accuracy: 0.3678\n",
            "Epoch 244/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 1.7867 - accuracy: 0.4211 - val_loss: 2.0938 - val_accuracy: 0.3635\n",
            "Epoch 245/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 1.7962 - accuracy: 0.4207 - val_loss: 2.0791 - val_accuracy: 0.3637\n",
            "Epoch 246/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 1.7865 - accuracy: 0.4191 - val_loss: 2.0838 - val_accuracy: 0.3604\n",
            "Epoch 247/250\n",
            "494/494 [==============================] - 1s 3ms/step - loss: 1.7932 - accuracy: 0.4175 - val_loss: 2.0851 - val_accuracy: 0.3592\n",
            "Epoch 248/250\n",
            "494/494 [==============================] - 2s 3ms/step - loss: 1.7922 - accuracy: 0.4170 - val_loss: 2.0764 - val_accuracy: 0.3749\n",
            "Epoch 249/250\n",
            "494/494 [==============================] - 2s 4ms/step - loss: 1.7977 - accuracy: 0.4201 - val_loss: 2.0859 - val_accuracy: 0.3658\n",
            "Epoch 250/250\n",
            "494/494 [==============================] - 2s 4ms/step - loss: 1.7839 - accuracy: 0.4269 - val_loss: 2.0804 - val_accuracy: 0.3703\n",
            "155/155 [==============================] - 0s 2ms/step - loss: 2.0954 - accuracy: 0.3706\n",
            "Test Accuracy: 0.3706180453300476\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Create a simple neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(128, activation='relu', input_dim=X_train.shape[1]))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(20, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history_simple_nn = model.fit(X_train, y_train, epochs=250, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(f'Test Accuracy: {test_acc}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ACG1c3aiSkoT"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}